{"version":3,"sources":["../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/google-provider.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/version.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/google-generative-ai-embedding-model.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/google-error.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/google-generative-ai-embedding-options.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/google-generative-ai-language-model.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/convert-google-generative-ai-usage.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/convert-json-schema-to-openapi-schema.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/convert-to-google-generative-ai-messages.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/get-model-path.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/google-generative-ai-options.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/google-prepare-tools.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/map-google-generative-ai-finish-reason.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/tool/code-execution.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/tool/enterprise-web-search.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/tool/file-search.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/tool/google-maps.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/tool/google-search.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/tool/url-context.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/tool/vertex-rag-store.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/google-tools.ts","../../../node_modules/.pnpm/@ai-sdk+google@3.0.1_zod@4.2.1/node_modules/@ai-sdk/google/src/google-generative-ai-image-model.ts"],"sourcesContent":["import {\n  EmbeddingModelV3,\n  LanguageModelV3,\n  ProviderV3,\n  ImageModelV3,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  generateId,\n  loadApiKey,\n  withoutTrailingSlash,\n  withUserAgentSuffix,\n} from '@ai-sdk/provider-utils';\nimport { VERSION } from './version';\nimport { GoogleGenerativeAIEmbeddingModel } from './google-generative-ai-embedding-model';\nimport { GoogleGenerativeAIEmbeddingModelId } from './google-generative-ai-embedding-options';\nimport { GoogleGenerativeAILanguageModel } from './google-generative-ai-language-model';\nimport { GoogleGenerativeAIModelId } from './google-generative-ai-options';\nimport { googleTools } from './google-tools';\n\nimport {\n  GoogleGenerativeAIImageSettings,\n  GoogleGenerativeAIImageModelId,\n} from './google-generative-ai-image-settings';\nimport { GoogleGenerativeAIImageModel } from './google-generative-ai-image-model';\n\nexport interface GoogleGenerativeAIProvider extends ProviderV3 {\n  (modelId: GoogleGenerativeAIModelId): LanguageModelV3;\n\n  languageModel(modelId: GoogleGenerativeAIModelId): LanguageModelV3;\n\n  chat(modelId: GoogleGenerativeAIModelId): LanguageModelV3;\n\n  /**\nCreates a model for image generation.\n */\n  image(\n    modelId: GoogleGenerativeAIImageModelId,\n    settings?: GoogleGenerativeAIImageSettings,\n  ): ImageModelV3;\n\n  /**\n   * @deprecated Use `chat()` instead.\n   */\n  generativeAI(modelId: GoogleGenerativeAIModelId): LanguageModelV3;\n\n  /**\n   * Creates a model for text embeddings.\n   */\n  embedding(modelId: GoogleGenerativeAIEmbeddingModelId): EmbeddingModelV3;\n\n  /**\n   * Creates a model for text embeddings.\n   */\n  embeddingModel(modelId: GoogleGenerativeAIEmbeddingModelId): EmbeddingModelV3;\n\n  /**\n   * @deprecated Use `embedding` instead.\n   */\n  textEmbedding(modelId: GoogleGenerativeAIEmbeddingModelId): EmbeddingModelV3;\n\n  /**\n   * @deprecated Use `embeddingModel` instead.\n   */\n  textEmbeddingModel(\n    modelId: GoogleGenerativeAIEmbeddingModelId,\n  ): EmbeddingModelV3;\n\n  tools: typeof googleTools;\n}\n\nexport interface GoogleGenerativeAIProviderSettings {\n  /**\nUse a different URL prefix for API calls, e.g. to use proxy servers.\nThe default prefix is `https://generativelanguage.googleapis.com/v1beta`.\n   */\n  baseURL?: string;\n\n  /**\nAPI key that is being send using the `x-goog-api-key` header.\nIt defaults to the `GOOGLE_GENERATIVE_AI_API_KEY` environment variable.\n   */\n  apiKey?: string;\n\n  /**\nCustom headers to include in the requests.\n     */\n  headers?: Record<string, string | undefined>;\n\n  /**\nCustom fetch implementation. You can use it as a middleware to intercept requests,\nor to provide a custom fetch implementation for e.g. testing.\n    */\n  fetch?: FetchFunction;\n\n  /**\nOptional function to generate a unique ID for each request.\n     */\n  generateId?: () => string;\n\n  /**\n   * Custom provider name\n   * Defaults to 'google.generative-ai'.\n   */\n  name?: string;\n}\n\n/**\nCreate a Google Generative AI provider instance.\n */\nexport function createGoogleGenerativeAI(\n  options: GoogleGenerativeAIProviderSettings = {},\n): GoogleGenerativeAIProvider {\n  const baseURL =\n    withoutTrailingSlash(options.baseURL) ??\n    'https://generativelanguage.googleapis.com/v1beta';\n\n  const providerName = options.name ?? 'google.generative-ai';\n\n  const getHeaders = () =>\n    withUserAgentSuffix(\n      {\n        'x-goog-api-key': loadApiKey({\n          apiKey: options.apiKey,\n          environmentVariableName: 'GOOGLE_GENERATIVE_AI_API_KEY',\n          description: 'Google Generative AI',\n        }),\n        ...options.headers,\n      },\n      `ai-sdk/google/${VERSION}`,\n    );\n\n  const createChatModel = (modelId: GoogleGenerativeAIModelId) =>\n    new GoogleGenerativeAILanguageModel(modelId, {\n      provider: providerName,\n      baseURL,\n      headers: getHeaders,\n      generateId: options.generateId ?? generateId,\n      supportedUrls: () => ({\n        '*': [\n          // Google Generative Language \"files\" endpoint\n          // e.g. https://generativelanguage.googleapis.com/v1beta/files/...\n          new RegExp(`^${baseURL}/files/.*$`),\n          // YouTube URLs (public or unlisted videos)\n          new RegExp(\n            `^https://(?:www\\\\.)?youtube\\\\.com/watch\\\\?v=[\\\\w-]+(?:&[\\\\w=&.-]*)?$`,\n          ),\n          new RegExp(`^https://youtu\\\\.be/[\\\\w-]+(?:\\\\?[\\\\w=&.-]*)?$`),\n        ],\n      }),\n      fetch: options.fetch,\n    });\n\n  const createEmbeddingModel = (modelId: GoogleGenerativeAIEmbeddingModelId) =>\n    new GoogleGenerativeAIEmbeddingModel(modelId, {\n      provider: providerName,\n      baseURL,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createImageModel = (\n    modelId: GoogleGenerativeAIImageModelId,\n    settings: GoogleGenerativeAIImageSettings = {},\n  ) =>\n    new GoogleGenerativeAIImageModel(modelId, settings, {\n      provider: providerName,\n      baseURL,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const provider = function (modelId: GoogleGenerativeAIModelId) {\n    if (new.target) {\n      throw new Error(\n        'The Google Generative AI model function cannot be called with the new keyword.',\n      );\n    }\n\n    return createChatModel(modelId);\n  };\n\n  provider.specificationVersion = 'v3' as const;\n  provider.languageModel = createChatModel;\n  provider.chat = createChatModel;\n  provider.generativeAI = createChatModel;\n  provider.embedding = createEmbeddingModel;\n  provider.embeddingModel = createEmbeddingModel;\n  provider.textEmbedding = createEmbeddingModel;\n  provider.textEmbeddingModel = createEmbeddingModel;\n  provider.image = createImageModel;\n  provider.imageModel = createImageModel;\n  provider.tools = googleTools;\n\n  return provider as GoogleGenerativeAIProvider;\n}\n\n/**\nDefault Google Generative AI provider instance.\n */\nexport const google = createGoogleGenerativeAI();\n","// Version string of this package injected at build time.\ndeclare const __PACKAGE_VERSION__: string | undefined;\nexport const VERSION: string =\n  typeof __PACKAGE_VERSION__ !== 'undefined'\n    ? __PACKAGE_VERSION__\n    : '0.0.0-test';\n","import {\n  EmbeddingModelV3,\n  TooManyEmbeddingValuesForCallError,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  FetchFunction,\n  lazySchema,\n  parseProviderOptions,\n  postJsonToApi,\n  resolve,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { googleFailedResponseHandler } from './google-error';\nimport {\n  GoogleGenerativeAIEmbeddingModelId,\n  googleGenerativeAIEmbeddingProviderOptions,\n} from './google-generative-ai-embedding-options';\n\ntype GoogleGenerativeAIEmbeddingConfig = {\n  provider: string;\n  baseURL: string;\n  headers: () => Record<string, string | undefined>;\n  fetch?: FetchFunction;\n};\n\nexport class GoogleGenerativeAIEmbeddingModel implements EmbeddingModelV3 {\n  readonly specificationVersion = 'v3';\n  readonly modelId: GoogleGenerativeAIEmbeddingModelId;\n  readonly maxEmbeddingsPerCall = 2048;\n  readonly supportsParallelCalls = true;\n\n  private readonly config: GoogleGenerativeAIEmbeddingConfig;\n\n  get provider(): string {\n    return this.config.provider;\n  }\n  constructor(\n    modelId: GoogleGenerativeAIEmbeddingModelId,\n    config: GoogleGenerativeAIEmbeddingConfig,\n  ) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  async doEmbed({\n    values,\n    headers,\n    abortSignal,\n    providerOptions,\n  }: Parameters<EmbeddingModelV3['doEmbed']>[0]): Promise<\n    Awaited<ReturnType<EmbeddingModelV3['doEmbed']>>\n  > {\n    // Parse provider options\n    const googleOptions = await parseProviderOptions({\n      provider: 'google',\n      providerOptions,\n      schema: googleGenerativeAIEmbeddingProviderOptions,\n    });\n\n    if (values.length > this.maxEmbeddingsPerCall) {\n      throw new TooManyEmbeddingValuesForCallError({\n        provider: this.provider,\n        modelId: this.modelId,\n        maxEmbeddingsPerCall: this.maxEmbeddingsPerCall,\n        values,\n      });\n    }\n\n    const mergedHeaders = combineHeaders(\n      await resolve(this.config.headers),\n      headers,\n    );\n\n    // For single embeddings, use the single endpoint (ratelimits, etc.)\n    if (values.length === 1) {\n      const {\n        responseHeaders,\n        value: response,\n        rawValue,\n      } = await postJsonToApi({\n        url: `${this.config.baseURL}/models/${this.modelId}:embedContent`,\n        headers: mergedHeaders,\n        body: {\n          model: `models/${this.modelId}`,\n          content: {\n            parts: [{ text: values[0] }],\n          },\n          outputDimensionality: googleOptions?.outputDimensionality,\n          taskType: googleOptions?.taskType,\n        },\n        failedResponseHandler: googleFailedResponseHandler,\n        successfulResponseHandler: createJsonResponseHandler(\n          googleGenerativeAISingleEmbeddingResponseSchema,\n        ),\n        abortSignal,\n        fetch: this.config.fetch,\n      });\n\n      return {\n        warnings: [],\n        embeddings: [response.embedding.values],\n        usage: undefined,\n        response: { headers: responseHeaders, body: rawValue },\n      };\n    }\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue,\n    } = await postJsonToApi({\n      url: `${this.config.baseURL}/models/${this.modelId}:batchEmbedContents`,\n      headers: mergedHeaders,\n      body: {\n        requests: values.map(value => ({\n          model: `models/${this.modelId}`,\n          content: { role: 'user', parts: [{ text: value }] },\n          outputDimensionality: googleOptions?.outputDimensionality,\n          taskType: googleOptions?.taskType,\n        })),\n      },\n      failedResponseHandler: googleFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        googleGenerativeAITextEmbeddingResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      warnings: [],\n      embeddings: response.embeddings.map(item => item.values),\n      usage: undefined,\n      response: { headers: responseHeaders, body: rawValue },\n    };\n  }\n}\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst googleGenerativeAITextEmbeddingResponseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      embeddings: z.array(z.object({ values: z.array(z.number()) })),\n    }),\n  ),\n);\n\n// Schema for single embedding response\nconst googleGenerativeAISingleEmbeddingResponseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      embedding: z.object({ values: z.array(z.number()) }),\n    }),\n  ),\n);\n","import {\n  createJsonErrorResponseHandler,\n  type InferSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nconst googleErrorDataSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      error: z.object({\n        code: z.number().nullable(),\n        message: z.string(),\n        status: z.string(),\n      }),\n    }),\n  ),\n);\n\nexport type GoogleErrorData = InferSchema<typeof googleErrorDataSchema>;\n\nexport const googleFailedResponseHandler = createJsonErrorResponseHandler({\n  errorSchema: googleErrorDataSchema,\n  errorToMessage: data => data.error.message,\n});\n","import {\n  type InferSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport type GoogleGenerativeAIEmbeddingModelId =\n  | 'gemini-embedding-001'\n  | 'text-embedding-004'\n  | (string & {});\n\nexport const googleGenerativeAIEmbeddingProviderOptions = lazySchema(() =>\n  zodSchema(\n    z.object({\n      /**\n       * Optional. Optional reduced dimension for the output embedding.\n       * If set, excessive values in the output embedding are truncated from the end.\n       */\n      outputDimensionality: z.number().optional(),\n\n      /**\n       * Optional. Specifies the task type for generating embeddings.\n       * Supported task types:\n       * - SEMANTIC_SIMILARITY: Optimized for text similarity.\n       * - CLASSIFICATION: Optimized for text classification.\n       * - CLUSTERING: Optimized for clustering texts based on similarity.\n       * - RETRIEVAL_DOCUMENT: Optimized for document retrieval.\n       * - RETRIEVAL_QUERY: Optimized for query-based retrieval.\n       * - QUESTION_ANSWERING: Optimized for answering questions.\n       * - FACT_VERIFICATION: Optimized for verifying factual information.\n       * - CODE_RETRIEVAL_QUERY: Optimized for retrieving code blocks based on natural language queries.\n       */\n      taskType: z\n        .enum([\n          'SEMANTIC_SIMILARITY',\n          'CLASSIFICATION',\n          'CLUSTERING',\n          'RETRIEVAL_DOCUMENT',\n          'RETRIEVAL_QUERY',\n          'QUESTION_ANSWERING',\n          'FACT_VERIFICATION',\n          'CODE_RETRIEVAL_QUERY',\n        ])\n        .optional(),\n    }),\n  ),\n);\n\nexport type GoogleGenerativeAIEmbeddingProviderOptions = InferSchema<\n  typeof googleGenerativeAIEmbeddingProviderOptions\n>;\n","import {\n  LanguageModelV3,\n  LanguageModelV3CallOptions,\n  LanguageModelV3Content,\n  LanguageModelV3FinishReason,\n  LanguageModelV3GenerateResult,\n  LanguageModelV3Source,\n  LanguageModelV3StreamPart,\n  LanguageModelV3StreamResult,\n  SharedV3ProviderMetadata,\n  SharedV3Warning,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  FetchFunction,\n  generateId,\n  InferSchema,\n  lazySchema,\n  parseProviderOptions,\n  ParseResult,\n  postJsonToApi,\n  Resolvable,\n  resolve,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport {\n  convertGoogleGenerativeAIUsage,\n  GoogleGenerativeAIUsageMetadata,\n} from './convert-google-generative-ai-usage';\nimport { convertJSONSchemaToOpenAPISchema } from './convert-json-schema-to-openapi-schema';\nimport { convertToGoogleGenerativeAIMessages } from './convert-to-google-generative-ai-messages';\nimport { getModelPath } from './get-model-path';\nimport { googleFailedResponseHandler } from './google-error';\nimport {\n  GoogleGenerativeAIModelId,\n  googleGenerativeAIProviderOptions,\n} from './google-generative-ai-options';\nimport { GoogleGenerativeAIContentPart } from './google-generative-ai-prompt';\nimport { prepareTools } from './google-prepare-tools';\nimport { mapGoogleGenerativeAIFinishReason } from './map-google-generative-ai-finish-reason';\n\ntype GoogleGenerativeAIConfig = {\n  provider: string;\n  baseURL: string;\n  headers: Resolvable<Record<string, string | undefined>>;\n  fetch?: FetchFunction;\n  generateId: () => string;\n\n  /**\n   * The supported URLs for the model.\n   */\n  supportedUrls?: () => LanguageModelV3['supportedUrls'];\n};\n\nexport class GoogleGenerativeAILanguageModel implements LanguageModelV3 {\n  readonly specificationVersion = 'v3';\n\n  readonly modelId: GoogleGenerativeAIModelId;\n\n  private readonly config: GoogleGenerativeAIConfig;\n  private readonly generateId: () => string;\n\n  constructor(\n    modelId: GoogleGenerativeAIModelId,\n    config: GoogleGenerativeAIConfig,\n  ) {\n    this.modelId = modelId;\n    this.config = config;\n    this.generateId = config.generateId ?? generateId;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  get supportedUrls() {\n    return this.config.supportedUrls?.() ?? {};\n  }\n\n  private async getArgs({\n    prompt,\n    maxOutputTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences,\n    responseFormat,\n    seed,\n    tools,\n    toolChoice,\n    providerOptions,\n  }: LanguageModelV3CallOptions) {\n    const warnings: SharedV3Warning[] = [];\n\n    const providerOptionsName = this.config.provider.includes('vertex')\n      ? 'vertex'\n      : 'google';\n    let googleOptions = await parseProviderOptions({\n      provider: providerOptionsName,\n      providerOptions,\n      schema: googleGenerativeAIProviderOptions,\n    });\n\n    if (googleOptions == null && providerOptionsName !== 'google') {\n      googleOptions = await parseProviderOptions({\n        provider: 'google',\n        providerOptions,\n        schema: googleGenerativeAIProviderOptions,\n      });\n    }\n\n    // Add warning if Vertex rag tools are used with a non-Vertex Google provider\n    if (\n      tools?.some(\n        tool =>\n          tool.type === 'provider' && tool.id === 'google.vertex_rag_store',\n      ) &&\n      !this.config.provider.startsWith('google.vertex.')\n    ) {\n      warnings.push({\n        type: 'other',\n        message:\n          \"The 'vertex_rag_store' tool is only supported with the Google Vertex provider \" +\n          'and might not be supported or could behave unexpectedly with the current Google provider ' +\n          `(${this.config.provider}).`,\n      });\n    }\n\n    const isGemmaModel = this.modelId.toLowerCase().startsWith('gemma-');\n\n    const { contents, systemInstruction } = convertToGoogleGenerativeAIMessages(\n      prompt,\n      { isGemmaModel, providerOptionsName },\n    );\n\n    const {\n      tools: googleTools,\n      toolConfig: googleToolConfig,\n      toolWarnings,\n    } = prepareTools({\n      tools,\n      toolChoice,\n      modelId: this.modelId,\n    });\n\n    return {\n      args: {\n        generationConfig: {\n          // standardized settings:\n          maxOutputTokens,\n          temperature,\n          topK,\n          topP,\n          frequencyPenalty,\n          presencePenalty,\n          stopSequences,\n          seed,\n\n          // response format:\n          responseMimeType:\n            responseFormat?.type === 'json' ? 'application/json' : undefined,\n          responseSchema:\n            responseFormat?.type === 'json' &&\n            responseFormat.schema != null &&\n            // Google GenAI does not support all OpenAPI Schema features,\n            // so this is needed as an escape hatch:\n            // TODO convert into provider option\n            (googleOptions?.structuredOutputs ?? true)\n              ? convertJSONSchemaToOpenAPISchema(responseFormat.schema)\n              : undefined,\n          ...(googleOptions?.audioTimestamp && {\n            audioTimestamp: googleOptions.audioTimestamp,\n          }),\n\n          // provider options:\n          responseModalities: googleOptions?.responseModalities,\n          thinkingConfig: googleOptions?.thinkingConfig,\n          ...(googleOptions?.mediaResolution && {\n            mediaResolution: googleOptions.mediaResolution,\n          }),\n          ...(googleOptions?.imageConfig && {\n            imageConfig: googleOptions.imageConfig,\n          }),\n        },\n        contents,\n        systemInstruction: isGemmaModel ? undefined : systemInstruction,\n        safetySettings: googleOptions?.safetySettings,\n        tools: googleTools,\n        toolConfig: googleOptions?.retrievalConfig\n          ? {\n              ...googleToolConfig,\n              retrievalConfig: googleOptions.retrievalConfig,\n            }\n          : googleToolConfig,\n        cachedContent: googleOptions?.cachedContent,\n        labels: googleOptions?.labels,\n      },\n      warnings: [...warnings, ...toolWarnings],\n      providerOptionsName,\n    };\n  }\n\n  async doGenerate(\n    options: LanguageModelV3CallOptions,\n  ): Promise<LanguageModelV3GenerateResult> {\n    const { args, warnings, providerOptionsName } = await this.getArgs(options);\n\n    const mergedHeaders = combineHeaders(\n      await resolve(this.config.headers),\n      options.headers,\n    );\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: `${this.config.baseURL}/${getModelPath(\n        this.modelId,\n      )}:generateContent`,\n      headers: mergedHeaders,\n      body: args,\n      failedResponseHandler: googleFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(responseSchema),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const candidate = response.candidates[0];\n    const content: Array<LanguageModelV3Content> = [];\n\n    // map ordered parts to content:\n    const parts = candidate.content?.parts ?? [];\n\n    const usageMetadata = response.usageMetadata;\n\n    // Associates a code execution result with its preceding call.\n    let lastCodeExecutionToolCallId: string | undefined;\n\n    // Build content array from all parts\n    for (const part of parts) {\n      if ('executableCode' in part && part.executableCode?.code) {\n        const toolCallId = this.config.generateId();\n        lastCodeExecutionToolCallId = toolCallId;\n\n        content.push({\n          type: 'tool-call',\n          toolCallId,\n          toolName: 'code_execution',\n          input: JSON.stringify(part.executableCode),\n          providerExecuted: true,\n        });\n      } else if ('codeExecutionResult' in part && part.codeExecutionResult) {\n        content.push({\n          type: 'tool-result',\n          // Assumes a result directly follows its corresponding call part.\n          toolCallId: lastCodeExecutionToolCallId!,\n          toolName: 'code_execution',\n          result: {\n            outcome: part.codeExecutionResult.outcome,\n            output: part.codeExecutionResult.output,\n          },\n        });\n        // Clear the ID after use to avoid accidental reuse.\n        lastCodeExecutionToolCallId = undefined;\n      } else if ('text' in part && part.text != null && part.text.length > 0) {\n        content.push({\n          type: part.thought === true ? 'reasoning' : 'text',\n          text: part.text,\n          providerMetadata: part.thoughtSignature\n            ? {\n                [providerOptionsName]: {\n                  thoughtSignature: part.thoughtSignature,\n                },\n              }\n            : undefined,\n        });\n      } else if ('functionCall' in part) {\n        content.push({\n          type: 'tool-call' as const,\n          toolCallId: this.config.generateId(),\n          toolName: part.functionCall.name,\n          input: JSON.stringify(part.functionCall.args),\n          providerMetadata: part.thoughtSignature\n            ? {\n                [providerOptionsName]: {\n                  thoughtSignature: part.thoughtSignature,\n                },\n              }\n            : undefined,\n        });\n      } else if ('inlineData' in part) {\n        content.push({\n          type: 'file' as const,\n          data: part.inlineData.data,\n          mediaType: part.inlineData.mimeType,\n          providerMetadata: part.thoughtSignature\n            ? {\n                [providerOptionsName]: {\n                  thoughtSignature: part.thoughtSignature,\n                },\n              }\n            : undefined,\n        });\n      }\n    }\n\n    const sources =\n      extractSources({\n        groundingMetadata: candidate.groundingMetadata,\n        generateId: this.config.generateId,\n      }) ?? [];\n    for (const source of sources) {\n      content.push(source);\n    }\n\n    return {\n      content,\n      finishReason: {\n        unified: mapGoogleGenerativeAIFinishReason({\n          finishReason: candidate.finishReason,\n          hasToolCalls: content.some(part => part.type === 'tool-call'),\n        }),\n        raw: candidate.finishReason ?? undefined,\n      },\n      usage: convertGoogleGenerativeAIUsage(usageMetadata),\n      warnings,\n      providerMetadata: {\n        [providerOptionsName]: {\n          promptFeedback: response.promptFeedback ?? null,\n          groundingMetadata: candidate.groundingMetadata ?? null,\n          urlContextMetadata: candidate.urlContextMetadata ?? null,\n          safetyRatings: candidate.safetyRatings ?? null,\n          usageMetadata: usageMetadata ?? null,\n        },\n      },\n      request: { body: args },\n      response: {\n        // TODO timestamp, model id, id\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n    };\n  }\n\n  async doStream(\n    options: LanguageModelV3CallOptions,\n  ): Promise<LanguageModelV3StreamResult> {\n    const { args, warnings, providerOptionsName } = await this.getArgs(options);\n\n    const headers = combineHeaders(\n      await resolve(this.config.headers),\n      options.headers,\n    );\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: `${this.config.baseURL}/${getModelPath(\n        this.modelId,\n      )}:streamGenerateContent?alt=sse`,\n      headers,\n      body: args,\n      failedResponseHandler: googleFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(chunkSchema),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    let finishReason: LanguageModelV3FinishReason = {\n      unified: 'other',\n      raw: undefined,\n    };\n    let usage: GoogleGenerativeAIUsageMetadata | undefined = undefined;\n    let providerMetadata: SharedV3ProviderMetadata | undefined = undefined;\n\n    const generateId = this.config.generateId;\n    let hasToolCalls = false;\n\n    // Track active blocks to group consecutive parts of same type\n    let currentTextBlockId: string | null = null;\n    let currentReasoningBlockId: string | null = null;\n    let blockCounter = 0;\n\n    // Track emitted sources to prevent duplicates\n    const emittedSourceUrls = new Set<string>();\n    // Associates a code execution result with its preceding call.\n    let lastCodeExecutionToolCallId: string | undefined;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<ChunkSchema>,\n          LanguageModelV3StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            if (!chunk.success) {\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            const usageMetadata = value.usageMetadata;\n\n            if (usageMetadata != null) {\n              usage = usageMetadata;\n            }\n\n            const candidate = value.candidates?.[0];\n\n            // sometimes the API returns an empty candidates array\n            if (candidate == null) {\n              return;\n            }\n\n            const content = candidate.content;\n\n            const sources = extractSources({\n              groundingMetadata: candidate.groundingMetadata,\n              generateId,\n            });\n            if (sources != null) {\n              for (const source of sources) {\n                if (\n                  source.sourceType === 'url' &&\n                  !emittedSourceUrls.has(source.url)\n                ) {\n                  emittedSourceUrls.add(source.url);\n                  controller.enqueue(source);\n                }\n              }\n            }\n\n            // Process tool call's parts before determining finishReason to ensure hasToolCalls is properly set\n            if (content != null) {\n              // Process all parts in a single loop to preserve original order\n              const parts = content.parts ?? [];\n              for (const part of parts) {\n                if ('executableCode' in part && part.executableCode?.code) {\n                  const toolCallId = generateId();\n                  lastCodeExecutionToolCallId = toolCallId;\n\n                  controller.enqueue({\n                    type: 'tool-call',\n                    toolCallId,\n                    toolName: 'code_execution',\n                    input: JSON.stringify(part.executableCode),\n                    providerExecuted: true,\n                  });\n\n                  hasToolCalls = true;\n                } else if (\n                  'codeExecutionResult' in part &&\n                  part.codeExecutionResult\n                ) {\n                  // Assumes a result directly follows its corresponding call part.\n                  const toolCallId = lastCodeExecutionToolCallId;\n\n                  if (toolCallId) {\n                    controller.enqueue({\n                      type: 'tool-result',\n                      toolCallId,\n                      toolName: 'code_execution',\n                      result: {\n                        outcome: part.codeExecutionResult.outcome,\n                        output: part.codeExecutionResult.output,\n                      },\n                    });\n                    // Clear the ID after use.\n                    lastCodeExecutionToolCallId = undefined;\n                  }\n                } else if (\n                  'text' in part &&\n                  part.text != null &&\n                  part.text.length > 0\n                ) {\n                  if (part.thought === true) {\n                    // End any active text block before starting reasoning\n                    if (currentTextBlockId !== null) {\n                      controller.enqueue({\n                        type: 'text-end',\n                        id: currentTextBlockId,\n                      });\n                      currentTextBlockId = null;\n                    }\n\n                    // Start new reasoning block if not already active\n                    if (currentReasoningBlockId === null) {\n                      currentReasoningBlockId = String(blockCounter++);\n                      controller.enqueue({\n                        type: 'reasoning-start',\n                        id: currentReasoningBlockId,\n                        providerMetadata: part.thoughtSignature\n                          ? {\n                              [providerOptionsName]: {\n                                thoughtSignature: part.thoughtSignature,\n                              },\n                            }\n                          : undefined,\n                      });\n                    }\n\n                    controller.enqueue({\n                      type: 'reasoning-delta',\n                      id: currentReasoningBlockId,\n                      delta: part.text,\n                      providerMetadata: part.thoughtSignature\n                        ? {\n                            [providerOptionsName]: {\n                              thoughtSignature: part.thoughtSignature,\n                            },\n                          }\n                        : undefined,\n                    });\n                  } else {\n                    // End any active reasoning block before starting text\n                    if (currentReasoningBlockId !== null) {\n                      controller.enqueue({\n                        type: 'reasoning-end',\n                        id: currentReasoningBlockId,\n                      });\n                      currentReasoningBlockId = null;\n                    }\n\n                    // Start new text block if not already active\n                    if (currentTextBlockId === null) {\n                      currentTextBlockId = String(blockCounter++);\n                      controller.enqueue({\n                        type: 'text-start',\n                        id: currentTextBlockId,\n                        providerMetadata: part.thoughtSignature\n                          ? {\n                              [providerOptionsName]: {\n                                thoughtSignature: part.thoughtSignature,\n                              },\n                            }\n                          : undefined,\n                      });\n                    }\n\n                    controller.enqueue({\n                      type: 'text-delta',\n                      id: currentTextBlockId,\n                      delta: part.text,\n                      providerMetadata: part.thoughtSignature\n                        ? {\n                            [providerOptionsName]: {\n                              thoughtSignature: part.thoughtSignature,\n                            },\n                          }\n                        : undefined,\n                    });\n                  }\n                } else if ('inlineData' in part) {\n                  // Process file parts inline to preserve order with text\n                  controller.enqueue({\n                    type: 'file',\n                    mediaType: part.inlineData.mimeType,\n                    data: part.inlineData.data,\n                  });\n                }\n              }\n\n              const toolCallDeltas = getToolCallsFromParts({\n                parts: content.parts,\n                generateId,\n                providerOptionsName,\n              });\n\n              if (toolCallDeltas != null) {\n                for (const toolCall of toolCallDeltas) {\n                  controller.enqueue({\n                    type: 'tool-input-start',\n                    id: toolCall.toolCallId,\n                    toolName: toolCall.toolName,\n                    providerMetadata: toolCall.providerMetadata,\n                  });\n\n                  controller.enqueue({\n                    type: 'tool-input-delta',\n                    id: toolCall.toolCallId,\n                    delta: toolCall.args,\n                    providerMetadata: toolCall.providerMetadata,\n                  });\n\n                  controller.enqueue({\n                    type: 'tool-input-end',\n                    id: toolCall.toolCallId,\n                    providerMetadata: toolCall.providerMetadata,\n                  });\n\n                  controller.enqueue({\n                    type: 'tool-call',\n                    toolCallId: toolCall.toolCallId,\n                    toolName: toolCall.toolName,\n                    input: toolCall.args,\n                    providerMetadata: toolCall.providerMetadata,\n                  });\n\n                  hasToolCalls = true;\n                }\n              }\n            }\n\n            if (candidate.finishReason != null) {\n              finishReason = {\n                unified: mapGoogleGenerativeAIFinishReason({\n                  finishReason: candidate.finishReason,\n                  hasToolCalls,\n                }),\n                raw: candidate.finishReason,\n              };\n\n              providerMetadata = {\n                [providerOptionsName]: {\n                  promptFeedback: value.promptFeedback ?? null,\n                  groundingMetadata: candidate.groundingMetadata ?? null,\n                  urlContextMetadata: candidate.urlContextMetadata ?? null,\n                  safetyRatings: candidate.safetyRatings ?? null,\n                },\n              };\n              if (usageMetadata != null) {\n                (\n                  providerMetadata[providerOptionsName] as Record<\n                    string,\n                    unknown\n                  >\n                ).usageMetadata = usageMetadata;\n              }\n            }\n          },\n\n          flush(controller) {\n            // Close any open blocks before finishing\n            if (currentTextBlockId !== null) {\n              controller.enqueue({\n                type: 'text-end',\n                id: currentTextBlockId,\n              });\n            }\n            if (currentReasoningBlockId !== null) {\n              controller.enqueue({\n                type: 'reasoning-end',\n                id: currentReasoningBlockId,\n              });\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage: convertGoogleGenerativeAIUsage(usage),\n              providerMetadata,\n            });\n          },\n        }),\n      ),\n      response: { headers: responseHeaders },\n      request: { body: args },\n    };\n  }\n}\n\nfunction getToolCallsFromParts({\n  parts,\n  generateId,\n  providerOptionsName,\n}: {\n  parts: ContentSchema['parts'];\n  generateId: () => string;\n  providerOptionsName: string;\n}) {\n  const functionCallParts = parts?.filter(\n    part => 'functionCall' in part,\n  ) as Array<\n    GoogleGenerativeAIContentPart & {\n      functionCall: { name: string; args: unknown };\n      thoughtSignature?: string | null;\n    }\n  >;\n\n  return functionCallParts == null || functionCallParts.length === 0\n    ? undefined\n    : functionCallParts.map(part => ({\n        type: 'tool-call' as const,\n        toolCallId: generateId(),\n        toolName: part.functionCall.name,\n        args: JSON.stringify(part.functionCall.args),\n        providerMetadata: part.thoughtSignature\n          ? {\n              [providerOptionsName]: {\n                thoughtSignature: part.thoughtSignature,\n              },\n            }\n          : undefined,\n      }));\n}\n\nfunction extractSources({\n  groundingMetadata,\n  generateId,\n}: {\n  groundingMetadata: GroundingMetadataSchema | undefined | null;\n  generateId: () => string;\n}): undefined | LanguageModelV3Source[] {\n  if (!groundingMetadata?.groundingChunks) {\n    return undefined;\n  }\n\n  const sources: LanguageModelV3Source[] = [];\n\n  for (const chunk of groundingMetadata.groundingChunks) {\n    if (chunk.web != null) {\n      // Handle web chunks as URL sources\n      sources.push({\n        type: 'source',\n        sourceType: 'url',\n        id: generateId(),\n        url: chunk.web.uri,\n        title: chunk.web.title ?? undefined,\n      });\n    } else if (chunk.retrievedContext != null) {\n      // Handle retrievedContext chunks from RAG operations\n      const uri = chunk.retrievedContext.uri;\n      const fileSearchStore = chunk.retrievedContext.fileSearchStore;\n\n      if (uri && (uri.startsWith('http://') || uri.startsWith('https://'))) {\n        // Old format: Google Search with HTTP/HTTPS URL\n        sources.push({\n          type: 'source',\n          sourceType: 'url',\n          id: generateId(),\n          url: uri,\n          title: chunk.retrievedContext.title ?? undefined,\n        });\n      } else if (uri) {\n        // Old format: Document with file path (gs://, etc.)\n        const title = chunk.retrievedContext.title ?? 'Unknown Document';\n        let mediaType = 'application/octet-stream';\n        let filename: string | undefined = undefined;\n\n        if (uri.endsWith('.pdf')) {\n          mediaType = 'application/pdf';\n          filename = uri.split('/').pop();\n        } else if (uri.endsWith('.txt')) {\n          mediaType = 'text/plain';\n          filename = uri.split('/').pop();\n        } else if (uri.endsWith('.docx')) {\n          mediaType =\n            'application/vnd.openxmlformats-officedocument.wordprocessingml.document';\n          filename = uri.split('/').pop();\n        } else if (uri.endsWith('.doc')) {\n          mediaType = 'application/msword';\n          filename = uri.split('/').pop();\n        } else if (uri.match(/\\.(md|markdown)$/)) {\n          mediaType = 'text/markdown';\n          filename = uri.split('/').pop();\n        } else {\n          filename = uri.split('/').pop();\n        }\n\n        sources.push({\n          type: 'source',\n          sourceType: 'document',\n          id: generateId(),\n          mediaType,\n          title,\n          filename,\n        });\n      } else if (fileSearchStore) {\n        // New format: File Search with fileSearchStore (no uri)\n        const title = chunk.retrievedContext.title ?? 'Unknown Document';\n        sources.push({\n          type: 'source',\n          sourceType: 'document',\n          id: generateId(),\n          mediaType: 'application/octet-stream',\n          title,\n          filename: fileSearchStore.split('/').pop(),\n        });\n      }\n    } else if (chunk.maps != null) {\n      if (chunk.maps.uri) {\n        sources.push({\n          type: 'source',\n          sourceType: 'url',\n          id: generateId(),\n          url: chunk.maps.uri,\n          title: chunk.maps.title ?? undefined,\n        });\n      }\n    }\n  }\n\n  return sources.length > 0 ? sources : undefined;\n}\n\nexport const getGroundingMetadataSchema = () =>\n  z.object({\n    webSearchQueries: z.array(z.string()).nullish(),\n    retrievalQueries: z.array(z.string()).nullish(),\n    searchEntryPoint: z.object({ renderedContent: z.string() }).nullish(),\n    groundingChunks: z\n      .array(\n        z.object({\n          web: z\n            .object({ uri: z.string(), title: z.string().nullish() })\n            .nullish(),\n          retrievedContext: z\n            .object({\n              uri: z.string().nullish(),\n              title: z.string().nullish(),\n              text: z.string().nullish(),\n              fileSearchStore: z.string().nullish(),\n            })\n            .nullish(),\n          maps: z\n            .object({\n              uri: z.string().nullish(),\n              title: z.string().nullish(),\n              text: z.string().nullish(),\n              placeId: z.string().nullish(),\n            })\n            .nullish(),\n        }),\n      )\n      .nullish(),\n    groundingSupports: z\n      .array(\n        z.object({\n          segment: z.object({\n            startIndex: z.number().nullish(),\n            endIndex: z.number().nullish(),\n            text: z.string().nullish(),\n          }),\n          segment_text: z.string().nullish(),\n          groundingChunkIndices: z.array(z.number()).nullish(),\n          supportChunkIndices: z.array(z.number()).nullish(),\n          confidenceScores: z.array(z.number()).nullish(),\n          confidenceScore: z.array(z.number()).nullish(),\n        }),\n      )\n      .nullish(),\n    retrievalMetadata: z\n      .union([\n        z.object({\n          webDynamicRetrievalScore: z.number(),\n        }),\n        z.object({}),\n      ])\n      .nullish(),\n  });\n\nconst getContentSchema = () =>\n  z.object({\n    parts: z\n      .array(\n        z.union([\n          // note: order matters since text can be fully empty\n          z.object({\n            functionCall: z.object({\n              name: z.string(),\n              args: z.unknown(),\n            }),\n            thoughtSignature: z.string().nullish(),\n          }),\n          z.object({\n            inlineData: z.object({\n              mimeType: z.string(),\n              data: z.string(),\n            }),\n            thoughtSignature: z.string().nullish(),\n          }),\n          z.object({\n            executableCode: z\n              .object({\n                language: z.string(),\n                code: z.string(),\n              })\n              .nullish(),\n            codeExecutionResult: z\n              .object({\n                outcome: z.string(),\n                output: z.string(),\n              })\n              .nullish(),\n            text: z.string().nullish(),\n            thought: z.boolean().nullish(),\n            thoughtSignature: z.string().nullish(),\n          }),\n        ]),\n      )\n      .nullish(),\n  });\n\n// https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters\nconst getSafetyRatingSchema = () =>\n  z.object({\n    category: z.string().nullish(),\n    probability: z.string().nullish(),\n    probabilityScore: z.number().nullish(),\n    severity: z.string().nullish(),\n    severityScore: z.number().nullish(),\n    blocked: z.boolean().nullish(),\n  });\n\nconst usageSchema = z.object({\n  cachedContentTokenCount: z.number().nullish(),\n  thoughtsTokenCount: z.number().nullish(),\n  promptTokenCount: z.number().nullish(),\n  candidatesTokenCount: z.number().nullish(),\n  totalTokenCount: z.number().nullish(),\n  // https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1/GenerateContentResponse#TrafficType\n  trafficType: z.string().nullish(),\n});\n\n// https://ai.google.dev/api/generate-content#UrlRetrievalMetadata\nexport const getUrlContextMetadataSchema = () =>\n  z.object({\n    urlMetadata: z.array(\n      z.object({\n        retrievedUrl: z.string(),\n        urlRetrievalStatus: z.string(),\n      }),\n    ),\n  });\n\nconst responseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      candidates: z.array(\n        z.object({\n          content: getContentSchema().nullish().or(z.object({}).strict()),\n          finishReason: z.string().nullish(),\n          safetyRatings: z.array(getSafetyRatingSchema()).nullish(),\n          groundingMetadata: getGroundingMetadataSchema().nullish(),\n          urlContextMetadata: getUrlContextMetadataSchema().nullish(),\n        }),\n      ),\n      usageMetadata: usageSchema.nullish(),\n      promptFeedback: z\n        .object({\n          blockReason: z.string().nullish(),\n          safetyRatings: z.array(getSafetyRatingSchema()).nullish(),\n        })\n        .nullish(),\n    }),\n  ),\n);\n\ntype ContentSchema = NonNullable<\n  InferSchema<typeof responseSchema>['candidates'][number]['content']\n>;\nexport type GroundingMetadataSchema = NonNullable<\n  InferSchema<typeof responseSchema>['candidates'][number]['groundingMetadata']\n>;\n\ntype GroundingChunkSchema = NonNullable<\n  GroundingMetadataSchema['groundingChunks']\n>[number];\n\nexport type UrlContextMetadataSchema = NonNullable<\n  InferSchema<typeof responseSchema>['candidates'][number]['urlContextMetadata']\n>;\n\nexport type SafetyRatingSchema = NonNullable<\n  InferSchema<typeof responseSchema>['candidates'][number]['safetyRatings']\n>[number];\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst chunkSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      candidates: z\n        .array(\n          z.object({\n            content: getContentSchema().nullish(),\n            finishReason: z.string().nullish(),\n            safetyRatings: z.array(getSafetyRatingSchema()).nullish(),\n            groundingMetadata: getGroundingMetadataSchema().nullish(),\n            urlContextMetadata: getUrlContextMetadataSchema().nullish(),\n          }),\n        )\n        .nullish(),\n      usageMetadata: usageSchema.nullish(),\n      promptFeedback: z\n        .object({\n          blockReason: z.string().nullish(),\n          safetyRatings: z.array(getSafetyRatingSchema()).nullish(),\n        })\n        .nullish(),\n    }),\n  ),\n);\n\ntype ChunkSchema = InferSchema<typeof chunkSchema>;\n","import { LanguageModelV3Usage } from '@ai-sdk/provider';\n\nexport type GoogleGenerativeAIUsageMetadata = {\n  promptTokenCount?: number | null;\n  candidatesTokenCount?: number | null;\n  totalTokenCount?: number | null;\n  cachedContentTokenCount?: number | null;\n  thoughtsTokenCount?: number | null;\n  trafficType?: string | null;\n};\n\nexport function convertGoogleGenerativeAIUsage(\n  usage: GoogleGenerativeAIUsageMetadata | undefined | null,\n): LanguageModelV3Usage {\n  if (usage == null) {\n    return {\n      inputTokens: {\n        total: undefined,\n        noCache: undefined,\n        cacheRead: undefined,\n        cacheWrite: undefined,\n      },\n      outputTokens: {\n        total: undefined,\n        text: undefined,\n        reasoning: undefined,\n      },\n      raw: undefined,\n    };\n  }\n\n  const promptTokens = usage.promptTokenCount ?? 0;\n  const candidatesTokens = usage.candidatesTokenCount ?? 0;\n  const cachedContentTokens = usage.cachedContentTokenCount ?? 0;\n  const thoughtsTokens = usage.thoughtsTokenCount ?? 0;\n\n  return {\n    inputTokens: {\n      total: promptTokens,\n      noCache: promptTokens - cachedContentTokens,\n      cacheRead: cachedContentTokens,\n      cacheWrite: undefined,\n    },\n    outputTokens: {\n      total: candidatesTokens + thoughtsTokens,\n      text: candidatesTokens,\n      reasoning: thoughtsTokens,\n    },\n    raw: usage,\n  };\n}\n","import { JSONSchema7Definition } from '@ai-sdk/provider';\n\n/**\n * Converts JSON Schema 7 to OpenAPI Schema 3.0\n */\nexport function convertJSONSchemaToOpenAPISchema(\n  jsonSchema: JSONSchema7Definition | undefined,\n  isRoot = true,\n): unknown {\n  // Handle empty object schemas: undefined at root, preserved when nested\n  if (jsonSchema == null) {\n    return undefined;\n  }\n\n  if (isEmptyObjectSchema(jsonSchema)) {\n    if (isRoot) {\n      return undefined;\n    }\n\n    if (typeof jsonSchema === 'object' && jsonSchema.description) {\n      return { type: 'object', description: jsonSchema.description };\n    }\n    return { type: 'object' };\n  }\n\n  if (typeof jsonSchema === 'boolean') {\n    return { type: 'boolean', properties: {} };\n  }\n\n  const {\n    type,\n    description,\n    required,\n    properties,\n    items,\n    allOf,\n    anyOf,\n    oneOf,\n    format,\n    const: constValue,\n    minLength,\n    enum: enumValues,\n  } = jsonSchema;\n\n  const result: Record<string, unknown> = {};\n\n  if (description) result.description = description;\n  if (required) result.required = required;\n  if (format) result.format = format;\n\n  if (constValue !== undefined) {\n    result.enum = [constValue];\n  }\n\n  // Handle type\n  if (type) {\n    if (Array.isArray(type)) {\n      const hasNull = type.includes('null');\n      const nonNullTypes = type.filter(t => t !== 'null');\n\n      if (nonNullTypes.length === 0) {\n        // Only null type\n        result.type = 'null';\n      } else {\n        // One or more non-null types: always use anyOf\n        result.anyOf = nonNullTypes.map(t => ({ type: t }));\n        if (hasNull) {\n          result.nullable = true;\n        }\n      }\n    } else {\n      result.type = type;\n    }\n  }\n\n  // Handle enum\n  if (enumValues !== undefined) {\n    result.enum = enumValues;\n  }\n\n  if (properties != null) {\n    result.properties = Object.entries(properties).reduce(\n      (acc, [key, value]) => {\n        acc[key] = convertJSONSchemaToOpenAPISchema(value, false);\n        return acc;\n      },\n      {} as Record<string, unknown>,\n    );\n  }\n\n  if (items) {\n    result.items = Array.isArray(items)\n      ? items.map(item => convertJSONSchemaToOpenAPISchema(item, false))\n      : convertJSONSchemaToOpenAPISchema(items, false);\n  }\n\n  if (allOf) {\n    result.allOf = allOf.map(item =>\n      convertJSONSchemaToOpenAPISchema(item, false),\n    );\n  }\n  if (anyOf) {\n    // Handle cases where anyOf includes a null type\n    if (\n      anyOf.some(\n        schema => typeof schema === 'object' && schema?.type === 'null',\n      )\n    ) {\n      const nonNullSchemas = anyOf.filter(\n        schema => !(typeof schema === 'object' && schema?.type === 'null'),\n      );\n\n      if (nonNullSchemas.length === 1) {\n        // If there's only one non-null schema, convert it and make it nullable\n        const converted = convertJSONSchemaToOpenAPISchema(\n          nonNullSchemas[0],\n          false,\n        );\n        if (typeof converted === 'object') {\n          result.nullable = true;\n          Object.assign(result, converted);\n        }\n      } else {\n        // If there are multiple non-null schemas, keep them in anyOf\n        result.anyOf = nonNullSchemas.map(item =>\n          convertJSONSchemaToOpenAPISchema(item, false),\n        );\n        result.nullable = true;\n      }\n    } else {\n      result.anyOf = anyOf.map(item =>\n        convertJSONSchemaToOpenAPISchema(item, false),\n      );\n    }\n  }\n  if (oneOf) {\n    result.oneOf = oneOf.map(item =>\n      convertJSONSchemaToOpenAPISchema(item, false),\n    );\n  }\n\n  if (minLength !== undefined) {\n    result.minLength = minLength;\n  }\n\n  return result;\n}\n\nfunction isEmptyObjectSchema(jsonSchema: JSONSchema7Definition): boolean {\n  return (\n    jsonSchema != null &&\n    typeof jsonSchema === 'object' &&\n    jsonSchema.type === 'object' &&\n    (jsonSchema.properties == null ||\n      Object.keys(jsonSchema.properties).length === 0) &&\n    !jsonSchema.additionalProperties\n  );\n}\n","import {\n  LanguageModelV3Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport {\n  GoogleGenerativeAIContent,\n  GoogleGenerativeAIContentPart,\n  GoogleGenerativeAIPrompt,\n} from './google-generative-ai-prompt';\nimport { convertToBase64 } from '@ai-sdk/provider-utils';\n\nexport function convertToGoogleGenerativeAIMessages(\n  prompt: LanguageModelV3Prompt,\n  options?: { isGemmaModel?: boolean; providerOptionsName?: string },\n): GoogleGenerativeAIPrompt {\n  const systemInstructionParts: Array<{ text: string }> = [];\n  const contents: Array<GoogleGenerativeAIContent> = [];\n  let systemMessagesAllowed = true;\n  const isGemmaModel = options?.isGemmaModel ?? false;\n  const providerOptionsName = options?.providerOptionsName ?? 'google';\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        if (!systemMessagesAllowed) {\n          throw new UnsupportedFunctionalityError({\n            functionality:\n              'system messages are only supported at the beginning of the conversation',\n          });\n        }\n\n        systemInstructionParts.push({ text: content });\n        break;\n      }\n\n      case 'user': {\n        systemMessagesAllowed = false;\n\n        const parts: GoogleGenerativeAIContentPart[] = [];\n\n        for (const part of content) {\n          switch (part.type) {\n            case 'text': {\n              parts.push({ text: part.text });\n              break;\n            }\n\n            case 'file': {\n              // default to image/jpeg for unknown image/* types\n              const mediaType =\n                part.mediaType === 'image/*' ? 'image/jpeg' : part.mediaType;\n\n              parts.push(\n                part.data instanceof URL\n                  ? {\n                      fileData: {\n                        mimeType: mediaType,\n                        fileUri: part.data.toString(),\n                      },\n                    }\n                  : {\n                      inlineData: {\n                        mimeType: mediaType,\n                        data: convertToBase64(part.data),\n                      },\n                    },\n              );\n\n              break;\n            }\n          }\n        }\n\n        contents.push({ role: 'user', parts });\n        break;\n      }\n\n      case 'assistant': {\n        systemMessagesAllowed = false;\n\n        contents.push({\n          role: 'model',\n          parts: content\n            .map(part => {\n              const providerOpts = part.providerOptions?.[providerOptionsName];\n              const thoughtSignature =\n                providerOpts?.thoughtSignature != null\n                  ? String(providerOpts.thoughtSignature)\n                  : undefined;\n\n              switch (part.type) {\n                case 'text': {\n                  return part.text.length === 0\n                    ? undefined\n                    : {\n                        text: part.text,\n                        thoughtSignature,\n                      };\n                }\n\n                case 'reasoning': {\n                  return part.text.length === 0\n                    ? undefined\n                    : {\n                        text: part.text,\n                        thought: true,\n                        thoughtSignature,\n                      };\n                }\n\n                case 'file': {\n                  if (part.data instanceof URL) {\n                    throw new UnsupportedFunctionalityError({\n                      functionality:\n                        'File data URLs in assistant messages are not supported',\n                    });\n                  }\n\n                  return {\n                    inlineData: {\n                      mimeType: part.mediaType,\n                      data: convertToBase64(part.data),\n                    },\n                    thoughtSignature,\n                  };\n                }\n\n                case 'tool-call': {\n                  return {\n                    functionCall: {\n                      name: part.toolName,\n                      args: part.input,\n                    },\n                    thoughtSignature,\n                  };\n                }\n              }\n            })\n            .filter(part => part !== undefined),\n        });\n        break;\n      }\n\n      case 'tool': {\n        systemMessagesAllowed = false;\n\n        const parts: GoogleGenerativeAIContentPart[] = [];\n\n        for (const part of content) {\n          if (part.type === 'tool-approval-response') {\n            continue;\n          }\n          const output = part.output;\n\n          if (output.type === 'content') {\n            for (const contentPart of output.value) {\n              switch (contentPart.type) {\n                case 'text':\n                  parts.push({\n                    functionResponse: {\n                      name: part.toolName,\n                      response: {\n                        name: part.toolName,\n                        content: contentPart.text,\n                      },\n                    },\n                  });\n                  break;\n                case 'image-data':\n                  parts.push(\n                    {\n                      inlineData: {\n                        mimeType: contentPart.mediaType,\n                        data: contentPart.data,\n                      },\n                    },\n                    {\n                      text: 'Tool executed successfully and returned this image as a response',\n                    },\n                  );\n                  break;\n                default:\n                  parts.push({ text: JSON.stringify(contentPart) });\n                  break;\n              }\n            }\n          } else {\n            parts.push({\n              functionResponse: {\n                name: part.toolName,\n                response: {\n                  name: part.toolName,\n                  content:\n                    output.type === 'execution-denied'\n                      ? (output.reason ?? 'Tool execution denied.')\n                      : output.value,\n                },\n              },\n            });\n          }\n        }\n\n        contents.push({\n          role: 'user',\n          parts,\n        });\n        break;\n      }\n    }\n  }\n\n  if (\n    isGemmaModel &&\n    systemInstructionParts.length > 0 &&\n    contents.length > 0 &&\n    contents[0].role === 'user'\n  ) {\n    const systemText = systemInstructionParts\n      .map(part => part.text)\n      .join('\\n\\n');\n\n    contents[0].parts.unshift({ text: systemText + '\\n\\n' });\n  }\n\n  return {\n    systemInstruction:\n      systemInstructionParts.length > 0 && !isGemmaModel\n        ? { parts: systemInstructionParts }\n        : undefined,\n    contents,\n  };\n}\n","export function getModelPath(modelId: string): string {\n  return modelId.includes('/') ? modelId : `models/${modelId}`;\n}\n","import { InferSchema, lazySchema, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport type GoogleGenerativeAIModelId =\n  // Stable models\n  // https://ai.google.dev/gemini-api/docs/models/gemini\n  | 'gemini-1.5-flash'\n  | 'gemini-1.5-flash-latest'\n  | 'gemini-1.5-flash-001'\n  | 'gemini-1.5-flash-002'\n  | 'gemini-1.5-flash-8b'\n  | 'gemini-1.5-flash-8b-latest'\n  | 'gemini-1.5-flash-8b-001'\n  | 'gemini-1.5-pro'\n  | 'gemini-1.5-pro-latest'\n  | 'gemini-1.5-pro-001'\n  | 'gemini-1.5-pro-002'\n  | 'gemini-2.0-flash'\n  | 'gemini-2.0-flash-001'\n  | 'gemini-2.0-flash-live-001'\n  | 'gemini-2.0-flash-lite'\n  | 'gemini-2.0-pro-exp-02-05'\n  | 'gemini-2.0-flash-thinking-exp-01-21'\n  | 'gemini-2.0-flash-exp'\n  | 'gemini-2.5-pro'\n  | 'gemini-2.5-flash'\n  | 'gemini-2.5-flash-image-preview'\n  | 'gemini-2.5-flash-lite'\n  | 'gemini-2.5-flash-lite-preview-09-2025'\n  | 'gemini-2.5-flash-preview-04-17'\n  | 'gemini-2.5-flash-preview-09-2025'\n  | 'gemini-3-pro-preview'\n  | 'gemini-3-pro-image-preview'\n  | 'gemini-3-flash-preview'\n  // latest version\n  // https://ai.google.dev/gemini-api/docs/models#latest\n  | 'gemini-pro-latest'\n  | 'gemini-flash-latest'\n  | 'gemini-flash-lite-latest'\n  // Experimental models\n  // https://ai.google.dev/gemini-api/docs/models/experimental-models\n  | 'gemini-2.5-pro-exp-03-25'\n  | 'gemini-exp-1206'\n  | 'gemma-3-12b-it'\n  | 'gemma-3-27b-it'\n  | (string & {});\n\nexport const googleGenerativeAIProviderOptions = lazySchema(() =>\n  zodSchema(\n    z.object({\n      responseModalities: z.array(z.enum(['TEXT', 'IMAGE'])).optional(),\n\n      thinkingConfig: z\n        .object({\n          thinkingBudget: z.number().optional(),\n          includeThoughts: z.boolean().optional(),\n          // https://ai.google.dev/gemini-api/docs/gemini-3?thinking=high#thinking_level\n          thinkingLevel: z\n            .enum(['minimal', 'low', 'medium', 'high'])\n            .optional(),\n        })\n        .optional(),\n\n      /**\n       * Optional.\n       * The name of the cached content used as context to serve the prediction.\n       * Format: cachedContents/{cachedContent}\n       */\n      cachedContent: z.string().optional(),\n\n      /**\n       * Optional. Enable structured output. Default is true.\n       *\n       * This is useful when the JSON Schema contains elements that are\n       * not supported by the OpenAPI schema version that\n       * Google Generative AI uses. You can use this to disable\n       * structured outputs if you need to.\n       */\n      structuredOutputs: z.boolean().optional(),\n\n      /**\n       * Optional. A list of unique safety settings for blocking unsafe content.\n       */\n      safetySettings: z\n        .array(\n          z.object({\n            category: z.enum([\n              'HARM_CATEGORY_UNSPECIFIED',\n              'HARM_CATEGORY_HATE_SPEECH',\n              'HARM_CATEGORY_DANGEROUS_CONTENT',\n              'HARM_CATEGORY_HARASSMENT',\n              'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n              'HARM_CATEGORY_CIVIC_INTEGRITY',\n            ]),\n            threshold: z.enum([\n              'HARM_BLOCK_THRESHOLD_UNSPECIFIED',\n              'BLOCK_LOW_AND_ABOVE',\n              'BLOCK_MEDIUM_AND_ABOVE',\n              'BLOCK_ONLY_HIGH',\n              'BLOCK_NONE',\n              'OFF',\n            ]),\n          }),\n        )\n        .optional(),\n\n      threshold: z\n        .enum([\n          'HARM_BLOCK_THRESHOLD_UNSPECIFIED',\n          'BLOCK_LOW_AND_ABOVE',\n          'BLOCK_MEDIUM_AND_ABOVE',\n          'BLOCK_ONLY_HIGH',\n          'BLOCK_NONE',\n          'OFF',\n        ])\n        .optional(),\n\n      /**\n       * Optional. Enables timestamp understanding for audio-only files.\n       *\n       * https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/audio-understanding\n       */\n      audioTimestamp: z.boolean().optional(),\n\n      /**\n       * Optional. Defines labels used in billing reports. Available on Vertex AI only.\n       *\n       * https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/add-labels-to-api-calls\n       */\n      labels: z.record(z.string(), z.string()).optional(),\n\n      /**\n       * Optional. If specified, the media resolution specified will be used.\n       *\n       * https://ai.google.dev/api/generate-content#MediaResolution\n       */\n      mediaResolution: z\n        .enum([\n          'MEDIA_RESOLUTION_UNSPECIFIED',\n          'MEDIA_RESOLUTION_LOW',\n          'MEDIA_RESOLUTION_MEDIUM',\n          'MEDIA_RESOLUTION_HIGH',\n        ])\n        .optional(),\n\n      /**\n       * Optional. Configures the image generation aspect ratio for Gemini models.\n       *\n       * https://ai.google.dev/gemini-api/docs/image-generation#aspect_ratios\n       */\n      imageConfig: z\n        .object({\n          aspectRatio: z\n            .enum([\n              '1:1',\n              '2:3',\n              '3:2',\n              '3:4',\n              '4:3',\n              '4:5',\n              '5:4',\n              '9:16',\n              '16:9',\n              '21:9',\n            ])\n            .optional(),\n          imageSize: z.enum(['1K', '2K', '4K']).optional(),\n        })\n        .optional(),\n\n      /**\n       * Optional. Configuration for grounding retrieval.\n       * Used to provide location context for Google Maps and Google Search grounding.\n       *\n       * https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-maps\n       */\n      retrievalConfig: z\n        .object({\n          latLng: z\n            .object({\n              latitude: z.number(),\n              longitude: z.number(),\n            })\n            .optional(),\n        })\n        .optional(),\n    }),\n  ),\n);\n\nexport type GoogleGenerativeAIProviderOptions = InferSchema<\n  typeof googleGenerativeAIProviderOptions\n>;\n","import {\n  LanguageModelV3CallOptions,\n  SharedV3Warning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { convertJSONSchemaToOpenAPISchema } from './convert-json-schema-to-openapi-schema';\nimport { GoogleGenerativeAIModelId } from './google-generative-ai-options';\n\nexport function prepareTools({\n  tools,\n  toolChoice,\n  modelId,\n}: {\n  tools: LanguageModelV3CallOptions['tools'];\n  toolChoice?: LanguageModelV3CallOptions['toolChoice'];\n  modelId: GoogleGenerativeAIModelId;\n}): {\n  tools:\n    | Array<\n        | {\n            functionDeclarations: Array<{\n              name: string;\n              description: string;\n              parameters: unknown;\n            }>;\n          }\n        | Record<string, any>\n      >\n    | undefined;\n  toolConfig:\n    | undefined\n    | {\n        functionCallingConfig: {\n          mode: 'AUTO' | 'NONE' | 'ANY';\n          allowedFunctionNames?: string[];\n        };\n      };\n  toolWarnings: SharedV3Warning[];\n} {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  tools = tools?.length ? tools : undefined;\n\n  const toolWarnings: SharedV3Warning[] = [];\n\n  const isLatest = (\n    [\n      'gemini-flash-latest',\n      'gemini-flash-lite-latest',\n      'gemini-pro-latest',\n    ] as const satisfies GoogleGenerativeAIModelId[]\n  ).some(id => id === modelId);\n  const isGemini2orNewer =\n    modelId.includes('gemini-2') || modelId.includes('gemini-3') || isLatest;\n  const supportsDynamicRetrieval =\n    modelId.includes('gemini-1.5-flash') && !modelId.includes('-8b');\n  const supportsFileSearch = modelId.includes('gemini-2.5');\n\n  if (tools == null) {\n    return { tools: undefined, toolConfig: undefined, toolWarnings };\n  }\n\n  // Check for mixed tool types and add warnings\n  const hasFunctionTools = tools.some(tool => tool.type === 'function');\n  const hasProviderTools = tools.some(tool => tool.type === 'provider');\n\n  if (hasFunctionTools && hasProviderTools) {\n    toolWarnings.push({\n      type: 'unsupported',\n      feature: `combination of function and provider-defined tools`,\n    });\n  }\n\n  if (hasProviderTools) {\n    const googleTools: any[] = [];\n\n    const ProviderTools = tools.filter(tool => tool.type === 'provider');\n    ProviderTools.forEach(tool => {\n      switch (tool.id) {\n        case 'google.google_search':\n          if (isGemini2orNewer) {\n            googleTools.push({ googleSearch: {} });\n          } else if (supportsDynamicRetrieval) {\n            // For non-Gemini-2 models that don't support dynamic retrieval, use basic googleSearchRetrieval\n            googleTools.push({\n              googleSearchRetrieval: {\n                dynamicRetrievalConfig: {\n                  mode: tool.args.mode as\n                    | 'MODE_DYNAMIC'\n                    | 'MODE_UNSPECIFIED'\n                    | undefined,\n                  dynamicThreshold: tool.args.dynamicThreshold as\n                    | number\n                    | undefined,\n                },\n              },\n            });\n          } else {\n            googleTools.push({ googleSearchRetrieval: {} });\n          }\n          break;\n        case 'google.enterprise_web_search':\n          if (isGemini2orNewer) {\n            googleTools.push({ enterpriseWebSearch: {} });\n          } else {\n            toolWarnings.push({\n              type: 'unsupported',\n              feature: `provider-defined tool ${tool.id}`,\n              details: 'Enterprise Web Search requires Gemini 2.0 or newer.',\n            });\n          }\n          break;\n        case 'google.url_context':\n          if (isGemini2orNewer) {\n            googleTools.push({ urlContext: {} });\n          } else {\n            toolWarnings.push({\n              type: 'unsupported',\n              feature: `provider-defined tool ${tool.id}`,\n              details:\n                'The URL context tool is not supported with other Gemini models than Gemini 2.',\n            });\n          }\n          break;\n        case 'google.code_execution':\n          if (isGemini2orNewer) {\n            googleTools.push({ codeExecution: {} });\n          } else {\n            toolWarnings.push({\n              type: 'unsupported',\n              feature: `provider-defined tool ${tool.id}`,\n              details:\n                'The code execution tools is not supported with other Gemini models than Gemini 2.',\n            });\n          }\n          break;\n        case 'google.file_search':\n          if (supportsFileSearch) {\n            googleTools.push({ fileSearch: { ...tool.args } });\n          } else {\n            toolWarnings.push({\n              type: 'unsupported',\n              feature: `provider-defined tool ${tool.id}`,\n              details:\n                'The file search tool is only supported with Gemini 2.5 models.',\n            });\n          }\n          break;\n        case 'google.vertex_rag_store':\n          if (isGemini2orNewer) {\n            googleTools.push({\n              retrieval: {\n                vertex_rag_store: {\n                  rag_resources: {\n                    rag_corpus: tool.args.ragCorpus,\n                  },\n                  similarity_top_k: tool.args.topK as number | undefined,\n                },\n              },\n            });\n          } else {\n            toolWarnings.push({\n              type: 'unsupported',\n              feature: `provider-defined tool ${tool.id}`,\n              details:\n                'The RAG store tool is not supported with other Gemini models than Gemini 2.',\n            });\n          }\n          break;\n        case 'google.google_maps':\n          if (isGemini2orNewer) {\n            googleTools.push({ googleMaps: {} });\n          } else {\n            toolWarnings.push({\n              type: 'unsupported',\n              feature: `provider-defined tool ${tool.id}`,\n              details:\n                'The Google Maps grounding tool is not supported with Gemini models other than Gemini 2 or newer.',\n            });\n          }\n          break;\n        default:\n          toolWarnings.push({\n            type: 'unsupported',\n            feature: `provider-defined tool ${tool.id}`,\n          });\n          break;\n      }\n    });\n\n    return {\n      tools: googleTools.length > 0 ? googleTools : undefined,\n      toolConfig: undefined,\n      toolWarnings,\n    };\n  }\n\n  const functionDeclarations = [];\n  for (const tool of tools) {\n    switch (tool.type) {\n      case 'function':\n        functionDeclarations.push({\n          name: tool.name,\n          description: tool.description ?? '',\n          parameters: convertJSONSchemaToOpenAPISchema(tool.inputSchema),\n        });\n        break;\n      default:\n        toolWarnings.push({\n          type: 'unsupported',\n          feature: `function tool ${tool.name}`,\n        });\n        break;\n    }\n  }\n\n  if (toolChoice == null) {\n    return {\n      tools: [{ functionDeclarations }],\n      toolConfig: undefined,\n      toolWarnings,\n    };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n      return {\n        tools: [{ functionDeclarations }],\n        toolConfig: { functionCallingConfig: { mode: 'AUTO' } },\n        toolWarnings,\n      };\n    case 'none':\n      return {\n        tools: [{ functionDeclarations }],\n        toolConfig: { functionCallingConfig: { mode: 'NONE' } },\n        toolWarnings,\n      };\n    case 'required':\n      return {\n        tools: [{ functionDeclarations }],\n        toolConfig: { functionCallingConfig: { mode: 'ANY' } },\n        toolWarnings,\n      };\n    case 'tool':\n      return {\n        tools: [{ functionDeclarations }],\n        toolConfig: {\n          functionCallingConfig: {\n            mode: 'ANY',\n            allowedFunctionNames: [toolChoice.toolName],\n          },\n        },\n        toolWarnings,\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new UnsupportedFunctionalityError({\n        functionality: `tool choice type: ${_exhaustiveCheck}`,\n      });\n    }\n  }\n}\n","import { LanguageModelV3FinishReason } from '@ai-sdk/provider';\n\nexport function mapGoogleGenerativeAIFinishReason({\n  finishReason,\n  hasToolCalls,\n}: {\n  finishReason: string | null | undefined;\n  hasToolCalls: boolean;\n}): LanguageModelV3FinishReason['unified'] {\n  switch (finishReason) {\n    case 'STOP':\n      return hasToolCalls ? 'tool-calls' : 'stop';\n    case 'MAX_TOKENS':\n      return 'length';\n    case 'IMAGE_SAFETY':\n    case 'RECITATION':\n    case 'SAFETY':\n    case 'BLOCKLIST':\n    case 'PROHIBITED_CONTENT':\n    case 'SPII':\n      return 'content-filter';\n    case 'MALFORMED_FUNCTION_CALL':\n      return 'error';\n    case 'FINISH_REASON_UNSPECIFIED':\n    case 'OTHER':\n    default:\n      return 'other';\n  }\n}\n","import { createProviderToolFactoryWithOutputSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n/**\n * A tool that enables the model to generate and run Python code.\n *\n * @note Ensure the selected model supports Code Execution.\n * Multi-tool usage with the code execution tool is typically compatible with Gemini >=2 models.\n *\n * @see https://ai.google.dev/gemini-api/docs/code-execution (Google AI)\n * @see https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/code-execution-api (Vertex AI)\n */\nexport const codeExecution = createProviderToolFactoryWithOutputSchema<\n  {\n    language: string;\n    code: string;\n  },\n  {\n    outcome: string;\n    output: string;\n  },\n  {}\n>({\n  id: 'google.code_execution',\n  inputSchema: z.object({\n    language: z.string().describe('The programming language of the code.'),\n    code: z.string().describe('The code to be executed.'),\n  }),\n  outputSchema: z.object({\n    outcome: z\n      .string()\n      .describe('The outcome of the execution (e.g., \"OUTCOME_OK\").'),\n    output: z.string().describe('The output from the code execution.'),\n  }),\n});\n","import {\n  createProviderToolFactory,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/web-grounding-enterprise\n\nexport const enterpriseWebSearch = createProviderToolFactory<\n  {\n    // Enterprise Web Search does not have any input schema\n  },\n  {}\n>({\n  id: 'google.enterprise_web_search',\n  inputSchema: lazySchema(() => zodSchema(z.object({}))),\n});\n","import {\n  createProviderToolFactory,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n/** Tool to retrieve knowledge from the File Search Stores. */\nconst fileSearchArgsBaseSchema = z\n  .object({\n    /** The names of the file_search_stores to retrieve from.\n     *  Example: `fileSearchStores/my-file-search-store-123`\n     */\n    fileSearchStoreNames: z\n      .array(z.string())\n      .describe(\n        'The names of the file_search_stores to retrieve from. Example: `fileSearchStores/my-file-search-store-123`',\n      ),\n    /** The number of file search retrieval chunks to retrieve. */\n    topK: z\n      .number()\n      .int()\n      .positive()\n      .describe('The number of file search retrieval chunks to retrieve.')\n      .optional(),\n\n    /** Metadata filter to apply to the file search retrieval documents.\n     *  See https://google.aip.dev/160 for the syntax of the filter expression.\n     */\n    metadataFilter: z\n      .string()\n      .describe(\n        'Metadata filter to apply to the file search retrieval documents. See https://google.aip.dev/160 for the syntax of the filter expression.',\n      )\n      .optional(),\n  })\n  .passthrough();\n\nexport type GoogleFileSearchToolArgs = z.infer<typeof fileSearchArgsBaseSchema>;\n\nconst fileSearchArgsSchema = lazySchema(() =>\n  zodSchema(fileSearchArgsBaseSchema),\n);\n\nexport const fileSearch = createProviderToolFactory<\n  {},\n  GoogleFileSearchToolArgs\n>({\n  id: 'google.file_search',\n  inputSchema: fileSearchArgsSchema,\n});\n","import {\n  createProviderToolFactory,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// https://ai.google.dev/gemini-api/docs/maps-grounding\n// https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-maps\n\nexport const googleMaps = createProviderToolFactory<{}, {}>({\n  id: 'google.google_maps',\n  inputSchema: lazySchema(() => zodSchema(z.object({}))),\n});\n","import {\n  createProviderToolFactory,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// https://ai.google.dev/gemini-api/docs/google-search\n// https://ai.google.dev/api/generate-content#GroundingSupport\n// https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-search\n\nexport const googleSearch = createProviderToolFactory<\n  {},\n  {\n    /**\n     * The mode of the predictor to be used in dynamic retrieval. The following modes are supported:\n     *  - MODE_DYNAMIC: Run retrieval only when system decides it is necessary\n     *  - MODE_UNSPECIFIED: Always trigger retrieval\n     * @default MODE_UNSPECIFIED\n     */\n    mode?: 'MODE_DYNAMIC' | 'MODE_UNSPECIFIED';\n\n    /**\n     * The threshold to be used in dynamic retrieval (if not set, a system default value is used).\n     */\n    dynamicThreshold?: number;\n  }\n>({\n  id: 'google.google_search',\n  inputSchema: lazySchema(() =>\n    zodSchema(\n      z.object({\n        mode: z\n          .enum(['MODE_DYNAMIC', 'MODE_UNSPECIFIED'])\n          .default('MODE_UNSPECIFIED'),\n        dynamicThreshold: z.number().default(1),\n      }),\n    ),\n  ),\n});\n","import {\n  createProviderToolFactory,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const urlContext = createProviderToolFactory<\n  {\n    // Url context does not have any input schema, it will directly use the url from the prompt\n  },\n  {}\n>({\n  id: 'google.url_context',\n  inputSchema: lazySchema(() => zodSchema(z.object({}))),\n});\n","import { createProviderToolFactory } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-vertexai-search#generate-content-using-gemini-api\n// https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/rag-output-explained\n\n/**\n * A tool that enables the model to perform RAG searches against a Vertex RAG Store.\n *\n * @note Only works with Vertex Gemini models.\n */\nexport const vertexRagStore = createProviderToolFactory<\n  {},\n  {\n    /**\n     * RagCorpus resource names, eg: projects/{project}/locations/{location}/ragCorpora/{rag_corpus}\n     */\n    ragCorpus: string;\n\n    /**\n     * The number of top contexts to retrieve.\n     */\n    topK?: number;\n  }\n>({\n  id: 'google.vertex_rag_store',\n  inputSchema: z.object({\n    ragCorpus: z.string(),\n    topK: z.number().optional(),\n  }),\n});\n","import { codeExecution } from './tool/code-execution';\nimport { enterpriseWebSearch } from './tool/enterprise-web-search';\nimport { fileSearch } from './tool/file-search';\nimport { googleMaps } from './tool/google-maps';\nimport { googleSearch } from './tool/google-search';\nimport { urlContext } from './tool/url-context';\nimport { vertexRagStore } from './tool/vertex-rag-store';\n\nexport const googleTools = {\n  /**\n   * Creates a Google search tool that gives Google direct access to real-time web content.\n   * Must have name \"google_search\".\n   */\n  googleSearch,\n\n  /**\n   * Creates an Enterprise Web Search tool for grounding responses using a compliance-focused web index.\n   * Designed for highly-regulated industries (finance, healthcare, public sector).\n   * Does not log customer data and supports VPC service controls.\n   * Must have name \"enterprise_web_search\".\n   *\n   * @note Only available on Vertex AI. Requires Gemini 2.0 or newer.\n   *\n   * @see https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/web-grounding-enterprise\n   */\n  enterpriseWebSearch,\n\n  /**\n   * Creates a Google Maps grounding tool that gives the model access to Google Maps data.\n   * Must have name \"google_maps\".\n   *\n   * @see https://ai.google.dev/gemini-api/docs/maps-grounding\n   * @see https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-maps\n   */\n  googleMaps,\n\n  /**\n   * Creates a URL context tool that gives Google direct access to real-time web content.\n   * Must have name \"url_context\".\n   */\n  urlContext,\n\n  /**\n   * Enables Retrieval Augmented Generation (RAG) via the Gemini File Search tool.\n   * Must have name \"file_search\".\n   *\n   * @param fileSearchStoreNames - Fully-qualified File Search store resource names.\n   * @param metadataFilter - Optional filter expression to restrict the files that can be retrieved.\n   * @param topK - Optional result limit for the number of chunks returned from File Search.\n   *\n   * @see https://ai.google.dev/gemini-api/docs/file-search\n   */\n  fileSearch,\n  /**\n   * A tool that enables the model to generate and run Python code.\n   * Must have name \"code_execution\".\n   *\n   * @note Ensure the selected model supports Code Execution.\n   * Multi-tool usage with the code execution tool is typically compatible with Gemini >=2 models.\n   *\n   * @see https://ai.google.dev/gemini-api/docs/code-execution (Google AI)\n   * @see https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/code-execution-api (Vertex AI)\n   */\n  codeExecution,\n\n  /**\n   * Creates a Vertex RAG Store tool that enables the model to perform RAG searches against a Vertex RAG Store.\n   * Must have name \"vertex_rag_store\".\n   */\n  vertexRagStore,\n};\n","import { ImageModelV3, SharedV3Warning } from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  type InferSchema,\n  lazySchema,\n  parseProviderOptions,\n  postJsonToApi,\n  resolve,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { googleFailedResponseHandler } from './google-error';\nimport {\n  GoogleGenerativeAIImageModelId,\n  GoogleGenerativeAIImageSettings,\n} from './google-generative-ai-image-settings';\nimport { FetchFunction, Resolvable } from '@ai-sdk/provider-utils';\n\ninterface GoogleGenerativeAIImageModelConfig {\n  provider: string;\n  baseURL: string;\n  headers?: Resolvable<Record<string, string | undefined>>;\n  fetch?: FetchFunction;\n  generateId?: () => string;\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\nexport class GoogleGenerativeAIImageModel implements ImageModelV3 {\n  readonly specificationVersion = 'v3';\n\n  get maxImagesPerCall(): number {\n    // https://ai.google.dev/gemini-api/docs/imagen#imagen-model\n    return this.settings.maxImagesPerCall ?? 4;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: GoogleGenerativeAIImageModelId,\n    private readonly settings: GoogleGenerativeAIImageSettings,\n    private readonly config: GoogleGenerativeAIImageModelConfig,\n  ) {}\n\n  async doGenerate(\n    options: Parameters<ImageModelV3['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<ImageModelV3['doGenerate']>>> {\n    const {\n      prompt,\n      n = 1,\n      size,\n      aspectRatio = '1:1',\n      seed,\n      providerOptions,\n      headers,\n      abortSignal,\n      files,\n      mask,\n    } = options;\n    const warnings: Array<SharedV3Warning> = [];\n\n    // Google Generative AI does not support image editing\n    if (files != null && files.length > 0) {\n      throw new Error(\n        'Google Generative AI does not support image editing. ' +\n          'Use Google Vertex AI (@ai-sdk/google-vertex) for image editing capabilities.',\n      );\n    }\n\n    if (mask != null) {\n      throw new Error(\n        'Google Generative AI does not support image editing with masks. ' +\n          'Use Google Vertex AI (@ai-sdk/google-vertex) for image editing capabilities.',\n      );\n    }\n\n    if (size != null) {\n      warnings.push({\n        type: 'unsupported',\n        feature: 'size',\n        details:\n          'This model does not support the `size` option. Use `aspectRatio` instead.',\n      });\n    }\n\n    if (seed != null) {\n      warnings.push({\n        type: 'unsupported',\n        feature: 'seed',\n        details:\n          'This model does not support the `seed` option through this provider.',\n      });\n    }\n\n    const googleOptions = await parseProviderOptions({\n      provider: 'google',\n      providerOptions,\n      schema: googleImageProviderOptionsSchema,\n    });\n\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n\n    const parameters: Record<string, unknown> = {\n      sampleCount: n,\n    };\n\n    if (aspectRatio != null) {\n      parameters.aspectRatio = aspectRatio;\n    }\n\n    if (googleOptions) {\n      Object.assign(parameters, googleOptions);\n    }\n\n    const body = {\n      instances: [{ prompt }],\n      parameters,\n    };\n\n    const { responseHeaders, value: response } = await postJsonToApi<{\n      predictions: Array<{ bytesBase64Encoded: string }>;\n    }>({\n      url: `${this.config.baseURL}/models/${this.modelId}:predict`,\n      headers: combineHeaders(await resolve(this.config.headers), headers),\n      body,\n      failedResponseHandler: googleFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        googleImageResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n    return {\n      images: response.predictions.map(\n        (p: { bytesBase64Encoded: string }) => p.bytesBase64Encoded,\n      ),\n      warnings: warnings ?? [],\n      providerMetadata: {\n        google: {\n          images: response.predictions.map(prediction => ({\n            // Add any prediction-specific metadata here\n          })),\n        },\n      },\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n      },\n    };\n  }\n}\n\n// minimal version of the schema\nconst googleImageResponseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      predictions: z\n        .array(z.object({ bytesBase64Encoded: z.string() }))\n        .default([]),\n    }),\n  ),\n);\n\n// Note: For the initial GA launch of Imagen 3, safety filters are not configurable.\n// https://ai.google.dev/gemini-api/docs/imagen#imagen-model\nconst googleImageProviderOptionsSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      personGeneration: z\n        .enum(['dont_allow', 'allow_adult', 'allow_all'])\n        .nullish(),\n      aspectRatio: z.enum(['1:1', '3:4', '4:3', '9:16', '16:9']).nullish(),\n    }),\n  ),\n);\n\nexport type GoogleGenerativeAIImageProviderOptions = InferSchema<\n  typeof googleImageProviderOptionsSchema\n>;\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;AEcA,SAAS,KAAAA,UAAS;ACRlB,SAAS,SAAS;ACDlB,SAAS,KAAAC,UAAS;ACsBlB,SAAS,KAAAC,UAAS;AK1BlB,SAAS,KAAAC,UAAS;AGAlB,SAAS,KAAAC,UAAS;ACIlB,SAAS,KAAAC,UAAS;ACAlB,SAAS,KAAAC,UAAS;ACAlB,SAAS,KAAAC,UAAS;ACAlB,SAAS,KAAAC,WAAS;ACAlB,SAAS,KAAAC,WAAS;ACJlB,SAAS,KAAAC,WAAS;AEUlB,SAAS,KAAAC,WAAS;ApBTX,IAAM,UACX,OACI,UACA;AEGN,IAAM,wBAAwB;EAAW,MACvC;IACE,EAAE,OAAO;MACP,OAAO,EAAE,OAAO;QACd,MAAM,EAAE,OAAO,EAAE,SAAS;QAC1B,SAAS,EAAE,OAAO;QAClB,QAAQ,EAAE,OAAO;MACnB,CAAC;IACH,CAAC;EACH;AACF;AAIO,IAAM,8BAA8B,+BAA+B;EACxE,aAAa;EACb,gBAAgB,CAAA,SAAQ,KAAK,MAAM;AACrC,CAAC;ACbM,IAAM,6CAA6CC;EAAW,MACnEC;IACEF,GAAE,OAAO;;;;;MAKP,sBAAsBA,GAAE,OAAO,EAAE,SAAS;;;;;;;;;;;;;MAc1C,UAAUA,GACP,KAAK;QACJ;QACA;QACA;QACA;QACA;QACA;QACA;QACA;MACF,CAAC,EACA,SAAS;IACd,CAAC;EACH;AACF;AFnBO,IAAM,mCAAN,MAAmE;EAWxE,YACE,SACA,QACA;AAbF,SAAS,uBAAuB;AAEhC,SAAS,uBAAuB;AAChC,SAAS,wBAAwB;AAW/B,SAAK,UAAU;AACf,SAAK,SAAS;EAChB;EATA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EASA,MAAM,QAAQ;IACZ;IACA;IACA;IACA;EACF,GAEE;AAEA,UAAM,gBAAgB,MAAM,qBAAqB;MAC/C,UAAU;MACV;MACA,QAAQ;IACV,CAAC;AAED,QAAI,OAAO,SAAS,KAAK,sBAAsB;AAC7C,YAAM,IAAI,mCAAmC;QAC3C,UAAU,KAAK;QACf,SAAS,KAAK;QACd,sBAAsB,KAAK;QAC3B;MACF,CAAC;IACH;AAEA,UAAM,gBAAgB;MACpB,MAAM,QAAQ,KAAK,OAAO,OAAO;MACjC;IACF;AAGA,QAAI,OAAO,WAAW,GAAG;AACvB,YAAM;QACJ,iBAAAG;QACA,OAAOC;QACP,UAAAC;MACF,IAAI,MAAM,cAAc;QACtB,KAAK,GAAG,KAAK,OAAO,OAAO,WAAW,KAAK,OAAO;QAClD,SAAS;QACT,MAAM;UACJ,OAAO,UAAU,KAAK,OAAO;UAC7B,SAAS;YACP,OAAO,CAAC,EAAE,MAAM,OAAO,CAAC,EAAE,CAAC;UAC7B;UACA,sBAAsB,iBAAA,OAAA,SAAA,cAAe;UACrC,UAAU,iBAAA,OAAA,SAAA,cAAe;QAC3B;QACA,uBAAuB;QACvB,2BAA2B;UACzB;QACF;QACA;QACA,OAAO,KAAK,OAAO;MACrB,CAAC;AAED,aAAO;QACL,UAAU,CAAC;QACX,YAAY,CAACD,UAAS,UAAU,MAAM;QACtC,OAAO;QACP,UAAU,EAAE,SAASD,kBAAiB,MAAME,UAAS;MACvD;IACF;AAEA,UAAM;MACJ;MACA,OAAO;MACP;IACF,IAAI,MAAM,cAAc;MACtB,KAAK,GAAG,KAAK,OAAO,OAAO,WAAW,KAAK,OAAO;MAClD,SAAS;MACT,MAAM;QACJ,UAAU,OAAO,IAAI,CAAA,WAAU;UAC7B,OAAO,UAAU,KAAK,OAAO;UAC7B,SAAS,EAAE,MAAM,QAAQ,OAAO,CAAC,EAAE,MAAM,MAAM,CAAC,EAAE;UAClD,sBAAsB,iBAAA,OAAA,SAAA,cAAe;UACrC,UAAU,iBAAA,OAAA,SAAA,cAAe;QAC3B,EAAE;MACJ;MACA,uBAAuB;MACvB,2BAA2B;QACzB;MACF;MACA;MACA,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,WAAO;MACL,UAAU,CAAC;MACX,YAAY,SAAS,WAAW,IAAI,CAAA,SAAQ,KAAK,MAAM;MACvD,OAAO;MACP,UAAU,EAAE,SAAS,iBAAiB,MAAM,SAAS;IACvD;EACF;AACF;AAIA,IAAM,gDAAgDJ;EAAW,MAC/DC;IACEF,GAAE,OAAO;MACP,YAAYA,GAAE,MAAMA,GAAE,OAAO,EAAE,QAAQA,GAAE,MAAMA,GAAE,OAAO,CAAC,EAAE,CAAC,CAAC;IAC/D,CAAC;EACH;AACF;AAGA,IAAM,kDAAkDC;EAAW,MACjEC;IACEF,GAAE,OAAO;MACP,WAAWA,GAAE,OAAO,EAAE,QAAQA,GAAE,MAAMA,GAAE,OAAO,CAAC,EAAE,CAAC;IACrD,CAAC;EACH;AACF;AInJO,SAAS,+BACd,OACsB;AAbxB,MAAA,IAAA,IAAA,IAAA;AAcE,MAAI,SAAS,MAAM;AACjB,WAAO;MACL,aAAa;QACX,OAAO;QACP,SAAS;QACT,WAAW;QACX,YAAY;MACd;MACA,cAAc;QACZ,OAAO;QACP,MAAM;QACN,WAAW;MACb;MACA,KAAK;IACP;EACF;AAEA,QAAM,gBAAe,KAAA,MAAM,qBAAN,OAAA,KAA0B;AAC/C,QAAM,oBAAmB,KAAA,MAAM,yBAAN,OAAA,KAA8B;AACvD,QAAM,uBAAsB,KAAA,MAAM,4BAAN,OAAA,KAAiC;AAC7D,QAAM,kBAAiB,KAAA,MAAM,uBAAN,OAAA,KAA4B;AAEnD,SAAO;IACL,aAAa;MACX,OAAO;MACP,SAAS,eAAe;MACxB,WAAW;MACX,YAAY;IACd;IACA,cAAc;MACZ,OAAO,mBAAmB;MAC1B,MAAM;MACN,WAAW;IACb;IACA,KAAK;EACP;AACF;AC7CO,SAAS,iCACd,YACA,SAAS,MACA;AAET,MAAI,cAAc,MAAM;AACtB,WAAO;EACT;AAEA,MAAI,oBAAoB,UAAU,GAAG;AACnC,QAAI,QAAQ;AACV,aAAO;IACT;AAEA,QAAI,OAAO,eAAe,YAAY,WAAW,aAAa;AAC5D,aAAO,EAAE,MAAM,UAAU,aAAa,WAAW,YAAY;IAC/D;AACA,WAAO,EAAE,MAAM,SAAS;EAC1B;AAEA,MAAI,OAAO,eAAe,WAAW;AACnC,WAAO,EAAE,MAAM,WAAW,YAAY,CAAC,EAAE;EAC3C;AAEA,QAAM;IACJ;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA,OAAO;IACP;IACA,MAAM;EACR,IAAI;AAEJ,QAAM,SAAkC,CAAC;AAEzC,MAAI,YAAa,QAAO,cAAc;AACtC,MAAI,SAAU,QAAO,WAAW;AAChC,MAAI,OAAQ,QAAO,SAAS;AAE5B,MAAI,eAAe,QAAW;AAC5B,WAAO,OAAO,CAAC,UAAU;EAC3B;AAGA,MAAI,MAAM;AACR,QAAI,MAAM,QAAQ,IAAI,GAAG;AACvB,YAAM,UAAU,KAAK,SAAS,MAAM;AACpC,YAAM,eAAe,KAAK,OAAO,CAAA,MAAK,MAAM,MAAM;AAElD,UAAI,aAAa,WAAW,GAAG;AAE7B,eAAO,OAAO;MAChB,OAAO;AAEL,eAAO,QAAQ,aAAa,IAAI,CAAA,OAAM,EAAE,MAAM,EAAE,EAAE;AAClD,YAAI,SAAS;AACX,iBAAO,WAAW;QACpB;MACF;IACF,OAAO;AACL,aAAO,OAAO;IAChB;EACF;AAGA,MAAI,eAAe,QAAW;AAC5B,WAAO,OAAO;EAChB;AAEA,MAAI,cAAc,MAAM;AACtB,WAAO,aAAa,OAAO,QAAQ,UAAU,EAAE;MAC7C,CAAC,KAAK,CAAC,KAAK,KAAK,MAAM;AACrB,YAAI,GAAG,IAAI,iCAAiC,OAAO,KAAK;AACxD,eAAO;MACT;MACA,CAAC;IACH;EACF;AAEA,MAAI,OAAO;AACT,WAAO,QAAQ,MAAM,QAAQ,KAAK,IAC9B,MAAM,IAAI,CAAA,SAAQ,iCAAiC,MAAM,KAAK,CAAC,IAC/D,iCAAiC,OAAO,KAAK;EACnD;AAEA,MAAI,OAAO;AACT,WAAO,QAAQ,MAAM;MAAI,CAAA,SACvB,iCAAiC,MAAM,KAAK;IAC9C;EACF;AACA,MAAI,OAAO;AAET,QACE,MAAM;MACJ,CAAA,WAAU,OAAO,WAAW,aAAY,UAAA,OAAA,SAAA,OAAQ,UAAS;IAC3D,GACA;AACA,YAAM,iBAAiB,MAAM;QAC3B,CAAA,WAAU,EAAE,OAAO,WAAW,aAAY,UAAA,OAAA,SAAA,OAAQ,UAAS;MAC7D;AAEA,UAAI,eAAe,WAAW,GAAG;AAE/B,cAAM,YAAY;UAChB,eAAe,CAAC;UAChB;QACF;AACA,YAAI,OAAO,cAAc,UAAU;AACjC,iBAAO,WAAW;AAClB,iBAAO,OAAO,QAAQ,SAAS;QACjC;MACF,OAAO;AAEL,eAAO,QAAQ,eAAe;UAAI,CAAA,SAChC,iCAAiC,MAAM,KAAK;QAC9C;AACA,eAAO,WAAW;MACpB;IACF,OAAO;AACL,aAAO,QAAQ,MAAM;QAAI,CAAA,SACvB,iCAAiC,MAAM,KAAK;MAC9C;IACF;EACF;AACA,MAAI,OAAO;AACT,WAAO,QAAQ,MAAM;MAAI,CAAA,SACvB,iCAAiC,MAAM,KAAK;IAC9C;EACF;AAEA,MAAI,cAAc,QAAW;AAC3B,WAAO,YAAY;EACrB;AAEA,SAAO;AACT;AAEA,SAAS,oBAAoB,YAA4C;AACvE,SACE,cAAc,QACd,OAAO,eAAe,YACtB,WAAW,SAAS,aACnB,WAAW,cAAc,QACxB,OAAO,KAAK,WAAW,UAAU,EAAE,WAAW,MAChD,CAAC,WAAW;AAEhB;AClJO,SAAS,oCACd,QACA,SAC0B;AAd5B,MAAA,IAAA,IAAA;AAeE,QAAM,yBAAkD,CAAC;AACzD,QAAM,WAA6C,CAAC;AACpD,MAAI,wBAAwB;AAC5B,QAAM,gBAAe,KAAA,WAAA,OAAA,SAAA,QAAS,iBAAT,OAAA,KAAyB;AAC9C,QAAM,uBAAsB,KAAA,WAAA,OAAA,SAAA,QAAS,wBAAT,OAAA,KAAgC;AAE5D,aAAW,EAAE,MAAM,QAAQ,KAAK,QAAQ;AACtC,YAAQ,MAAM;MACZ,KAAK,UAAU;AACb,YAAI,CAAC,uBAAuB;AAC1B,gBAAM,IAAI,8BAA8B;YACtC,eACE;UACJ,CAAC;QACH;AAEA,+BAAuB,KAAK,EAAE,MAAM,QAAQ,CAAC;AAC7C;MACF;MAEA,KAAK,QAAQ;AACX,gCAAwB;AAExB,cAAM,QAAyC,CAAC;AAEhD,mBAAW,QAAQ,SAAS;AAC1B,kBAAQ,KAAK,MAAM;YACjB,KAAK,QAAQ;AACX,oBAAM,KAAK,EAAE,MAAM,KAAK,KAAK,CAAC;AAC9B;YACF;YAEA,KAAK,QAAQ;AAEX,oBAAM,YACJ,KAAK,cAAc,YAAY,eAAe,KAAK;AAErD,oBAAM;gBACJ,KAAK,gBAAgB,MACjB;kBACE,UAAU;oBACR,UAAU;oBACV,SAAS,KAAK,KAAK,SAAS;kBAC9B;gBACF,IACA;kBACE,YAAY;oBACV,UAAU;oBACV,MAAM,gBAAgB,KAAK,IAAI;kBACjC;gBACF;cACN;AAEA;YACF;UACF;QACF;AAEA,iBAAS,KAAK,EAAE,MAAM,QAAQ,MAAM,CAAC;AACrC;MACF;MAEA,KAAK,aAAa;AAChB,gCAAwB;AAExB,iBAAS,KAAK;UACZ,MAAM;UACN,OAAO,QACJ,IAAI,CAAA,SAAQ;AAnFzB,gBAAAM;AAoFc,kBAAM,gBAAeA,MAAA,KAAK,oBAAL,OAAA,SAAAA,IAAuB,mBAAA;AAC5C,kBAAM,oBACJ,gBAAA,OAAA,SAAA,aAAc,qBAAoB,OAC9B,OAAO,aAAa,gBAAgB,IACpC;AAEN,oBAAQ,KAAK,MAAM;cACjB,KAAK,QAAQ;AACX,uBAAO,KAAK,KAAK,WAAW,IACxB,SACA;kBACE,MAAM,KAAK;kBACX;gBACF;cACN;cAEA,KAAK,aAAa;AAChB,uBAAO,KAAK,KAAK,WAAW,IACxB,SACA;kBACE,MAAM,KAAK;kBACX,SAAS;kBACT;gBACF;cACN;cAEA,KAAK,QAAQ;AACX,oBAAI,KAAK,gBAAgB,KAAK;AAC5B,wBAAM,IAAI,8BAA8B;oBACtC,eACE;kBACJ,CAAC;gBACH;AAEA,uBAAO;kBACL,YAAY;oBACV,UAAU,KAAK;oBACf,MAAM,gBAAgB,KAAK,IAAI;kBACjC;kBACA;gBACF;cACF;cAEA,KAAK,aAAa;AAChB,uBAAO;kBACL,cAAc;oBACZ,MAAM,KAAK;oBACX,MAAM,KAAK;kBACb;kBACA;gBACF;cACF;YACF;UACF,CAAC,EACA,OAAO,CAAA,SAAQ,SAAS,MAAS;QACtC,CAAC;AACD;MACF;MAEA,KAAK,QAAQ;AACX,gCAAwB;AAExB,cAAM,QAAyC,CAAC;AAEhD,mBAAW,QAAQ,SAAS;AAC1B,cAAI,KAAK,SAAS,0BAA0B;AAC1C;UACF;AACA,gBAAM,SAAS,KAAK;AAEpB,cAAI,OAAO,SAAS,WAAW;AAC7B,uBAAW,eAAe,OAAO,OAAO;AACtC,sBAAQ,YAAY,MAAM;gBACxB,KAAK;AACH,wBAAM,KAAK;oBACT,kBAAkB;sBAChB,MAAM,KAAK;sBACX,UAAU;wBACR,MAAM,KAAK;wBACX,SAAS,YAAY;sBACvB;oBACF;kBACF,CAAC;AACD;gBACF,KAAK;AACH,wBAAM;oBACJ;sBACE,YAAY;wBACV,UAAU,YAAY;wBACtB,MAAM,YAAY;sBACpB;oBACF;oBACA;sBACE,MAAM;oBACR;kBACF;AACA;gBACF;AACE,wBAAM,KAAK,EAAE,MAAM,KAAK,UAAU,WAAW,EAAE,CAAC;AAChD;cACJ;YACF;UACF,OAAO;AACL,kBAAM,KAAK;cACT,kBAAkB;gBAChB,MAAM,KAAK;gBACX,UAAU;kBACR,MAAM,KAAK;kBACX,SACE,OAAO,SAAS,sBACX,KAAA,OAAO,WAAP,OAAA,KAAiB,2BAClB,OAAO;gBACf;cACF;YACF,CAAC;UACH;QACF;AAEA,iBAAS,KAAK;UACZ,MAAM;UACN;QACF,CAAC;AACD;MACF;IACF;EACF;AAEA,MACE,gBACA,uBAAuB,SAAS,KAChC,SAAS,SAAS,KAClB,SAAS,CAAC,EAAE,SAAS,QACrB;AACA,UAAM,aAAa,uBAChB,IAAI,CAAA,SAAQ,KAAK,IAAI,EACrB,KAAK,MAAM;AAEd,aAAS,CAAC,EAAE,MAAM,QAAQ,EAAE,MAAM,aAAa,OAAO,CAAC;EACzD;AAEA,SAAO;IACL,mBACE,uBAAuB,SAAS,KAAK,CAAC,eAClC,EAAE,OAAO,uBAAuB,IAChC;IACN;EACF;AACF;ACvOO,SAAS,aAAa,SAAyB;AACpD,SAAO,QAAQ,SAAS,GAAG,IAAI,UAAU,UAAU,OAAO;AAC5D;AC6CO,IAAM,oCAAoCL;EAAW,MAC1DC;IACEF,GAAE,OAAO;MACP,oBAAoBA,GAAE,MAAMA,GAAE,KAAK,CAAC,QAAQ,OAAO,CAAC,CAAC,EAAE,SAAS;MAEhE,gBAAgBA,GACb,OAAO;QACN,gBAAgBA,GAAE,OAAO,EAAE,SAAS;QACpC,iBAAiBA,GAAE,QAAQ,EAAE,SAAS;;QAEtC,eAAeA,GACZ,KAAK,CAAC,WAAW,OAAO,UAAU,MAAM,CAAC,EACzC,SAAS;MACd,CAAC,EACA,SAAS;;;;;;MAOZ,eAAeA,GAAE,OAAO,EAAE,SAAS;;;;;;;;;MAUnC,mBAAmBA,GAAE,QAAQ,EAAE,SAAS;;;;MAKxC,gBAAgBA,GACb;QACCA,GAAE,OAAO;UACP,UAAUA,GAAE,KAAK;YACf;YACA;YACA;YACA;YACA;YACA;UACF,CAAC;UACD,WAAWA,GAAE,KAAK;YAChB;YACA;YACA;YACA;YACA;YACA;UACF,CAAC;QACH,CAAC;MACH,EACC,SAAS;MAEZ,WAAWA,GACR,KAAK;QACJ;QACA;QACA;QACA;QACA;QACA;MACF,CAAC,EACA,SAAS;;;;;;MAOZ,gBAAgBA,GAAE,QAAQ,EAAE,SAAS;;;;;;MAOrC,QAAQA,GAAE,OAAOA,GAAE,OAAO,GAAGA,GAAE,OAAO,CAAC,EAAE,SAAS;;;;;;MAOlD,iBAAiBA,GACd,KAAK;QACJ;QACA;QACA;QACA;MACF,CAAC,EACA,SAAS;;;;;;MAOZ,aAAaA,GACV,OAAO;QACN,aAAaA,GACV,KAAK;UACJ;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;QACF,CAAC,EACA,SAAS;QACZ,WAAWA,GAAE,KAAK,CAAC,MAAM,MAAM,IAAI,CAAC,EAAE,SAAS;MACjD,CAAC,EACA,SAAS;;;;;;;MAQZ,iBAAiBA,GACd,OAAO;QACN,QAAQA,GACL,OAAO;UACN,UAAUA,GAAE,OAAO;UACnB,WAAWA,GAAE,OAAO;QACtB,CAAC,EACA,SAAS;MACd,CAAC,EACA,SAAS;IACd,CAAC;EACH;AACF;ACpLO,SAAS,aAAa;EAC3B;EACA;EACA;AACF,GA0BE;AAtCF,MAAA;AAwCE,WAAQ,SAAA,OAAA,SAAA,MAAO,UAAS,QAAQ;AAEhC,QAAM,eAAkC,CAAC;AAEzC,QAAM,WACJ;IACE;IACA;IACA;EACF,EACA,KAAK,CAAA,OAAM,OAAO,OAAO;AAC3B,QAAM,mBACJ,QAAQ,SAAS,UAAU,KAAK,QAAQ,SAAS,UAAU,KAAK;AAClE,QAAM,2BACJ,QAAQ,SAAS,kBAAkB,KAAK,CAAC,QAAQ,SAAS,KAAK;AACjE,QAAM,qBAAqB,QAAQ,SAAS,YAAY;AAExD,MAAI,SAAS,MAAM;AACjB,WAAO,EAAE,OAAO,QAAW,YAAY,QAAW,aAAa;EACjE;AAGA,QAAM,mBAAmB,MAAM,KAAK,CAAA,SAAQ,KAAK,SAAS,UAAU;AACpE,QAAM,mBAAmB,MAAM,KAAK,CAAA,SAAQ,KAAK,SAAS,UAAU;AAEpE,MAAI,oBAAoB,kBAAkB;AACxC,iBAAa,KAAK;MAChB,MAAM;MACN,SAAS;IACX,CAAC;EACH;AAEA,MAAI,kBAAkB;AACpB,UAAMO,eAAqB,CAAC;AAE5B,UAAM,gBAAgB,MAAM,OAAO,CAAA,SAAQ,KAAK,SAAS,UAAU;AACnE,kBAAc,QAAQ,CAAA,SAAQ;AAC5B,cAAQ,KAAK,IAAI;QACf,KAAK;AACH,cAAI,kBAAkB;AACpBA,yBAAY,KAAK,EAAE,cAAc,CAAC,EAAE,CAAC;UACvC,WAAW,0BAA0B;AAEnCA,yBAAY,KAAK;cACf,uBAAuB;gBACrB,wBAAwB;kBACtB,MAAM,KAAK,KAAK;kBAIhB,kBAAkB,KAAK,KAAK;gBAG9B;cACF;YACF,CAAC;UACH,OAAO;AACLA,yBAAY,KAAK,EAAE,uBAAuB,CAAC,EAAE,CAAC;UAChD;AACA;QACF,KAAK;AACH,cAAI,kBAAkB;AACpBA,yBAAY,KAAK,EAAE,qBAAqB,CAAC,EAAE,CAAC;UAC9C,OAAO;AACL,yBAAa,KAAK;cAChB,MAAM;cACN,SAAS,yBAAyB,KAAK,EAAE;cACzC,SAAS;YACX,CAAC;UACH;AACA;QACF,KAAK;AACH,cAAI,kBAAkB;AACpBA,yBAAY,KAAK,EAAE,YAAY,CAAC,EAAE,CAAC;UACrC,OAAO;AACL,yBAAa,KAAK;cAChB,MAAM;cACN,SAAS,yBAAyB,KAAK,EAAE;cACzC,SACE;YACJ,CAAC;UACH;AACA;QACF,KAAK;AACH,cAAI,kBAAkB;AACpBA,yBAAY,KAAK,EAAE,eAAe,CAAC,EAAE,CAAC;UACxC,OAAO;AACL,yBAAa,KAAK;cAChB,MAAM;cACN,SAAS,yBAAyB,KAAK,EAAE;cACzC,SACE;YACJ,CAAC;UACH;AACA;QACF,KAAK;AACH,cAAI,oBAAoB;AACtBA,yBAAY,KAAK,EAAE,YAAY,EAAE,GAAG,KAAK,KAAK,EAAE,CAAC;UACnD,OAAO;AACL,yBAAa,KAAK;cAChB,MAAM;cACN,SAAS,yBAAyB,KAAK,EAAE;cACzC,SACE;YACJ,CAAC;UACH;AACA;QACF,KAAK;AACH,cAAI,kBAAkB;AACpBA,yBAAY,KAAK;cACf,WAAW;gBACT,kBAAkB;kBAChB,eAAe;oBACb,YAAY,KAAK,KAAK;kBACxB;kBACA,kBAAkB,KAAK,KAAK;gBAC9B;cACF;YACF,CAAC;UACH,OAAO;AACL,yBAAa,KAAK;cAChB,MAAM;cACN,SAAS,yBAAyB,KAAK,EAAE;cACzC,SACE;YACJ,CAAC;UACH;AACA;QACF,KAAK;AACH,cAAI,kBAAkB;AACpBA,yBAAY,KAAK,EAAE,YAAY,CAAC,EAAE,CAAC;UACrC,OAAO;AACL,yBAAa,KAAK;cAChB,MAAM;cACN,SAAS,yBAAyB,KAAK,EAAE;cACzC,SACE;YACJ,CAAC;UACH;AACA;QACF;AACE,uBAAa,KAAK;YAChB,MAAM;YACN,SAAS,yBAAyB,KAAK,EAAE;UAC3C,CAAC;AACD;MACJ;IACF,CAAC;AAED,WAAO;MACL,OAAOA,aAAY,SAAS,IAAIA,eAAc;MAC9C,YAAY;MACZ;IACF;EACF;AAEA,QAAM,uBAAuB,CAAC;AAC9B,aAAW,QAAQ,OAAO;AACxB,YAAQ,KAAK,MAAM;MACjB,KAAK;AACH,6BAAqB,KAAK;UACxB,MAAM,KAAK;UACX,cAAa,KAAA,KAAK,gBAAL,OAAA,KAAoB;UACjC,YAAY,iCAAiC,KAAK,WAAW;QAC/D,CAAC;AACD;MACF;AACE,qBAAa,KAAK;UAChB,MAAM;UACN,SAAS,iBAAiB,KAAK,IAAI;QACrC,CAAC;AACD;IACJ;EACF;AAEA,MAAI,cAAc,MAAM;AACtB,WAAO;MACL,OAAO,CAAC,EAAE,qBAAqB,CAAC;MAChC,YAAY;MACZ;IACF;EACF;AAEA,QAAM,OAAO,WAAW;AAExB,UAAQ,MAAM;IACZ,KAAK;AACH,aAAO;QACL,OAAO,CAAC,EAAE,qBAAqB,CAAC;QAChC,YAAY,EAAE,uBAAuB,EAAE,MAAM,OAAO,EAAE;QACtD;MACF;IACF,KAAK;AACH,aAAO;QACL,OAAO,CAAC,EAAE,qBAAqB,CAAC;QAChC,YAAY,EAAE,uBAAuB,EAAE,MAAM,OAAO,EAAE;QACtD;MACF;IACF,KAAK;AACH,aAAO;QACL,OAAO,CAAC,EAAE,qBAAqB,CAAC;QAChC,YAAY,EAAE,uBAAuB,EAAE,MAAM,MAAM,EAAE;QACrD;MACF;IACF,KAAK;AACH,aAAO;QACL,OAAO,CAAC,EAAE,qBAAqB,CAAC;QAChC,YAAY;UACV,uBAAuB;YACrB,MAAM;YACN,sBAAsB,CAAC,WAAW,QAAQ;UAC5C;QACF;QACA;MACF;IACF,SAAS;AACP,YAAM,mBAA0B;AAChC,YAAM,IAAIC,8BAA8B;QACtC,eAAe,qBAAqB,gBAAgB;MACtD,CAAC;IACH;EACF;AACF;ACpQO,SAAS,kCAAkC;EAChD;EACA;AACF,GAG2C;AACzC,UAAQ,cAAc;IACpB,KAAK;AACH,aAAO,eAAe,eAAe;IACvC,KAAK;AACH,aAAO;IACT,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT,KAAK;IACL,KAAK;IACL;AACE,aAAO;EACX;AACF;AP6BO,IAAM,kCAAN,MAAiE;EAQtE,YACE,SACA,QACA;AAVF,SAAS,uBAAuB;AA1DlC,QAAA;AAqEI,SAAK,UAAU;AACf,SAAK,SAAS;AACd,SAAK,cAAa,KAAA,OAAO,eAAP,OAAA,KAAqB;EACzC;EAEA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAEA,IAAI,gBAAgB;AA9EtB,QAAA,IAAA,IAAA;AA+EI,YAAO,MAAA,MAAA,KAAA,KAAK,QAAO,kBAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAAiC,CAAC;EAC3C;EAEA,MAAc,QAAQ;IACpB;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EACF,GAA+B;AAhGjC,QAAA;AAiGI,UAAM,WAA8B,CAAC;AAErC,UAAM,sBAAsB,KAAK,OAAO,SAAS,SAAS,QAAQ,IAC9D,WACA;AACJ,QAAI,gBAAgB,MAAMC,qBAAqB;MAC7C,UAAU;MACV;MACA,QAAQ;IACV,CAAC;AAED,QAAI,iBAAiB,QAAQ,wBAAwB,UAAU;AAC7D,sBAAgB,MAAMA,qBAAqB;QACzC,UAAU;QACV;QACA,QAAQ;MACV,CAAC;IACH;AAGA,SACE,SAAA,OAAA,SAAA,MAAO;MACL,CAAA,SACE,KAAK,SAAS,cAAc,KAAK,OAAO;IAAA,MAE5C,CAAC,KAAK,OAAO,SAAS,WAAW,gBAAgB,GACjD;AACA,eAAS,KAAK;QACZ,MAAM;QACN,SACE,2KAEI,KAAK,OAAO,QAAQ;MAC5B,CAAC;IACH;AAEA,UAAM,eAAe,KAAK,QAAQ,YAAY,EAAE,WAAW,QAAQ;AAEnE,UAAM,EAAE,UAAU,kBAAkB,IAAI;MACtC;MACA,EAAE,cAAc,oBAAoB;IACtC;AAEA,UAAM;MACJ,OAAOF;MACP,YAAY;MACZ;IACF,IAAI,aAAa;MACf;MACA;MACA,SAAS,KAAK;IAChB,CAAC;AAED,WAAO;MACL,MAAM;QACJ,kBAAkB;;UAEhB;UACA;UACA;UACA;UACA;UACA;UACA;UACA;;UAGA,mBACE,kBAAA,OAAA,SAAA,eAAgB,UAAS,SAAS,qBAAqB;UACzD,iBACE,kBAAA,OAAA,SAAA,eAAgB,UAAS,UACzB,eAAe,UAAU;;;YAIxB,KAAA,iBAAA,OAAA,SAAA,cAAe,sBAAf,OAAA,KAAoC,QACjC,iCAAiC,eAAe,MAAM,IACtD;UACN,IAAI,iBAAA,OAAA,SAAA,cAAe,mBAAkB;YACnC,gBAAgB,cAAc;UAChC;;UAGA,oBAAoB,iBAAA,OAAA,SAAA,cAAe;UACnC,gBAAgB,iBAAA,OAAA,SAAA,cAAe;UAC/B,IAAI,iBAAA,OAAA,SAAA,cAAe,oBAAmB;YACpC,iBAAiB,cAAc;UACjC;UACA,IAAI,iBAAA,OAAA,SAAA,cAAe,gBAAe;YAChC,aAAa,cAAc;UAC7B;QACF;QACA;QACA,mBAAmB,eAAe,SAAY;QAC9C,gBAAgB,iBAAA,OAAA,SAAA,cAAe;QAC/B,OAAOA;QACP,aAAY,iBAAA,OAAA,SAAA,cAAe,mBACvB;UACE,GAAG;UACH,iBAAiB,cAAc;QACjC,IACA;QACJ,eAAe,iBAAA,OAAA,SAAA,cAAe;QAC9B,QAAQ,iBAAA,OAAA,SAAA,cAAe;MACzB;MACA,UAAU,CAAC,GAAG,UAAU,GAAG,YAAY;MACvC;IACF;EACF;EAEA,MAAM,WACJ,SACwC;AAjN5C,QAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AAkNI,UAAM,EAAE,MAAM,UAAU,oBAAoB,IAAI,MAAM,KAAK,QAAQ,OAAO;AAE1E,UAAM,gBAAgBG;MACpB,MAAMC,QAAQ,KAAK,OAAO,OAAO;MACjC,QAAQ;IACV;AAEA,UAAM;MACJ;MACA,OAAO;MACP,UAAU;IACZ,IAAI,MAAMC,cAAc;MACtB,KAAK,GAAG,KAAK,OAAO,OAAO,IAAI;QAC7B,KAAK;MACP,CAAC;MACD,SAAS;MACT,MAAM;MACN,uBAAuB;MACvB,2BAA2BC,0BAA0B,cAAc;MACnE,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,UAAM,YAAY,SAAS,WAAW,CAAC;AACvC,UAAM,UAAyC,CAAC;AAGhD,UAAM,SAAQ,MAAA,KAAA,UAAU,YAAV,OAAA,SAAA,GAAmB,UAAnB,OAAA,KAA4B,CAAC;AAE3C,UAAM,gBAAgB,SAAS;AAG/B,QAAI;AAGJ,eAAW,QAAQ,OAAO;AACxB,UAAI,oBAAoB,UAAQ,KAAA,KAAK,mBAAL,OAAA,SAAA,GAAqB,OAAM;AACzD,cAAM,aAAa,KAAK,OAAO,WAAW;AAC1C,sCAA8B;AAE9B,gBAAQ,KAAK;UACX,MAAM;UACN;UACA,UAAU;UACV,OAAO,KAAK,UAAU,KAAK,cAAc;UACzC,kBAAkB;QACpB,CAAC;MACH,WAAW,yBAAyB,QAAQ,KAAK,qBAAqB;AACpE,gBAAQ,KAAK;UACX,MAAM;;UAEN,YAAY;UACZ,UAAU;UACV,QAAQ;YACN,SAAS,KAAK,oBAAoB;YAClC,QAAQ,KAAK,oBAAoB;UACnC;QACF,CAAC;AAED,sCAA8B;MAChC,WAAW,UAAU,QAAQ,KAAK,QAAQ,QAAQ,KAAK,KAAK,SAAS,GAAG;AACtE,gBAAQ,KAAK;UACX,MAAM,KAAK,YAAY,OAAO,cAAc;UAC5C,MAAM,KAAK;UACX,kBAAkB,KAAK,mBACnB;YACE,CAAC,mBAAmB,GAAG;cACrB,kBAAkB,KAAK;YACzB;UACF,IACA;QACN,CAAC;MACH,WAAW,kBAAkB,MAAM;AACjC,gBAAQ,KAAK;UACX,MAAM;UACN,YAAY,KAAK,OAAO,WAAW;UACnC,UAAU,KAAK,aAAa;UAC5B,OAAO,KAAK,UAAU,KAAK,aAAa,IAAI;UAC5C,kBAAkB,KAAK,mBACnB;YACE,CAAC,mBAAmB,GAAG;cACrB,kBAAkB,KAAK;YACzB;UACF,IACA;QACN,CAAC;MACH,WAAW,gBAAgB,MAAM;AAC/B,gBAAQ,KAAK;UACX,MAAM;UACN,MAAM,KAAK,WAAW;UACtB,WAAW,KAAK,WAAW;UAC3B,kBAAkB,KAAK,mBACnB;YACE,CAAC,mBAAmB,GAAG;cACrB,kBAAkB,KAAK;YACzB;UACF,IACA;QACN,CAAC;MACH;IACF;AAEA,UAAM,WACJ,KAAA,eAAe;MACb,mBAAmB,UAAU;MAC7B,YAAY,KAAK,OAAO;IAC1B,CAAC,MAHD,OAAA,KAGM,CAAC;AACT,eAAW,UAAU,SAAS;AAC5B,cAAQ,KAAK,MAAM;IACrB;AAEA,WAAO;MACL;MACA,cAAc;QACZ,SAAS,kCAAkC;UACzC,cAAc,UAAU;UACxB,cAAc,QAAQ,KAAK,CAAA,SAAQ,KAAK,SAAS,WAAW;QAC9D,CAAC;QACD,MAAK,KAAA,UAAU,iBAAV,OAAA,KAA0B;MACjC;MACA,OAAO,+BAA+B,aAAa;MACnD;MACA,kBAAkB;QAChB,CAAC,mBAAmB,GAAG;UACrB,iBAAgB,KAAA,SAAS,mBAAT,OAAA,KAA2B;UAC3C,oBAAmB,KAAA,UAAU,sBAAV,OAAA,KAA+B;UAClD,qBAAoB,KAAA,UAAU,uBAAV,OAAA,KAAgC;UACpD,gBAAe,KAAA,UAAU,kBAAV,OAAA,KAA2B;UAC1C,eAAe,iBAAA,OAAA,gBAAiB;QAClC;MACF;MACA,SAAS,EAAE,MAAM,KAAK;MACtB,UAAU;;QAER,SAAS;QACT,MAAM;MACR;IACF;EACF;EAEA,MAAM,SACJ,SACsC;AACtC,UAAM,EAAE,MAAM,UAAU,oBAAoB,IAAI,MAAM,KAAK,QAAQ,OAAO;AAE1E,UAAM,UAAUH;MACd,MAAMC,QAAQ,KAAK,OAAO,OAAO;MACjC,QAAQ;IACV;AAEA,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAMC,cAAc;MAC/D,KAAK,GAAG,KAAK,OAAO,OAAO,IAAI;QAC7B,KAAK;MACP,CAAC;MACD;MACA,MAAM;MACN,uBAAuB;MACvB,2BAA2B,iCAAiC,WAAW;MACvE,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,QAAI,eAA4C;MAC9C,SAAS;MACT,KAAK;IACP;AACA,QAAI,QAAqD;AACzD,QAAI,mBAAyD;AAE7D,UAAME,cAAa,KAAK,OAAO;AAC/B,QAAI,eAAe;AAGnB,QAAI,qBAAoC;AACxC,QAAI,0BAAyC;AAC7C,QAAI,eAAe;AAGnB,UAAM,oBAAoB,oBAAI,IAAY;AAE1C,QAAI;AAEJ,WAAO;MACL,QAAQ,SAAS;QACf,IAAI,gBAGF;UACA,MAAM,YAAY;AAChB,uBAAW,QAAQ,EAAE,MAAM,gBAAgB,SAAS,CAAC;UACvD;UAEA,UAAU,OAAO,YAAY;AAlZvC,gBAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AAmZY,gBAAI,QAAQ,kBAAkB;AAC5B,yBAAW,QAAQ,EAAE,MAAM,OAAO,UAAU,MAAM,SAAS,CAAC;YAC9D;AAEA,gBAAI,CAAC,MAAM,SAAS;AAClB,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;YACF;AAEA,kBAAM,QAAQ,MAAM;AAEpB,kBAAM,gBAAgB,MAAM;AAE5B,gBAAI,iBAAiB,MAAM;AACzB,sBAAQ;YACV;AAEA,kBAAM,aAAY,KAAA,MAAM,eAAN,OAAA,SAAA,GAAmB,CAAA;AAGrC,gBAAI,aAAa,MAAM;AACrB;YACF;AAEA,kBAAM,UAAU,UAAU;AAE1B,kBAAM,UAAU,eAAe;cAC7B,mBAAmB,UAAU;cAC7B,YAAAA;YACF,CAAC;AACD,gBAAI,WAAW,MAAM;AACnB,yBAAW,UAAU,SAAS;AAC5B,oBACE,OAAO,eAAe,SACtB,CAAC,kBAAkB,IAAI,OAAO,GAAG,GACjC;AACA,oCAAkB,IAAI,OAAO,GAAG;AAChC,6BAAW,QAAQ,MAAM;gBAC3B;cACF;YACF;AAGA,gBAAI,WAAW,MAAM;AAEnB,oBAAM,SAAQ,KAAA,QAAQ,UAAR,OAAA,KAAiB,CAAC;AAChC,yBAAW,QAAQ,OAAO;AACxB,oBAAI,oBAAoB,UAAQ,KAAA,KAAK,mBAAL,OAAA,SAAA,GAAqB,OAAM;AACzD,wBAAM,aAAaA,YAAW;AAC9B,gDAA8B;AAE9B,6BAAW,QAAQ;oBACjB,MAAM;oBACN;oBACA,UAAU;oBACV,OAAO,KAAK,UAAU,KAAK,cAAc;oBACzC,kBAAkB;kBACpB,CAAC;AAED,iCAAe;gBACjB,WACE,yBAAyB,QACzB,KAAK,qBACL;AAEA,wBAAM,aAAa;AAEnB,sBAAI,YAAY;AACd,+BAAW,QAAQ;sBACjB,MAAM;sBACN;sBACA,UAAU;sBACV,QAAQ;wBACN,SAAS,KAAK,oBAAoB;wBAClC,QAAQ,KAAK,oBAAoB;sBACnC;oBACF,CAAC;AAED,kDAA8B;kBAChC;gBACF,WACE,UAAU,QACV,KAAK,QAAQ,QACb,KAAK,KAAK,SAAS,GACnB;AACA,sBAAI,KAAK,YAAY,MAAM;AAEzB,wBAAI,uBAAuB,MAAM;AAC/B,iCAAW,QAAQ;wBACjB,MAAM;wBACN,IAAI;sBACN,CAAC;AACD,2CAAqB;oBACvB;AAGA,wBAAI,4BAA4B,MAAM;AACpC,gDAA0B,OAAO,cAAc;AAC/C,iCAAW,QAAQ;wBACjB,MAAM;wBACN,IAAI;wBACJ,kBAAkB,KAAK,mBACnB;0BACE,CAAC,mBAAmB,GAAG;4BACrB,kBAAkB,KAAK;0BACzB;wBACF,IACA;sBACN,CAAC;oBACH;AAEA,+BAAW,QAAQ;sBACjB,MAAM;sBACN,IAAI;sBACJ,OAAO,KAAK;sBACZ,kBAAkB,KAAK,mBACnB;wBACE,CAAC,mBAAmB,GAAG;0BACrB,kBAAkB,KAAK;wBACzB;sBACF,IACA;oBACN,CAAC;kBACH,OAAO;AAEL,wBAAI,4BAA4B,MAAM;AACpC,iCAAW,QAAQ;wBACjB,MAAM;wBACN,IAAI;sBACN,CAAC;AACD,gDAA0B;oBAC5B;AAGA,wBAAI,uBAAuB,MAAM;AAC/B,2CAAqB,OAAO,cAAc;AAC1C,iCAAW,QAAQ;wBACjB,MAAM;wBACN,IAAI;wBACJ,kBAAkB,KAAK,mBACnB;0BACE,CAAC,mBAAmB,GAAG;4BACrB,kBAAkB,KAAK;0BACzB;wBACF,IACA;sBACN,CAAC;oBACH;AAEA,+BAAW,QAAQ;sBACjB,MAAM;sBACN,IAAI;sBACJ,OAAO,KAAK;sBACZ,kBAAkB,KAAK,mBACnB;wBACE,CAAC,mBAAmB,GAAG;0BACrB,kBAAkB,KAAK;wBACzB;sBACF,IACA;oBACN,CAAC;kBACH;gBACF,WAAW,gBAAgB,MAAM;AAE/B,6BAAW,QAAQ;oBACjB,MAAM;oBACN,WAAW,KAAK,WAAW;oBAC3B,MAAM,KAAK,WAAW;kBACxB,CAAC;gBACH;cACF;AAEA,oBAAM,iBAAiB,sBAAsB;gBAC3C,OAAO,QAAQ;gBACf,YAAAA;gBACA;cACF,CAAC;AAED,kBAAI,kBAAkB,MAAM;AAC1B,2BAAW,YAAY,gBAAgB;AACrC,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI,SAAS;oBACb,UAAU,SAAS;oBACnB,kBAAkB,SAAS;kBAC7B,CAAC;AAED,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI,SAAS;oBACb,OAAO,SAAS;oBAChB,kBAAkB,SAAS;kBAC7B,CAAC;AAED,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI,SAAS;oBACb,kBAAkB,SAAS;kBAC7B,CAAC;AAED,6BAAW,QAAQ;oBACjB,MAAM;oBACN,YAAY,SAAS;oBACrB,UAAU,SAAS;oBACnB,OAAO,SAAS;oBAChB,kBAAkB,SAAS;kBAC7B,CAAC;AAED,iCAAe;gBACjB;cACF;YACF;AAEA,gBAAI,UAAU,gBAAgB,MAAM;AAClC,6BAAe;gBACb,SAAS,kCAAkC;kBACzC,cAAc,UAAU;kBACxB;gBACF,CAAC;gBACD,KAAK,UAAU;cACjB;AAEA,iCAAmB;gBACjB,CAAC,mBAAmB,GAAG;kBACrB,iBAAgB,KAAA,MAAM,mBAAN,OAAA,KAAwB;kBACxC,oBAAmB,KAAA,UAAU,sBAAV,OAAA,KAA+B;kBAClD,qBAAoB,KAAA,UAAU,uBAAV,OAAA,KAAgC;kBACpD,gBAAe,KAAA,UAAU,kBAAV,OAAA,KAA2B;gBAC5C;cACF;AACA,kBAAI,iBAAiB,MAAM;AAEvB,iCAAiB,mBAAmB,EAIpC,gBAAgB;cACpB;YACF;UACF;UAEA,MAAM,YAAY;AAEhB,gBAAI,uBAAuB,MAAM;AAC/B,yBAAW,QAAQ;gBACjB,MAAM;gBACN,IAAI;cACN,CAAC;YACH;AACA,gBAAI,4BAA4B,MAAM;AACpC,yBAAW,QAAQ;gBACjB,MAAM;gBACN,IAAI;cACN,CAAC;YACH;AAEA,uBAAW,QAAQ;cACjB,MAAM;cACN;cACA,OAAO,+BAA+B,KAAK;cAC3C;YACF,CAAC;UACH;QACF,CAAC;MACH;MACA,UAAU,EAAE,SAAS,gBAAgB;MACrC,SAAS,EAAE,MAAM,KAAK;IACxB;EACF;AACF;AAEA,SAAS,sBAAsB;EAC7B;EACA,YAAAA;EACA;AACF,GAIG;AACD,QAAM,oBAAoB,SAAA,OAAA,SAAA,MAAO;IAC/B,CAAA,SAAQ,kBAAkB;EAAA;AAQ5B,SAAO,qBAAqB,QAAQ,kBAAkB,WAAW,IAC7D,SACA,kBAAkB,IAAI,CAAA,UAAS;IAC7B,MAAM;IACN,YAAYA,YAAW;IACvB,UAAU,KAAK,aAAa;IAC5B,MAAM,KAAK,UAAU,KAAK,aAAa,IAAI;IAC3C,kBAAkB,KAAK,mBACnB;MACE,CAAC,mBAAmB,GAAG;QACrB,kBAAkB,KAAK;MACzB;IACF,IACA;EACN,EAAE;AACR;AAEA,SAAS,eAAe;EACtB;EACA,YAAAA;AACF,GAGwC;AA3sBxC,MAAA,IAAA,IAAA,IAAA,IAAA;AA4sBE,MAAI,EAAC,qBAAA,OAAA,SAAA,kBAAmB,kBAAiB;AACvC,WAAO;EACT;AAEA,QAAM,UAAmC,CAAC;AAE1C,aAAW,SAAS,kBAAkB,iBAAiB;AACrD,QAAI,MAAM,OAAO,MAAM;AAErB,cAAQ,KAAK;QACX,MAAM;QACN,YAAY;QACZ,IAAIA,YAAW;QACf,KAAK,MAAM,IAAI;QACf,QAAO,KAAA,MAAM,IAAI,UAAV,OAAA,KAAmB;MAC5B,CAAC;IACH,WAAW,MAAM,oBAAoB,MAAM;AAEzC,YAAM,MAAM,MAAM,iBAAiB;AACnC,YAAM,kBAAkB,MAAM,iBAAiB;AAE/C,UAAI,QAAQ,IAAI,WAAW,SAAS,KAAK,IAAI,WAAW,UAAU,IAAI;AAEpE,gBAAQ,KAAK;UACX,MAAM;UACN,YAAY;UACZ,IAAIA,YAAW;UACf,KAAK;UACL,QAAO,KAAA,MAAM,iBAAiB,UAAvB,OAAA,KAAgC;QACzC,CAAC;MACH,WAAW,KAAK;AAEd,cAAM,SAAQ,KAAA,MAAM,iBAAiB,UAAvB,OAAA,KAAgC;AAC9C,YAAI,YAAY;AAChB,YAAI,WAA+B;AAEnC,YAAI,IAAI,SAAS,MAAM,GAAG;AACxB,sBAAY;AACZ,qBAAW,IAAI,MAAM,GAAG,EAAE,IAAI;QAChC,WAAW,IAAI,SAAS,MAAM,GAAG;AAC/B,sBAAY;AACZ,qBAAW,IAAI,MAAM,GAAG,EAAE,IAAI;QAChC,WAAW,IAAI,SAAS,OAAO,GAAG;AAChC,sBACE;AACF,qBAAW,IAAI,MAAM,GAAG,EAAE,IAAI;QAChC,WAAW,IAAI,SAAS,MAAM,GAAG;AAC/B,sBAAY;AACZ,qBAAW,IAAI,MAAM,GAAG,EAAE,IAAI;QAChC,WAAW,IAAI,MAAM,kBAAkB,GAAG;AACxC,sBAAY;AACZ,qBAAW,IAAI,MAAM,GAAG,EAAE,IAAI;QAChC,OAAO;AACL,qBAAW,IAAI,MAAM,GAAG,EAAE,IAAI;QAChC;AAEA,gBAAQ,KAAK;UACX,MAAM;UACN,YAAY;UACZ,IAAIA,YAAW;UACf;UACA;UACA;QACF,CAAC;MACH,WAAW,iBAAiB;AAE1B,cAAM,SAAQ,KAAA,MAAM,iBAAiB,UAAvB,OAAA,KAAgC;AAC9C,gBAAQ,KAAK;UACX,MAAM;UACN,YAAY;UACZ,IAAIA,YAAW;UACf,WAAW;UACX;UACA,UAAU,gBAAgB,MAAM,GAAG,EAAE,IAAI;QAC3C,CAAC;MACH;IACF,WAAW,MAAM,QAAQ,MAAM;AAC7B,UAAI,MAAM,KAAK,KAAK;AAClB,gBAAQ,KAAK;UACX,MAAM;UACN,YAAY;UACZ,IAAIA,YAAW;UACf,KAAK,MAAM,KAAK;UAChB,QAAO,KAAA,MAAM,KAAK,UAAX,OAAA,KAAoB;QAC7B,CAAC;MACH;IACF;EACF;AAEA,SAAO,QAAQ,SAAS,IAAI,UAAU;AACxC;AAEO,IAAM,6BAA6B,MACxCd,GAAE,OAAO;EACP,kBAAkBA,GAAE,MAAMA,GAAE,OAAO,CAAC,EAAE,QAAQ;EAC9C,kBAAkBA,GAAE,MAAMA,GAAE,OAAO,CAAC,EAAE,QAAQ;EAC9C,kBAAkBA,GAAE,OAAO,EAAE,iBAAiBA,GAAE,OAAO,EAAE,CAAC,EAAE,QAAQ;EACpE,iBAAiBA,GACd;IACCA,GAAE,OAAO;MACP,KAAKA,GACF,OAAO,EAAE,KAAKA,GAAE,OAAO,GAAG,OAAOA,GAAE,OAAO,EAAE,QAAQ,EAAE,CAAC,EACvD,QAAQ;MACX,kBAAkBA,GACf,OAAO;QACN,KAAKA,GAAE,OAAO,EAAE,QAAQ;QACxB,OAAOA,GAAE,OAAO,EAAE,QAAQ;QAC1B,MAAMA,GAAE,OAAO,EAAE,QAAQ;QACzB,iBAAiBA,GAAE,OAAO,EAAE,QAAQ;MACtC,CAAC,EACA,QAAQ;MACX,MAAMA,GACH,OAAO;QACN,KAAKA,GAAE,OAAO,EAAE,QAAQ;QACxB,OAAOA,GAAE,OAAO,EAAE,QAAQ;QAC1B,MAAMA,GAAE,OAAO,EAAE,QAAQ;QACzB,SAASA,GAAE,OAAO,EAAE,QAAQ;MAC9B,CAAC,EACA,QAAQ;IACb,CAAC;EACH,EACC,QAAQ;EACX,mBAAmBA,GAChB;IACCA,GAAE,OAAO;MACP,SAASA,GAAE,OAAO;QAChB,YAAYA,GAAE,OAAO,EAAE,QAAQ;QAC/B,UAAUA,GAAE,OAAO,EAAE,QAAQ;QAC7B,MAAMA,GAAE,OAAO,EAAE,QAAQ;MAC3B,CAAC;MACD,cAAcA,GAAE,OAAO,EAAE,QAAQ;MACjC,uBAAuBA,GAAE,MAAMA,GAAE,OAAO,CAAC,EAAE,QAAQ;MACnD,qBAAqBA,GAAE,MAAMA,GAAE,OAAO,CAAC,EAAE,QAAQ;MACjD,kBAAkBA,GAAE,MAAMA,GAAE,OAAO,CAAC,EAAE,QAAQ;MAC9C,iBAAiBA,GAAE,MAAMA,GAAE,OAAO,CAAC,EAAE,QAAQ;IAC/C,CAAC;EACH,EACC,QAAQ;EACX,mBAAmBA,GAChB,MAAM;IACLA,GAAE,OAAO;MACP,0BAA0BA,GAAE,OAAO;IACrC,CAAC;IACDA,GAAE,OAAO,CAAC,CAAC;EACb,CAAC,EACA,QAAQ;AACb,CAAC;AAEH,IAAM,mBAAmB,MACvBA,GAAE,OAAO;EACP,OAAOA,GACJ;IACCA,GAAE,MAAM;;MAENA,GAAE,OAAO;QACP,cAAcA,GAAE,OAAO;UACrB,MAAMA,GAAE,OAAO;UACf,MAAMA,GAAE,QAAQ;QAClB,CAAC;QACD,kBAAkBA,GAAE,OAAO,EAAE,QAAQ;MACvC,CAAC;MACDA,GAAE,OAAO;QACP,YAAYA,GAAE,OAAO;UACnB,UAAUA,GAAE,OAAO;UACnB,MAAMA,GAAE,OAAO;QACjB,CAAC;QACD,kBAAkBA,GAAE,OAAO,EAAE,QAAQ;MACvC,CAAC;MACDA,GAAE,OAAO;QACP,gBAAgBA,GACb,OAAO;UACN,UAAUA,GAAE,OAAO;UACnB,MAAMA,GAAE,OAAO;QACjB,CAAC,EACA,QAAQ;QACX,qBAAqBA,GAClB,OAAO;UACN,SAASA,GAAE,OAAO;UAClB,QAAQA,GAAE,OAAO;QACnB,CAAC,EACA,QAAQ;QACX,MAAMA,GAAE,OAAO,EAAE,QAAQ;QACzB,SAASA,GAAE,QAAQ,EAAE,QAAQ;QAC7B,kBAAkBA,GAAE,OAAO,EAAE,QAAQ;MACvC,CAAC;IACH,CAAC;EACH,EACC,QAAQ;AACb,CAAC;AAGH,IAAM,wBAAwB,MAC5BA,GAAE,OAAO;EACP,UAAUA,GAAE,OAAO,EAAE,QAAQ;EAC7B,aAAaA,GAAE,OAAO,EAAE,QAAQ;EAChC,kBAAkBA,GAAE,OAAO,EAAE,QAAQ;EACrC,UAAUA,GAAE,OAAO,EAAE,QAAQ;EAC7B,eAAeA,GAAE,OAAO,EAAE,QAAQ;EAClC,SAASA,GAAE,QAAQ,EAAE,QAAQ;AAC/B,CAAC;AAEH,IAAM,cAAcA,GAAE,OAAO;EAC3B,yBAAyBA,GAAE,OAAO,EAAE,QAAQ;EAC5C,oBAAoBA,GAAE,OAAO,EAAE,QAAQ;EACvC,kBAAkBA,GAAE,OAAO,EAAE,QAAQ;EACrC,sBAAsBA,GAAE,OAAO,EAAE,QAAQ;EACzC,iBAAiBA,GAAE,OAAO,EAAE,QAAQ;;EAEpC,aAAaA,GAAE,OAAO,EAAE,QAAQ;AAClC,CAAC;AAGM,IAAM,8BAA8B,MACzCA,GAAE,OAAO;EACP,aAAaA,GAAE;IACbA,GAAE,OAAO;MACP,cAAcA,GAAE,OAAO;MACvB,oBAAoBA,GAAE,OAAO;IAC/B,CAAC;EACH;AACF,CAAC;AAEH,IAAM,iBAAiBC;EAAW,MAChCC;IACEF,GAAE,OAAO;MACP,YAAYA,GAAE;QACZA,GAAE,OAAO;UACP,SAAS,iBAAiB,EAAE,QAAQ,EAAE,GAAGA,GAAE,OAAO,CAAC,CAAC,EAAE,OAAO,CAAC;UAC9D,cAAcA,GAAE,OAAO,EAAE,QAAQ;UACjC,eAAeA,GAAE,MAAM,sBAAsB,CAAC,EAAE,QAAQ;UACxD,mBAAmB,2BAA2B,EAAE,QAAQ;UACxD,oBAAoB,4BAA4B,EAAE,QAAQ;QAC5D,CAAC;MACH;MACA,eAAe,YAAY,QAAQ;MACnC,gBAAgBA,GACb,OAAO;QACN,aAAaA,GAAE,OAAO,EAAE,QAAQ;QAChC,eAAeA,GAAE,MAAM,sBAAsB,CAAC,EAAE,QAAQ;MAC1D,CAAC,EACA,QAAQ;IACb,CAAC;EACH;AACF;AAuBA,IAAM,cAAcC;EAAW,MAC7BC;IACEF,GAAE,OAAO;MACP,YAAYA,GACT;QACCA,GAAE,OAAO;UACP,SAAS,iBAAiB,EAAE,QAAQ;UACpC,cAAcA,GAAE,OAAO,EAAE,QAAQ;UACjC,eAAeA,GAAE,MAAM,sBAAsB,CAAC,EAAE,QAAQ;UACxD,mBAAmB,2BAA2B,EAAE,QAAQ;UACxD,oBAAoB,4BAA4B,EAAE,QAAQ;QAC5D,CAAC;MACH,EACC,QAAQ;MACX,eAAe,YAAY,QAAQ;MACnC,gBAAgBA,GACb,OAAO;QACN,aAAaA,GAAE,OAAO,EAAE,QAAQ;QAChC,eAAeA,GAAE,MAAM,sBAAsB,CAAC,EAAE,QAAQ;MAC1D,CAAC,EACA,QAAQ;IACb,CAAC;EACH;AACF;AQj+BO,IAAM,gBAAgB,0CAU3B;EACA,IAAI;EACJ,aAAaA,GAAE,OAAO;IACpB,UAAUA,GAAE,OAAO,EAAE,SAAS,uCAAuC;IACrE,MAAMA,GAAE,OAAO,EAAE,SAAS,0BAA0B;EACtD,CAAC;EACD,cAAcA,GAAE,OAAO;IACrB,SAASA,GACN,OAAO,EACP,SAAS,oDAAoD;IAChE,QAAQA,GAAE,OAAO,EAAE,SAAS,qCAAqC;EACnE,CAAC;AACH,CAAC;ACzBM,IAAM,sBAAsB,0BAKjC;EACA,IAAI;EACJ,aAAaC,WAAW,MAAMC,UAAUF,GAAE,OAAO,CAAC,CAAC,CAAC,CAAC;AACvD,CAAC;ACTD,IAAM,2BAA2BA,GAC9B,OAAO;;;;EAIN,sBAAsBA,GACnB,MAAMA,GAAE,OAAO,CAAC,EAChB;IACC;EACF;;EAEF,MAAMA,GACH,OAAO,EACP,IAAI,EACJ,SAAS,EACT,SAAS,yDAAyD,EAClE,SAAS;;;;EAKZ,gBAAgBA,GACb,OAAO,EACP;IACC;EACF,EACC,SAAS;AACd,CAAC,EACA,YAAY;AAIf,IAAM,uBAAuBC;EAAW,MACtCC,UAAU,wBAAwB;AACpC;AAEO,IAAM,aAAaa,0BAGxB;EACA,IAAI;EACJ,aAAa;AACf,CAAC;ACxCM,IAAM,aAAaA,0BAAkC;EAC1D,IAAI;EACJ,aAAad,WAAW,MAAMC,UAAUF,GAAE,OAAO,CAAC,CAAC,CAAC,CAAC;AACvD,CAAC;ACFM,IAAM,eAAee,0BAgB1B;EACA,IAAI;EACJ,aAAad;IAAW,MACtBC;MACEF,IAAE,OAAO;QACP,MAAMA,IACH,KAAK,CAAC,gBAAgB,kBAAkB,CAAC,EACzC,QAAQ,kBAAkB;QAC7B,kBAAkBA,IAAE,OAAO,EAAE,QAAQ,CAAC;MACxC,CAAC;IACH;EACF;AACF,CAAC;AChCM,IAAM,aAAae,0BAKxB;EACA,IAAI;EACJ,aAAad,WAAW,MAAMC,UAAUF,IAAE,OAAO,CAAC,CAAC,CAAC,CAAC;AACvD,CAAC;ACJM,IAAM,iBAAiBe,0BAa5B;EACA,IAAI;EACJ,aAAaf,IAAE,OAAO;IACpB,WAAWA,IAAE,OAAO;IACpB,MAAMA,IAAE,OAAO,EAAE,SAAS;EAC5B,CAAC;AACH,CAAC;ACtBM,IAAM,cAAc;;;;;EAKzB;;;;;;;;;;;EAYA;;;;;;;;EASA;;;;;EAMA;;;;;;;;;;;EAYA;;;;;;;;;;;EAWA;;;;;EAMA;AACF;ACxCO,IAAM,+BAAN,MAA2D;EAYhE,YACW,SACQ,UACA,QACjB;AAHS,SAAA,UAAA;AACQ,SAAA,WAAA;AACA,SAAA,SAAA;AAdnB,SAAS,uBAAuB;EAe7B;EAbH,IAAI,mBAA2B;AAjCjC,QAAA;AAmCI,YAAO,KAAA,KAAK,SAAS,qBAAd,OAAA,KAAkC;EAC3C;EAEA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAQA,MAAM,WACJ,SAC0D;AAlD9D,QAAA,IAAA,IAAA;AAmDI,UAAM;MACJ;MACA,IAAI;MACJ;MACA,cAAc;MACd;MACA;MACA;MACA;MACA;MACA;IACF,IAAI;AACJ,UAAM,WAAmC,CAAC;AAG1C,QAAI,SAAS,QAAQ,MAAM,SAAS,GAAG;AACrC,YAAM,IAAI;QACR;MAEF;IACF;AAEA,QAAI,QAAQ,MAAM;AAChB,YAAM,IAAI;QACR;MAEF;IACF;AAEA,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SACE;MACJ,CAAC;IACH;AAEA,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SACE;MACJ,CAAC;IACH;AAEA,UAAM,gBAAgB,MAAMS,qBAAqB;MAC/C,UAAU;MACV;MACA,QAAQ;IACV,CAAC;AAED,UAAM,eAAc,MAAA,MAAA,KAAA,KAAK,OAAO,cAAZ,OAAA,SAAA,GAAuB,gBAAvB,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA0C,oBAAI,KAAK;AAEvE,UAAM,aAAsC;MAC1C,aAAa;IACf;AAEA,QAAI,eAAe,MAAM;AACvB,iBAAW,cAAc;IAC3B;AAEA,QAAI,eAAe;AACjB,aAAO,OAAO,YAAY,aAAa;IACzC;AAEA,UAAM,OAAO;MACX,WAAW,CAAC,EAAE,OAAO,CAAC;MACtB;IACF;AAEA,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAMG,cAEhD;MACD,KAAK,GAAG,KAAK,OAAO,OAAO,WAAW,KAAK,OAAO;MAClD,SAASF,eAAe,MAAMC,QAAQ,KAAK,OAAO,OAAO,GAAG,OAAO;MACnE;MACA,uBAAuB;MACvB,2BAA2BE;QACzB;MACF;MACA;MACA,OAAO,KAAK,OAAO;IACrB,CAAC;AACD,WAAO;MACL,QAAQ,SAAS,YAAY;QAC3B,CAAC,MAAsC,EAAE;MAC3C;MACA,UAAU,YAAA,OAAA,WAAY,CAAC;MACvB,kBAAkB;QAChB,QAAQ;UACN,QAAQ,SAAS,YAAY,IAAI,CAAA,gBAAe;;UAEhD,EAAE;QACJ;MACF;MACA,UAAU;QACR,WAAW;QACX,SAAS,KAAK;QACd,SAAS;MACX;IACF;EACF;AACF;AAGA,IAAM,4BAA4BZ;EAAW,MAC3CC;IACEF,IAAE,OAAO;MACP,aAAaA,IACV,MAAMA,IAAE,OAAO,EAAE,oBAAoBA,IAAE,OAAO,EAAE,CAAC,CAAC,EAClD,QAAQ,CAAC,CAAC;IACf,CAAC;EACH;AACF;AAIA,IAAM,mCAAmCC;EAAW,MAClDC;IACEF,IAAE,OAAO;MACP,kBAAkBA,IACf,KAAK,CAAC,cAAc,eAAe,WAAW,CAAC,EAC/C,QAAQ;MACX,aAAaA,IAAE,KAAK,CAAC,OAAO,OAAO,OAAO,QAAQ,MAAM,CAAC,EAAE,QAAQ;IACrE,CAAC;EACH;AACF;ArBrEO,SAAS,yBACd,UAA8C,CAAC,GACnB;AAhH9B,MAAA,IAAA;AAiHE,QAAM,WACJ,KAAA,qBAAqB,QAAQ,OAAO,MAApC,OAAA,KACA;AAEF,QAAM,gBAAe,KAAA,QAAQ,SAAR,OAAA,KAAgB;AAErC,QAAM,aAAa,MACjB;IACE;MACE,kBAAkB,WAAW;QAC3B,QAAQ,QAAQ;QAChB,yBAAyB;QACzB,aAAa;MACf,CAAC;MACD,GAAG,QAAQ;IACb;IACA,iBAAiB,OAAO;EAC1B;AAEF,QAAM,kBAAkB,CAAC,YAAoC;AApI/D,QAAAM;AAqII,WAAA,IAAI,gCAAgC,SAAS;MAC3C,UAAU;MACV;MACA,SAAS;MACT,aAAYA,MAAA,QAAQ,eAAR,OAAAA,MAAsBQ;MAClC,eAAe,OAAO;QACpB,KAAK;;;UAGH,IAAI,OAAO,IAAI,OAAO,YAAY;;UAElC,IAAI;YACF;UACF;UACA,IAAI,OAAO,gDAAgD;QAC7D;MACF;MACA,OAAO,QAAQ;IACjB,CAAC;EAAA;AAEH,QAAM,uBAAuB,CAAC,YAC5B,IAAI,iCAAiC,SAAS;IAC5C,UAAU;IACV;IACA,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,mBAAmB,CACvB,SACA,WAA4C,CAAC,MAE7C,IAAI,6BAA6B,SAAS,UAAU;IAClD,UAAU;IACV;IACA,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,WAAW,SAAU,SAAoC;AAC7D,QAAI,YAAY;AACd,YAAM,IAAI;QACR;MACF;IACF;AAEA,WAAO,gBAAgB,OAAO;EAChC;AAEA,WAAS,uBAAuB;AAChC,WAAS,gBAAgB;AACzB,WAAS,OAAO;AAChB,WAAS,eAAe;AACxB,WAAS,YAAY;AACrB,WAAS,iBAAiB;AAC1B,WAAS,gBAAgB;AACzB,WAAS,qBAAqB;AAC9B,WAAS,QAAQ;AACjB,WAAS,aAAa;AACtB,WAAS,QAAQ;AAEjB,SAAO;AACT;AAKO,IAAM,SAAS,yBAAyB;","names":["z","z","z","z","z","z","z","z","z","z","z","z","lazySchema","zodSchema","responseHeaders","response","rawValue","_a","googleTools","UnsupportedFunctionalityError","parseProviderOptions","combineHeaders","resolve","postJsonToApi","createJsonResponseHandler","generateId","createProviderToolFactory"]}