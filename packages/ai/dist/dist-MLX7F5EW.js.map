{"version":3,"sources":["../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/chat/openai-chat-language-model.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/openai-error.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/openai-language-model-capabilities.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/chat/convert-openai-chat-usage.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/chat/convert-to-openai-chat-messages.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/chat/get-response-metadata.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/chat/map-openai-finish-reason.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/chat/openai-chat-api.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/chat/openai-chat-options.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/chat/openai-chat-prepare-tools.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/completion/openai-completion-language-model.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/completion/convert-openai-completion-usage.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/completion/convert-to-openai-completion-prompt.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/completion/get-response-metadata.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/completion/map-openai-finish-reason.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/completion/openai-completion-api.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/completion/openai-completion-options.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/embedding/openai-embedding-model.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/embedding/openai-embedding-options.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/embedding/openai-embedding-api.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/image/openai-image-model.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/image/openai-image-api.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/image/openai-image-options.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/transcription/openai-transcription-model.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/transcription/openai-transcription-api.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/transcription/openai-transcription-options.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/speech/openai-speech-model.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/speech/openai-speech-options.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/responses/openai-responses-language-model.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/responses/convert-openai-responses-usage.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/responses/convert-to-openai-responses-input.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/tool/apply-patch.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/tool/local-shell.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/tool/shell.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/responses/map-openai-responses-finish-reason.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/responses/openai-responses-api.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/responses/openai-responses-options.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/responses/openai-responses-prepare-tools.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/tool/code-interpreter.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/tool/file-search.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/tool/image-generation.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/tool/mcp.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/tool/web-search.ts","../../../node_modules/.pnpm/@ai-sdk+openai@3.0.2_zod@4.2.1/node_modules/@ai-sdk/openai/src/tool/web-search-preview.ts","../../../node_modules/.pnpm/@ai-sdk+azure@3.0.2_zod@4.2.1/node_modules/@ai-sdk/azure/src/azure-openai-provider.ts","../../../node_modules/.pnpm/@ai-sdk+azure@3.0.2_zod@4.2.1/node_modules/@ai-sdk/azure/src/azure-openai-tools.ts","../../../node_modules/.pnpm/@ai-sdk+azure@3.0.2_zod@4.2.1/node_modules/@ai-sdk/azure/src/version.ts"],"sourcesContent":["import {\n  InvalidResponseDataError,\n  LanguageModelV3,\n  LanguageModelV3CallOptions,\n  LanguageModelV3Content,\n  LanguageModelV3FinishReason,\n  LanguageModelV3GenerateResult,\n  LanguageModelV3StreamPart,\n  LanguageModelV3StreamResult,\n  SharedV3ProviderMetadata,\n  SharedV3Warning,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  ParseResult,\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  generateId,\n  isParsableJson,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport { getOpenAILanguageModelCapabilities } from '../openai-language-model-capabilities';\nimport {\n  OpenAIChatUsage,\n  convertOpenAIChatUsage,\n} from './convert-openai-chat-usage';\nimport { convertToOpenAIChatMessages } from './convert-to-openai-chat-messages';\nimport { getResponseMetadata } from './get-response-metadata';\nimport { mapOpenAIFinishReason } from './map-openai-finish-reason';\nimport {\n  OpenAIChatChunk,\n  openaiChatChunkSchema,\n  openaiChatResponseSchema,\n} from './openai-chat-api';\nimport {\n  OpenAIChatModelId,\n  openaiChatLanguageModelOptions,\n} from './openai-chat-options';\nimport { prepareChatTools } from './openai-chat-prepare-tools';\n\ntype OpenAIChatConfig = {\n  provider: string;\n  headers: () => Record<string, string | undefined>;\n  url: (options: { modelId: string; path: string }) => string;\n  fetch?: FetchFunction;\n};\n\nexport class OpenAIChatLanguageModel implements LanguageModelV3 {\n  readonly specificationVersion = 'v3';\n\n  readonly modelId: OpenAIChatModelId;\n\n  readonly supportedUrls = {\n    'image/*': [/^https?:\\/\\/.*$/],\n  };\n\n  private readonly config: OpenAIChatConfig;\n\n  constructor(modelId: OpenAIChatModelId, config: OpenAIChatConfig) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private async getArgs({\n    prompt,\n    maxOutputTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences,\n    responseFormat,\n    seed,\n    tools,\n    toolChoice,\n    providerOptions,\n  }: LanguageModelV3CallOptions) {\n    const warnings: SharedV3Warning[] = [];\n\n    // Parse provider options\n    const openaiOptions =\n      (await parseProviderOptions({\n        provider: 'openai',\n        providerOptions,\n        schema: openaiChatLanguageModelOptions,\n      })) ?? {};\n\n    const modelCapabilities = getOpenAILanguageModelCapabilities(this.modelId);\n    const isReasoningModel =\n      openaiOptions.forceReasoning ?? modelCapabilities.isReasoningModel;\n\n    if (topK != null) {\n      warnings.push({ type: 'unsupported', feature: 'topK' });\n    }\n\n    const { messages, warnings: messageWarnings } = convertToOpenAIChatMessages(\n      {\n        prompt,\n        systemMessageMode:\n          openaiOptions.systemMessageMode ??\n          (isReasoningModel\n            ? 'developer'\n            : modelCapabilities.systemMessageMode),\n      },\n    );\n\n    warnings.push(...messageWarnings);\n\n    const strictJsonSchema = openaiOptions.strictJsonSchema ?? true;\n\n    const baseArgs = {\n      // model id:\n      model: this.modelId,\n\n      // model specific settings:\n      logit_bias: openaiOptions.logitBias,\n      logprobs:\n        openaiOptions.logprobs === true ||\n        typeof openaiOptions.logprobs === 'number'\n          ? true\n          : undefined,\n      top_logprobs:\n        typeof openaiOptions.logprobs === 'number'\n          ? openaiOptions.logprobs\n          : typeof openaiOptions.logprobs === 'boolean'\n            ? openaiOptions.logprobs\n              ? 0\n              : undefined\n            : undefined,\n      user: openaiOptions.user,\n      parallel_tool_calls: openaiOptions.parallelToolCalls,\n\n      // standardized settings:\n      max_tokens: maxOutputTokens,\n      temperature,\n      top_p: topP,\n      frequency_penalty: frequencyPenalty,\n      presence_penalty: presencePenalty,\n      response_format:\n        responseFormat?.type === 'json'\n          ? responseFormat.schema != null\n            ? {\n                type: 'json_schema',\n                json_schema: {\n                  schema: responseFormat.schema,\n                  strict: strictJsonSchema,\n                  name: responseFormat.name ?? 'response',\n                  description: responseFormat.description,\n                },\n              }\n            : { type: 'json_object' }\n          : undefined,\n      stop: stopSequences,\n      seed,\n      verbosity: openaiOptions.textVerbosity,\n\n      // openai specific settings:\n      // TODO AI SDK 6: remove, we auto-map maxOutputTokens now\n      max_completion_tokens: openaiOptions.maxCompletionTokens,\n      store: openaiOptions.store,\n      metadata: openaiOptions.metadata,\n      prediction: openaiOptions.prediction,\n      reasoning_effort: openaiOptions.reasoningEffort,\n      service_tier: openaiOptions.serviceTier,\n      prompt_cache_key: openaiOptions.promptCacheKey,\n      prompt_cache_retention: openaiOptions.promptCacheRetention,\n      safety_identifier: openaiOptions.safetyIdentifier,\n\n      // messages:\n      messages,\n    };\n\n    // remove unsupported settings for reasoning models\n    // see https://platform.openai.com/docs/guides/reasoning#limitations\n    if (isReasoningModel) {\n      // when reasoning effort is none, gpt-5.1 models allow temperature, topP, logprobs\n      //  https://platform.openai.com/docs/guides/latest-model#gpt-5-1-parameter-compatibility\n      if (\n        openaiOptions.reasoningEffort !== 'none' ||\n        !modelCapabilities.supportsNonReasoningParameters\n      ) {\n        if (baseArgs.temperature != null) {\n          baseArgs.temperature = undefined;\n          warnings.push({\n            type: 'unsupported',\n            feature: 'temperature',\n            details: 'temperature is not supported for reasoning models',\n          });\n        }\n        if (baseArgs.top_p != null) {\n          baseArgs.top_p = undefined;\n          warnings.push({\n            type: 'unsupported',\n            feature: 'topP',\n            details: 'topP is not supported for reasoning models',\n          });\n        }\n        if (baseArgs.logprobs != null) {\n          baseArgs.logprobs = undefined;\n          warnings.push({\n            type: 'other',\n            message: 'logprobs is not supported for reasoning models',\n          });\n        }\n      }\n\n      if (baseArgs.frequency_penalty != null) {\n        baseArgs.frequency_penalty = undefined;\n        warnings.push({\n          type: 'unsupported',\n          feature: 'frequencyPenalty',\n          details: 'frequencyPenalty is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.presence_penalty != null) {\n        baseArgs.presence_penalty = undefined;\n        warnings.push({\n          type: 'unsupported',\n          feature: 'presencePenalty',\n          details: 'presencePenalty is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.logit_bias != null) {\n        baseArgs.logit_bias = undefined;\n        warnings.push({\n          type: 'other',\n          message: 'logitBias is not supported for reasoning models',\n        });\n      }\n\n      if (baseArgs.top_logprobs != null) {\n        baseArgs.top_logprobs = undefined;\n        warnings.push({\n          type: 'other',\n          message: 'topLogprobs is not supported for reasoning models',\n        });\n      }\n\n      // reasoning models use max_completion_tokens instead of max_tokens:\n      if (baseArgs.max_tokens != null) {\n        if (baseArgs.max_completion_tokens == null) {\n          baseArgs.max_completion_tokens = baseArgs.max_tokens;\n        }\n        baseArgs.max_tokens = undefined;\n      }\n    } else if (\n      this.modelId.startsWith('gpt-4o-search-preview') ||\n      this.modelId.startsWith('gpt-4o-mini-search-preview')\n    ) {\n      if (baseArgs.temperature != null) {\n        baseArgs.temperature = undefined;\n        warnings.push({\n          type: 'unsupported',\n          feature: 'temperature',\n          details:\n            'temperature is not supported for the search preview models and has been removed.',\n        });\n      }\n    }\n\n    // Validate flex processing support\n    if (\n      openaiOptions.serviceTier === 'flex' &&\n      !modelCapabilities.supportsFlexProcessing\n    ) {\n      warnings.push({\n        type: 'unsupported',\n        feature: 'serviceTier',\n        details:\n          'flex processing is only available for o3, o4-mini, and gpt-5 models',\n      });\n      baseArgs.service_tier = undefined;\n    }\n\n    // Validate priority processing support\n    if (\n      openaiOptions.serviceTier === 'priority' &&\n      !modelCapabilities.supportsPriorityProcessing\n    ) {\n      warnings.push({\n        type: 'unsupported',\n        feature: 'serviceTier',\n        details:\n          'priority processing is only available for supported models (gpt-4, gpt-5, gpt-5-mini, o3, o4-mini) and requires Enterprise access. gpt-5-nano is not supported',\n      });\n      baseArgs.service_tier = undefined;\n    }\n\n    const {\n      tools: openaiTools,\n      toolChoice: openaiToolChoice,\n      toolWarnings,\n    } = prepareChatTools({\n      tools,\n      toolChoice,\n    });\n\n    return {\n      args: {\n        ...baseArgs,\n        tools: openaiTools,\n        tool_choice: openaiToolChoice,\n      },\n      warnings: [...warnings, ...toolWarnings],\n    };\n  }\n\n  async doGenerate(\n    options: LanguageModelV3CallOptions,\n  ): Promise<LanguageModelV3GenerateResult> {\n    const { args: body, warnings } = await this.getArgs(options);\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/chat/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiChatResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const choice = response.choices[0];\n    const content: Array<LanguageModelV3Content> = [];\n\n    // text content:\n    const text = choice.message.content;\n    if (text != null && text.length > 0) {\n      content.push({ type: 'text', text });\n    }\n\n    // tool calls:\n    for (const toolCall of choice.message.tool_calls ?? []) {\n      content.push({\n        type: 'tool-call' as const,\n        toolCallId: toolCall.id ?? generateId(),\n        toolName: toolCall.function.name,\n        input: toolCall.function.arguments!,\n      });\n    }\n\n    // annotations/citations:\n    for (const annotation of choice.message.annotations ?? []) {\n      content.push({\n        type: 'source',\n        sourceType: 'url',\n        id: generateId(),\n        url: annotation.url_citation.url,\n        title: annotation.url_citation.title,\n      });\n    }\n\n    // provider metadata:\n    const completionTokenDetails = response.usage?.completion_tokens_details;\n    const promptTokenDetails = response.usage?.prompt_tokens_details;\n    const providerMetadata: SharedV3ProviderMetadata = { openai: {} };\n    if (completionTokenDetails?.accepted_prediction_tokens != null) {\n      providerMetadata.openai.acceptedPredictionTokens =\n        completionTokenDetails?.accepted_prediction_tokens;\n    }\n    if (completionTokenDetails?.rejected_prediction_tokens != null) {\n      providerMetadata.openai.rejectedPredictionTokens =\n        completionTokenDetails?.rejected_prediction_tokens;\n    }\n    if (choice.logprobs?.content != null) {\n      providerMetadata.openai.logprobs = choice.logprobs.content;\n    }\n\n    return {\n      content,\n      finishReason: {\n        unified: mapOpenAIFinishReason(choice.finish_reason),\n        raw: choice.finish_reason ?? undefined,\n      },\n      usage: convertOpenAIChatUsage(response.usage),\n      request: { body },\n      response: {\n        ...getResponseMetadata(response),\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n      warnings,\n      providerMetadata,\n    };\n  }\n\n  async doStream(\n    options: LanguageModelV3CallOptions,\n  ): Promise<LanguageModelV3StreamResult> {\n    const { args, warnings } = await this.getArgs(options);\n\n    const body = {\n      ...args,\n      stream: true,\n      stream_options: {\n        include_usage: true,\n      },\n    };\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/chat/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiChatChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const toolCalls: Array<{\n      id: string;\n      type: 'function';\n      function: {\n        name: string;\n        arguments: string;\n      };\n      hasFinished: boolean;\n    }> = [];\n\n    let finishReason: LanguageModelV3FinishReason = {\n      unified: 'other',\n      raw: undefined,\n    };\n    let usage: OpenAIChatUsage | undefined = undefined;\n    let metadataExtracted = false;\n    let isActiveText = false;\n\n    const providerMetadata: SharedV3ProviderMetadata = { openai: {} };\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<OpenAIChatChunk>,\n          LanguageModelV3StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = { unified: 'error', raw: undefined };\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            // handle error chunks:\n            if ('error' in value) {\n              finishReason = { unified: 'error', raw: undefined };\n              controller.enqueue({ type: 'error', error: value.error });\n              return;\n            }\n\n            // extract and emit response metadata once. Usually it comes in the first chunk.\n            // Azure may prepend a chunk with a `\"prompt_filter_results\"` key which does not contain other metadata,\n            // https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/content-filter-annotations?tabs=powershell\n            if (!metadataExtracted) {\n              const metadata = getResponseMetadata(value);\n              if (Object.values(metadata).some(Boolean)) {\n                metadataExtracted = true;\n                controller.enqueue({\n                  type: 'response-metadata',\n                  ...getResponseMetadata(value),\n                });\n              }\n            }\n\n            if (value.usage != null) {\n              usage = value.usage;\n\n              if (\n                value.usage.completion_tokens_details\n                  ?.accepted_prediction_tokens != null\n              ) {\n                providerMetadata.openai.acceptedPredictionTokens =\n                  value.usage.completion_tokens_details?.accepted_prediction_tokens;\n              }\n              if (\n                value.usage.completion_tokens_details\n                  ?.rejected_prediction_tokens != null\n              ) {\n                providerMetadata.openai.rejectedPredictionTokens =\n                  value.usage.completion_tokens_details?.rejected_prediction_tokens;\n              }\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = {\n                unified: mapOpenAIFinishReason(choice.finish_reason),\n                raw: choice.finish_reason,\n              };\n            }\n\n            if (choice?.logprobs?.content != null) {\n              providerMetadata.openai.logprobs = choice.logprobs.content;\n            }\n\n            if (choice?.delta == null) {\n              return;\n            }\n\n            const delta = choice.delta;\n\n            if (delta.content != null) {\n              if (!isActiveText) {\n                controller.enqueue({ type: 'text-start', id: '0' });\n                isActiveText = true;\n              }\n\n              controller.enqueue({\n                type: 'text-delta',\n                id: '0',\n                delta: delta.content,\n              });\n            }\n\n            if (delta.tool_calls != null) {\n              for (const toolCallDelta of delta.tool_calls) {\n                const index = toolCallDelta.index;\n\n                // Tool call start. OpenAI returns all information except the arguments in the first chunk.\n                if (toolCalls[index] == null) {\n                  if (toolCallDelta.type !== 'function') {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function' type.`,\n                    });\n                  }\n\n                  if (toolCallDelta.id == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'id' to be a string.`,\n                    });\n                  }\n\n                  if (toolCallDelta.function?.name == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function.name' to be a string.`,\n                    });\n                  }\n\n                  controller.enqueue({\n                    type: 'tool-input-start',\n                    id: toolCallDelta.id,\n                    toolName: toolCallDelta.function.name,\n                  });\n\n                  toolCalls[index] = {\n                    id: toolCallDelta.id,\n                    type: 'function',\n                    function: {\n                      name: toolCallDelta.function.name,\n                      arguments: toolCallDelta.function.arguments ?? '',\n                    },\n                    hasFinished: false,\n                  };\n\n                  const toolCall = toolCalls[index];\n\n                  if (\n                    toolCall.function?.name != null &&\n                    toolCall.function?.arguments != null\n                  ) {\n                    // send delta if the argument text has already started:\n                    if (toolCall.function.arguments.length > 0) {\n                      controller.enqueue({\n                        type: 'tool-input-delta',\n                        id: toolCall.id,\n                        delta: toolCall.function.arguments,\n                      });\n                    }\n\n                    // check if tool call is complete\n                    // (some providers send the full tool call in one chunk):\n                    if (isParsableJson(toolCall.function.arguments)) {\n                      controller.enqueue({\n                        type: 'tool-input-end',\n                        id: toolCall.id,\n                      });\n\n                      controller.enqueue({\n                        type: 'tool-call',\n                        toolCallId: toolCall.id ?? generateId(),\n                        toolName: toolCall.function.name,\n                        input: toolCall.function.arguments,\n                      });\n                      toolCall.hasFinished = true;\n                    }\n                  }\n\n                  continue;\n                }\n\n                // existing tool call, merge if not finished\n                const toolCall = toolCalls[index];\n\n                if (toolCall.hasFinished) {\n                  continue;\n                }\n\n                if (toolCallDelta.function?.arguments != null) {\n                  toolCall.function!.arguments +=\n                    toolCallDelta.function?.arguments ?? '';\n                }\n\n                // send delta\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.id,\n                  delta: toolCallDelta.function.arguments ?? '',\n                });\n\n                // check if tool call is complete\n                if (\n                  toolCall.function?.name != null &&\n                  toolCall.function?.arguments != null &&\n                  isParsableJson(toolCall.function.arguments)\n                ) {\n                  controller.enqueue({\n                    type: 'tool-input-end',\n                    id: toolCall.id,\n                  });\n\n                  controller.enqueue({\n                    type: 'tool-call',\n                    toolCallId: toolCall.id ?? generateId(),\n                    toolName: toolCall.function.name,\n                    input: toolCall.function.arguments,\n                  });\n                  toolCall.hasFinished = true;\n                }\n              }\n            }\n\n            // annotations/citations:\n            if (delta.annotations != null) {\n              for (const annotation of delta.annotations) {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'url',\n                  id: generateId(),\n                  url: annotation.url_citation.url,\n                  title: annotation.url_citation.title,\n                });\n              }\n            }\n          },\n\n          flush(controller) {\n            if (isActiveText) {\n              controller.enqueue({ type: 'text-end', id: '0' });\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage: convertOpenAIChatUsage(usage),\n              ...(providerMetadata != null ? { providerMetadata } : {}),\n            });\n          },\n        }),\n      ),\n      request: { body },\n      response: { headers: responseHeaders },\n    };\n  }\n}\n","import { z } from 'zod/v4';\nimport { createJsonErrorResponseHandler } from '@ai-sdk/provider-utils';\n\nexport const openaiErrorDataSchema = z.object({\n  error: z.object({\n    message: z.string(),\n\n    // The additional information below is handled loosely to support\n    // OpenAI-compatible providers that have slightly different error\n    // responses:\n    type: z.string().nullish(),\n    param: z.any().nullish(),\n    code: z.union([z.string(), z.number()]).nullish(),\n  }),\n});\n\nexport type OpenAIErrorData = z.infer<typeof openaiErrorDataSchema>;\n\nexport const openaiFailedResponseHandler = createJsonErrorResponseHandler({\n  errorSchema: openaiErrorDataSchema,\n  errorToMessage: data => data.error.message,\n});\n","export type OpenAILanguageModelCapabilities = {\n  isReasoningModel: boolean;\n  systemMessageMode: 'remove' | 'system' | 'developer';\n  supportsFlexProcessing: boolean;\n  supportsPriorityProcessing: boolean;\n\n  /**\n   * Allow temperature, topP, logProbs when reasoningEffort is none.\n   */\n  supportsNonReasoningParameters: boolean;\n};\n\nexport function getOpenAILanguageModelCapabilities(\n  modelId: string,\n): OpenAILanguageModelCapabilities {\n  const supportsFlexProcessing =\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini') ||\n    (modelId.startsWith('gpt-5') && !modelId.startsWith('gpt-5-chat'));\n\n  const supportsPriorityProcessing =\n    modelId.startsWith('gpt-4') ||\n    modelId.startsWith('gpt-5-mini') ||\n    (modelId.startsWith('gpt-5') &&\n      !modelId.startsWith('gpt-5-nano') &&\n      !modelId.startsWith('gpt-5-chat')) ||\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini');\n\n  // Use allowlist approach: only known reasoning models should use 'developer' role\n  // This prevents issues with fine-tuned models, third-party models, and custom models\n  const isReasoningModel =\n    modelId.startsWith('o1') ||\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini') ||\n    modelId.startsWith('codex-mini') ||\n    modelId.startsWith('computer-use-preview') ||\n    (modelId.startsWith('gpt-5') && !modelId.startsWith('gpt-5-chat'));\n\n  // https://platform.openai.com/docs/guides/latest-model#gpt-5-1-parameter-compatibility\n  // GPT-5.1 and GPT-5.2 support temperature, topP, logProbs when reasoningEffort is none\n  const supportsNonReasoningParameters =\n    modelId.startsWith('gpt-5.1') || modelId.startsWith('gpt-5.2');\n\n  const systemMessageMode = isReasoningModel ? 'developer' : 'system';\n\n  return {\n    supportsFlexProcessing,\n    supportsPriorityProcessing,\n    isReasoningModel,\n    systemMessageMode,\n    supportsNonReasoningParameters,\n  };\n}\n","import { LanguageModelV3Usage } from '@ai-sdk/provider';\n\nexport type OpenAIChatUsage = {\n  prompt_tokens?: number | null;\n  completion_tokens?: number | null;\n  total_tokens?: number | null;\n  prompt_tokens_details?: {\n    cached_tokens?: number | null;\n  } | null;\n  completion_tokens_details?: {\n    reasoning_tokens?: number | null;\n    accepted_prediction_tokens?: number | null;\n    rejected_prediction_tokens?: number | null;\n  } | null;\n};\n\nexport function convertOpenAIChatUsage(\n  usage: OpenAIChatUsage | undefined | null,\n): LanguageModelV3Usage {\n  if (usage == null) {\n    return {\n      inputTokens: {\n        total: undefined,\n        noCache: undefined,\n        cacheRead: undefined,\n        cacheWrite: undefined,\n      },\n      outputTokens: {\n        total: undefined,\n        text: undefined,\n        reasoning: undefined,\n      },\n      raw: undefined,\n    };\n  }\n\n  const promptTokens = usage.prompt_tokens ?? 0;\n  const completionTokens = usage.completion_tokens ?? 0;\n  const cachedTokens = usage.prompt_tokens_details?.cached_tokens ?? 0;\n  const reasoningTokens =\n    usage.completion_tokens_details?.reasoning_tokens ?? 0;\n\n  return {\n    inputTokens: {\n      total: promptTokens,\n      noCache: promptTokens - cachedTokens,\n      cacheRead: cachedTokens,\n      cacheWrite: undefined,\n    },\n    outputTokens: {\n      total: completionTokens,\n      text: completionTokens - reasoningTokens,\n      reasoning: reasoningTokens,\n    },\n    raw: usage,\n  };\n}\n","import {\n  SharedV3Warning,\n  LanguageModelV3Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { OpenAIChatPrompt } from './openai-chat-prompt';\nimport { convertToBase64 } from '@ai-sdk/provider-utils';\n\nexport function convertToOpenAIChatMessages({\n  prompt,\n  systemMessageMode = 'system',\n}: {\n  prompt: LanguageModelV3Prompt;\n  systemMessageMode?: 'system' | 'developer' | 'remove';\n}): {\n  messages: OpenAIChatPrompt;\n  warnings: Array<SharedV3Warning>;\n} {\n  const messages: OpenAIChatPrompt = [];\n  const warnings: Array<SharedV3Warning> = [];\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        switch (systemMessageMode) {\n          case 'system': {\n            messages.push({ role: 'system', content });\n            break;\n          }\n          case 'developer': {\n            messages.push({ role: 'developer', content });\n            break;\n          }\n          case 'remove': {\n            warnings.push({\n              type: 'other',\n              message: 'system messages are removed for this model',\n            });\n            break;\n          }\n          default: {\n            const _exhaustiveCheck: never = systemMessageMode;\n            throw new Error(\n              `Unsupported system message mode: ${_exhaustiveCheck}`,\n            );\n          }\n        }\n        break;\n      }\n\n      case 'user': {\n        if (content.length === 1 && content[0].type === 'text') {\n          messages.push({ role: 'user', content: content[0].text });\n          break;\n        }\n\n        messages.push({\n          role: 'user',\n          content: content.map((part, index) => {\n            switch (part.type) {\n              case 'text': {\n                return { type: 'text', text: part.text };\n              }\n              case 'file': {\n                if (part.mediaType.startsWith('image/')) {\n                  const mediaType =\n                    part.mediaType === 'image/*'\n                      ? 'image/jpeg'\n                      : part.mediaType;\n\n                  return {\n                    type: 'image_url',\n                    image_url: {\n                      url:\n                        part.data instanceof URL\n                          ? part.data.toString()\n                          : `data:${mediaType};base64,${convertToBase64(part.data)}`,\n\n                      // OpenAI specific extension: image detail\n                      detail: part.providerOptions?.openai?.imageDetail,\n                    },\n                  };\n                } else if (part.mediaType.startsWith('audio/')) {\n                  if (part.data instanceof URL) {\n                    throw new UnsupportedFunctionalityError({\n                      functionality: 'audio file parts with URLs',\n                    });\n                  }\n\n                  switch (part.mediaType) {\n                    case 'audio/wav': {\n                      return {\n                        type: 'input_audio',\n                        input_audio: {\n                          data: convertToBase64(part.data),\n                          format: 'wav',\n                        },\n                      };\n                    }\n                    case 'audio/mp3':\n                    case 'audio/mpeg': {\n                      return {\n                        type: 'input_audio',\n                        input_audio: {\n                          data: convertToBase64(part.data),\n                          format: 'mp3',\n                        },\n                      };\n                    }\n\n                    default: {\n                      throw new UnsupportedFunctionalityError({\n                        functionality: `audio content parts with media type ${part.mediaType}`,\n                      });\n                    }\n                  }\n                } else if (part.mediaType === 'application/pdf') {\n                  if (part.data instanceof URL) {\n                    throw new UnsupportedFunctionalityError({\n                      functionality: 'PDF file parts with URLs',\n                    });\n                  }\n\n                  return {\n                    type: 'file',\n                    file:\n                      typeof part.data === 'string' &&\n                      part.data.startsWith('file-')\n                        ? { file_id: part.data }\n                        : {\n                            filename: part.filename ?? `part-${index}.pdf`,\n                            file_data: `data:application/pdf;base64,${convertToBase64(part.data)}`,\n                          },\n                  };\n                } else {\n                  throw new UnsupportedFunctionalityError({\n                    functionality: `file part media type ${part.mediaType}`,\n                  });\n                }\n              }\n            }\n          }),\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        let text = '';\n        const toolCalls: Array<{\n          id: string;\n          type: 'function';\n          function: { name: string; arguments: string };\n        }> = [];\n\n        for (const part of content) {\n          switch (part.type) {\n            case 'text': {\n              text += part.text;\n              break;\n            }\n            case 'tool-call': {\n              toolCalls.push({\n                id: part.toolCallId,\n                type: 'function',\n                function: {\n                  name: part.toolName,\n                  arguments: JSON.stringify(part.input),\n                },\n              });\n              break;\n            }\n          }\n        }\n\n        messages.push({\n          role: 'assistant',\n          content: text,\n          tool_calls: toolCalls.length > 0 ? toolCalls : undefined,\n        });\n\n        break;\n      }\n\n      case 'tool': {\n        for (const toolResponse of content) {\n          if (toolResponse.type === 'tool-approval-response') {\n            continue;\n          }\n          const output = toolResponse.output;\n\n          let contentValue: string;\n          switch (output.type) {\n            case 'text':\n            case 'error-text':\n              contentValue = output.value;\n              break;\n            case 'execution-denied':\n              contentValue = output.reason ?? 'Tool execution denied.';\n              break;\n            case 'content':\n            case 'json':\n            case 'error-json':\n              contentValue = JSON.stringify(output.value);\n              break;\n          }\n\n          messages.push({\n            role: 'tool',\n            tool_call_id: toolResponse.toolCallId,\n            content: contentValue,\n          });\n        }\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  return { messages, warnings };\n}\n","export function getResponseMetadata({\n  id,\n  model,\n  created,\n}: {\n  id?: string | undefined | null;\n  created?: number | undefined | null;\n  model?: string | undefined | null;\n}) {\n  return {\n    id: id ?? undefined,\n    modelId: model ?? undefined,\n    timestamp: created ? new Date(created * 1000) : undefined,\n  };\n}\n","import { LanguageModelV3FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAIFinishReason(\n  finishReason: string | null | undefined,\n): LanguageModelV3FinishReason['unified'] {\n  switch (finishReason) {\n    case 'stop':\n      return 'stop';\n    case 'length':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    case 'function_call':\n    case 'tool_calls':\n      return 'tool-calls';\n    default:\n      return 'other';\n  }\n}\n","import { JSONSchema7 } from '@ai-sdk/provider';\nimport { InferSchema, lazySchema, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { openaiErrorDataSchema } from '../openai-error';\n\nexport interface OpenAIChatFunctionTool {\n  type: 'function';\n  function: {\n    name: string;\n    description: string | undefined;\n    parameters: JSONSchema7;\n    strict?: boolean;\n  };\n}\n\nexport type OpenAIChatToolChoice =\n  | 'auto'\n  | 'none'\n  | 'required'\n  | { type: 'function'; function: { name: string } };\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nexport const openaiChatResponseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      id: z.string().nullish(),\n      created: z.number().nullish(),\n      model: z.string().nullish(),\n      choices: z.array(\n        z.object({\n          message: z.object({\n            role: z.literal('assistant').nullish(),\n            content: z.string().nullish(),\n            tool_calls: z\n              .array(\n                z.object({\n                  id: z.string().nullish(),\n                  type: z.literal('function'),\n                  function: z.object({\n                    name: z.string(),\n                    arguments: z.string(),\n                  }),\n                }),\n              )\n              .nullish(),\n            annotations: z\n              .array(\n                z.object({\n                  type: z.literal('url_citation'),\n                  url_citation: z.object({\n                    start_index: z.number(),\n                    end_index: z.number(),\n                    url: z.string(),\n                    title: z.string(),\n                  }),\n                }),\n              )\n              .nullish(),\n          }),\n          index: z.number(),\n          logprobs: z\n            .object({\n              content: z\n                .array(\n                  z.object({\n                    token: z.string(),\n                    logprob: z.number(),\n                    top_logprobs: z.array(\n                      z.object({\n                        token: z.string(),\n                        logprob: z.number(),\n                      }),\n                    ),\n                  }),\n                )\n                .nullish(),\n            })\n            .nullish(),\n          finish_reason: z.string().nullish(),\n        }),\n      ),\n      usage: z\n        .object({\n          prompt_tokens: z.number().nullish(),\n          completion_tokens: z.number().nullish(),\n          total_tokens: z.number().nullish(),\n          prompt_tokens_details: z\n            .object({\n              cached_tokens: z.number().nullish(),\n            })\n            .nullish(),\n          completion_tokens_details: z\n            .object({\n              reasoning_tokens: z.number().nullish(),\n              accepted_prediction_tokens: z.number().nullish(),\n              rejected_prediction_tokens: z.number().nullish(),\n            })\n            .nullish(),\n        })\n        .nullish(),\n    }),\n  ),\n);\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nexport const openaiChatChunkSchema = lazySchema(() =>\n  zodSchema(\n    z.union([\n      z.object({\n        id: z.string().nullish(),\n        created: z.number().nullish(),\n        model: z.string().nullish(),\n        choices: z.array(\n          z.object({\n            delta: z\n              .object({\n                role: z.enum(['assistant']).nullish(),\n                content: z.string().nullish(),\n                tool_calls: z\n                  .array(\n                    z.object({\n                      index: z.number(),\n                      id: z.string().nullish(),\n                      type: z.literal('function').nullish(),\n                      function: z.object({\n                        name: z.string().nullish(),\n                        arguments: z.string().nullish(),\n                      }),\n                    }),\n                  )\n                  .nullish(),\n                annotations: z\n                  .array(\n                    z.object({\n                      type: z.literal('url_citation'),\n                      url_citation: z.object({\n                        start_index: z.number(),\n                        end_index: z.number(),\n                        url: z.string(),\n                        title: z.string(),\n                      }),\n                    }),\n                  )\n                  .nullish(),\n              })\n              .nullish(),\n            logprobs: z\n              .object({\n                content: z\n                  .array(\n                    z.object({\n                      token: z.string(),\n                      logprob: z.number(),\n                      top_logprobs: z.array(\n                        z.object({\n                          token: z.string(),\n                          logprob: z.number(),\n                        }),\n                      ),\n                    }),\n                  )\n                  .nullish(),\n              })\n              .nullish(),\n            finish_reason: z.string().nullish(),\n            index: z.number(),\n          }),\n        ),\n        usage: z\n          .object({\n            prompt_tokens: z.number().nullish(),\n            completion_tokens: z.number().nullish(),\n            total_tokens: z.number().nullish(),\n            prompt_tokens_details: z\n              .object({\n                cached_tokens: z.number().nullish(),\n              })\n              .nullish(),\n            completion_tokens_details: z\n              .object({\n                reasoning_tokens: z.number().nullish(),\n                accepted_prediction_tokens: z.number().nullish(),\n                rejected_prediction_tokens: z.number().nullish(),\n              })\n              .nullish(),\n          })\n          .nullish(),\n      }),\n      openaiErrorDataSchema,\n    ]),\n  ),\n);\n\nexport type OpenAIChatResponse = InferSchema<typeof openaiChatResponseSchema>;\n\nexport type OpenAIChatChunk = InferSchema<typeof openaiChatChunkSchema>;\n","import { InferSchema, lazySchema, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// https://platform.openai.com/docs/models\nexport type OpenAIChatModelId =\n  | 'o1'\n  | 'o1-2024-12-17'\n  | 'o3-mini'\n  | 'o3-mini-2025-01-31'\n  | 'o3'\n  | 'o3-2025-04-16'\n  | 'gpt-4.1'\n  | 'gpt-4.1-2025-04-14'\n  | 'gpt-4.1-mini'\n  | 'gpt-4.1-mini-2025-04-14'\n  | 'gpt-4.1-nano'\n  | 'gpt-4.1-nano-2025-04-14'\n  | 'gpt-4o'\n  | 'gpt-4o-2024-05-13'\n  | 'gpt-4o-2024-08-06'\n  | 'gpt-4o-2024-11-20'\n  | 'gpt-4o-mini'\n  | 'gpt-4o-mini-2024-07-18'\n  | 'gpt-4-turbo'\n  | 'gpt-4-turbo-2024-04-09'\n  | 'gpt-4'\n  | 'gpt-4-0613'\n  | 'gpt-4.5-preview'\n  | 'gpt-4.5-preview-2025-02-27'\n  | 'gpt-3.5-turbo-0125'\n  | 'gpt-3.5-turbo'\n  | 'gpt-3.5-turbo-1106'\n  | 'chatgpt-4o-latest'\n  | 'gpt-5'\n  | 'gpt-5-2025-08-07'\n  | 'gpt-5-mini'\n  | 'gpt-5-mini-2025-08-07'\n  | 'gpt-5-nano'\n  | 'gpt-5-nano-2025-08-07'\n  | 'gpt-5-chat-latest'\n  | 'gpt-5.1'\n  | 'gpt-5.1-chat-latest'\n  | 'gpt-5.2'\n  | 'gpt-5.2-chat-latest'\n  | 'gpt-5.2-pro'\n  | (string & {});\n\nexport const openaiChatLanguageModelOptions = lazySchema(() =>\n  zodSchema(\n    z.object({\n      /**\n       * Modify the likelihood of specified tokens appearing in the completion.\n       *\n       * Accepts a JSON object that maps tokens (specified by their token ID in\n       * the GPT tokenizer) to an associated bias value from -100 to 100.\n       */\n      logitBias: z.record(z.coerce.number<string>(), z.number()).optional(),\n\n      /**\n       * Return the log probabilities of the tokens.\n       *\n       * Setting to true will return the log probabilities of the tokens that\n       * were generated.\n       *\n       * Setting to a number will return the log probabilities of the top n\n       * tokens that were generated.\n       */\n      logprobs: z.union([z.boolean(), z.number()]).optional(),\n\n      /**\n       * Whether to enable parallel function calling during tool use. Default to true.\n       */\n      parallelToolCalls: z.boolean().optional(),\n\n      /**\n       * A unique identifier representing your end-user, which can help OpenAI to\n       * monitor and detect abuse.\n       */\n      user: z.string().optional(),\n\n      /**\n       * Reasoning effort for reasoning models. Defaults to `medium`.\n       */\n      reasoningEffort: z\n        .enum(['none', 'minimal', 'low', 'medium', 'high', 'xhigh'])\n        .optional(),\n\n      /**\n       * Maximum number of completion tokens to generate. Useful for reasoning models.\n       */\n      maxCompletionTokens: z.number().optional(),\n\n      /**\n       * Whether to enable persistence in responses API.\n       */\n      store: z.boolean().optional(),\n\n      /**\n       * Metadata to associate with the request.\n       */\n      metadata: z.record(z.string().max(64), z.string().max(512)).optional(),\n\n      /**\n       * Parameters for prediction mode.\n       */\n      prediction: z.record(z.string(), z.any()).optional(),\n\n      /**\n       * Service tier for the request.\n       * - 'auto': Default service tier. The request will be processed with the service tier configured in the\n       *           Project settings. Unless otherwise configured, the Project will use 'default'.\n       * - 'flex': 50% cheaper processing at the cost of increased latency. Only available for o3 and o4-mini models.\n       * - 'priority': Higher-speed processing with predictably low latency at premium cost. Available for Enterprise customers.\n       * - 'default': The request will be processed with the standard pricing and performance for the selected model.\n       *\n       * @default 'auto'\n       */\n      serviceTier: z.enum(['auto', 'flex', 'priority', 'default']).optional(),\n\n      /**\n       * Whether to use strict JSON schema validation.\n       *\n       * @default true\n       */\n      strictJsonSchema: z.boolean().optional(),\n\n      /**\n       * Controls the verbosity of the model's responses.\n       * Lower values will result in more concise responses, while higher values will result in more verbose responses.\n       */\n      textVerbosity: z.enum(['low', 'medium', 'high']).optional(),\n\n      /**\n       * A cache key for prompt caching. Allows manual control over prompt caching behavior.\n       * Useful for improving cache hit rates and working around automatic caching issues.\n       */\n      promptCacheKey: z.string().optional(),\n\n      /**\n       * The retention policy for the prompt cache.\n       * - 'in_memory': Default. Standard prompt caching behavior.\n       * - '24h': Extended prompt caching that keeps cached prefixes active for up to 24 hours.\n       *          Currently only available for 5.1 series models.\n       *\n       * @default 'in_memory'\n       */\n      promptCacheRetention: z.enum(['in_memory', '24h']).optional(),\n\n      /**\n       * A stable identifier used to help detect users of your application\n       * that may be violating OpenAI's usage policies. The IDs should be a\n       * string that uniquely identifies each user. We recommend hashing their\n       * username or email address, in order to avoid sending us any identifying\n       * information.\n       */\n      safetyIdentifier: z.string().optional(),\n\n      /**\n       * Override the system message mode for this model.\n       * - 'system': Use the 'system' role for system messages (default for most models)\n       * - 'developer': Use the 'developer' role for system messages (used by reasoning models)\n       * - 'remove': Remove system messages entirely\n       *\n       * If not specified, the mode is automatically determined based on the model.\n       */\n      systemMessageMode: z.enum(['system', 'developer', 'remove']).optional(),\n\n      /**\n       * Force treating this model as a reasoning model.\n       *\n       * This is useful for \"stealth\" reasoning models (e.g. via a custom baseURL)\n       * where the model ID is not recognized by the SDK's allowlist.\n       *\n       * When enabled, the SDK applies reasoning-model parameter compatibility rules\n       * and defaults `systemMessageMode` to `developer` unless overridden.\n       */\n      forceReasoning: z.boolean().optional(),\n    }),\n  ),\n);\n\nexport type OpenAIChatLanguageModelOptions = InferSchema<\n  typeof openaiChatLanguageModelOptions\n>;\n","import {\n  LanguageModelV3CallOptions,\n  SharedV3Warning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport {\n  OpenAIChatToolChoice,\n  OpenAIChatFunctionTool,\n} from './openai-chat-api';\n\nexport function prepareChatTools({\n  tools,\n  toolChoice,\n}: {\n  tools: LanguageModelV3CallOptions['tools'];\n  toolChoice?: LanguageModelV3CallOptions['toolChoice'];\n}): {\n  tools?: OpenAIChatFunctionTool[];\n  toolChoice?: OpenAIChatToolChoice;\n  toolWarnings: Array<SharedV3Warning>;\n} {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  tools = tools?.length ? tools : undefined;\n\n  const toolWarnings: SharedV3Warning[] = [];\n\n  if (tools == null) {\n    return { tools: undefined, toolChoice: undefined, toolWarnings };\n  }\n\n  const openaiTools: OpenAIChatFunctionTool[] = [];\n\n  for (const tool of tools) {\n    switch (tool.type) {\n      case 'function':\n        openaiTools.push({\n          type: 'function',\n          function: {\n            name: tool.name,\n            description: tool.description,\n            parameters: tool.inputSchema,\n            ...(tool.strict != null ? { strict: tool.strict } : {}),\n          },\n        });\n        break;\n      default:\n        toolWarnings.push({\n          type: 'unsupported',\n          feature: `tool type: ${tool.type}`,\n        });\n        break;\n    }\n  }\n\n  if (toolChoice == null) {\n    return { tools: openaiTools, toolChoice: undefined, toolWarnings };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n    case 'none':\n    case 'required':\n      return { tools: openaiTools, toolChoice: type, toolWarnings };\n    case 'tool':\n      return {\n        tools: openaiTools,\n        toolChoice: {\n          type: 'function',\n          function: {\n            name: toolChoice.toolName,\n          },\n        },\n        toolWarnings,\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new UnsupportedFunctionalityError({\n        functionality: `tool choice type: ${_exhaustiveCheck}`,\n      });\n    }\n  }\n}\n","import {\n  LanguageModelV3,\n  LanguageModelV3CallOptions,\n  LanguageModelV3FinishReason,\n  LanguageModelV3GenerateResult,\n  LanguageModelV3StreamPart,\n  LanguageModelV3StreamResult,\n  SharedV3ProviderMetadata,\n  SharedV3Warning,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  FetchFunction,\n  parseProviderOptions,\n  ParseResult,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport {\n  convertOpenAICompletionUsage,\n  OpenAICompletionUsage,\n} from './convert-openai-completion-usage';\nimport { convertToOpenAICompletionPrompt } from './convert-to-openai-completion-prompt';\nimport { getResponseMetadata } from './get-response-metadata';\nimport { mapOpenAIFinishReason } from './map-openai-finish-reason';\nimport {\n  OpenAICompletionChunk,\n  openaiCompletionChunkSchema,\n  openaiCompletionResponseSchema,\n} from './openai-completion-api';\nimport {\n  OpenAICompletionModelId,\n  openaiCompletionProviderOptions,\n} from './openai-completion-options';\n\ntype OpenAICompletionConfig = {\n  provider: string;\n  headers: () => Record<string, string | undefined>;\n  url: (options: { modelId: string; path: string }) => string;\n  fetch?: FetchFunction;\n};\n\nexport class OpenAICompletionLanguageModel implements LanguageModelV3 {\n  readonly specificationVersion = 'v3';\n\n  readonly modelId: OpenAICompletionModelId;\n\n  private readonly config: OpenAICompletionConfig;\n\n  private get providerOptionsName(): string {\n    return this.config.provider.split('.')[0].trim();\n  }\n\n  constructor(\n    modelId: OpenAICompletionModelId,\n    config: OpenAICompletionConfig,\n  ) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  readonly supportedUrls: Record<string, RegExp[]> = {\n    // No URLs are supported for completion models.\n  };\n\n  private async getArgs({\n    prompt,\n    maxOutputTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences: userStopSequences,\n    responseFormat,\n    tools,\n    toolChoice,\n    seed,\n    providerOptions,\n  }: LanguageModelV3CallOptions) {\n    const warnings: SharedV3Warning[] = [];\n\n    // Parse provider options\n    const openaiOptions = {\n      ...(await parseProviderOptions({\n        provider: 'openai',\n        providerOptions,\n        schema: openaiCompletionProviderOptions,\n      })),\n      ...(await parseProviderOptions({\n        provider: this.providerOptionsName,\n        providerOptions,\n        schema: openaiCompletionProviderOptions,\n      })),\n    };\n\n    if (topK != null) {\n      warnings.push({ type: 'unsupported', feature: 'topK' });\n    }\n\n    if (tools?.length) {\n      warnings.push({ type: 'unsupported', feature: 'tools' });\n    }\n\n    if (toolChoice != null) {\n      warnings.push({ type: 'unsupported', feature: 'toolChoice' });\n    }\n\n    if (responseFormat != null && responseFormat.type !== 'text') {\n      warnings.push({\n        type: 'unsupported',\n        feature: 'responseFormat',\n        details: 'JSON response format is not supported.',\n      });\n    }\n\n    const { prompt: completionPrompt, stopSequences } =\n      convertToOpenAICompletionPrompt({ prompt });\n\n    const stop = [...(stopSequences ?? []), ...(userStopSequences ?? [])];\n\n    return {\n      args: {\n        // model id:\n        model: this.modelId,\n\n        // model specific settings:\n        echo: openaiOptions.echo,\n        logit_bias: openaiOptions.logitBias,\n        logprobs:\n          openaiOptions?.logprobs === true\n            ? 0\n            : openaiOptions?.logprobs === false\n              ? undefined\n              : openaiOptions?.logprobs,\n        suffix: openaiOptions.suffix,\n        user: openaiOptions.user,\n\n        // standardized settings:\n        max_tokens: maxOutputTokens,\n        temperature,\n        top_p: topP,\n        frequency_penalty: frequencyPenalty,\n        presence_penalty: presencePenalty,\n        seed,\n\n        // prompt:\n        prompt: completionPrompt,\n\n        // stop sequences:\n        stop: stop.length > 0 ? stop : undefined,\n      },\n      warnings,\n    };\n  }\n\n  async doGenerate(\n    options: LanguageModelV3CallOptions,\n  ): Promise<LanguageModelV3GenerateResult> {\n    const { args, warnings } = await this.getArgs(options);\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: args,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiCompletionResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const choice = response.choices[0];\n\n    const providerMetadata: SharedV3ProviderMetadata = { openai: {} };\n\n    if (choice.logprobs != null) {\n      providerMetadata.openai.logprobs = choice.logprobs;\n    }\n\n    return {\n      content: [{ type: 'text', text: choice.text }],\n      usage: convertOpenAICompletionUsage(response.usage),\n      finishReason: {\n        unified: mapOpenAIFinishReason(choice.finish_reason),\n        raw: choice.finish_reason ?? undefined,\n      },\n      request: { body: args },\n      response: {\n        ...getResponseMetadata(response),\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n      providerMetadata,\n      warnings,\n    };\n  }\n\n  async doStream(\n    options: LanguageModelV3CallOptions,\n  ): Promise<LanguageModelV3StreamResult> {\n    const { args, warnings } = await this.getArgs(options);\n\n    const body = {\n      ...args,\n      stream: true,\n\n      stream_options: {\n        include_usage: true,\n      },\n    };\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiCompletionChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    let finishReason: LanguageModelV3FinishReason = {\n      unified: 'other',\n      raw: undefined,\n    };\n    const providerMetadata: SharedV3ProviderMetadata = { openai: {} };\n    let usage: OpenAICompletionUsage | undefined = undefined;\n    let isFirstChunk = true;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<OpenAICompletionChunk>,\n          LanguageModelV3StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = { unified: 'error', raw: undefined };\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            // handle error chunks:\n            if ('error' in value) {\n              finishReason = { unified: 'error', raw: undefined };\n              controller.enqueue({ type: 'error', error: value.error });\n              return;\n            }\n\n            if (isFirstChunk) {\n              isFirstChunk = false;\n\n              controller.enqueue({\n                type: 'response-metadata',\n                ...getResponseMetadata(value),\n              });\n\n              controller.enqueue({ type: 'text-start', id: '0' });\n            }\n\n            if (value.usage != null) {\n              usage = value.usage;\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = {\n                unified: mapOpenAIFinishReason(choice.finish_reason),\n                raw: choice.finish_reason,\n              };\n            }\n\n            if (choice?.logprobs != null) {\n              providerMetadata.openai.logprobs = choice.logprobs;\n            }\n\n            if (choice?.text != null && choice.text.length > 0) {\n              controller.enqueue({\n                type: 'text-delta',\n                id: '0',\n                delta: choice.text,\n              });\n            }\n          },\n\n          flush(controller) {\n            if (!isFirstChunk) {\n              controller.enqueue({ type: 'text-end', id: '0' });\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              providerMetadata,\n              usage: convertOpenAICompletionUsage(usage),\n            });\n          },\n        }),\n      ),\n      request: { body },\n      response: { headers: responseHeaders },\n    };\n  }\n}\n","import { LanguageModelV3Usage } from '@ai-sdk/provider';\n\nexport type OpenAICompletionUsage = {\n  prompt_tokens?: number | null;\n  completion_tokens?: number | null;\n  total_tokens?: number | null;\n};\n\nexport function convertOpenAICompletionUsage(\n  usage: OpenAICompletionUsage | undefined | null,\n): LanguageModelV3Usage {\n  if (usage == null) {\n    return {\n      inputTokens: {\n        total: undefined,\n        noCache: undefined,\n        cacheRead: undefined,\n        cacheWrite: undefined,\n      },\n      outputTokens: {\n        total: undefined,\n        text: undefined,\n        reasoning: undefined,\n      },\n      raw: undefined,\n    };\n  }\n\n  const promptTokens = usage.prompt_tokens ?? 0;\n  const completionTokens = usage.completion_tokens ?? 0;\n\n  return {\n    inputTokens: {\n      total: usage.prompt_tokens ?? undefined,\n      noCache: promptTokens,\n      cacheRead: undefined,\n      cacheWrite: undefined,\n    },\n    outputTokens: {\n      total: usage.completion_tokens ?? undefined,\n      text: completionTokens,\n      reasoning: undefined,\n    },\n    raw: usage,\n  };\n}\n","import {\n  InvalidPromptError,\n  LanguageModelV3Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\n\nexport function convertToOpenAICompletionPrompt({\n  prompt,\n  user = 'user',\n  assistant = 'assistant',\n}: {\n  prompt: LanguageModelV3Prompt;\n  user?: string;\n  assistant?: string;\n}): {\n  prompt: string;\n  stopSequences?: string[];\n} {\n  // transform to a chat message format:\n  let text = '';\n\n  // if first message is a system message, add it to the text:\n  if (prompt[0].role === 'system') {\n    text += `${prompt[0].content}\\n\\n`;\n    prompt = prompt.slice(1);\n  }\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        throw new InvalidPromptError({\n          message: 'Unexpected system message in prompt: ${content}',\n          prompt,\n        });\n      }\n\n      case 'user': {\n        const userMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n            }\n          })\n          .filter(Boolean)\n          .join('');\n\n        text += `${user}:\\n${userMessage}\\n\\n`;\n        break;\n      }\n\n      case 'assistant': {\n        const assistantMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n              case 'tool-call': {\n                throw new UnsupportedFunctionalityError({\n                  functionality: 'tool-call messages',\n                });\n              }\n            }\n          })\n          .join('');\n\n        text += `${assistant}:\\n${assistantMessage}\\n\\n`;\n        break;\n      }\n\n      case 'tool': {\n        throw new UnsupportedFunctionalityError({\n          functionality: 'tool messages',\n        });\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  // Assistant message prefix:\n  text += `${assistant}:\\n`;\n\n  return {\n    prompt: text,\n    stopSequences: [`\\n${user}:`],\n  };\n}\n","export function getResponseMetadata({\n  id,\n  model,\n  created,\n}: {\n  id?: string | undefined | null;\n  created?: number | undefined | null;\n  model?: string | undefined | null;\n}) {\n  return {\n    id: id ?? undefined,\n    modelId: model ?? undefined,\n    timestamp: created != null ? new Date(created * 1000) : undefined,\n  };\n}\n","import { LanguageModelV3FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAIFinishReason(\n  finishReason: string | null | undefined,\n): LanguageModelV3FinishReason['unified'] {\n  switch (finishReason) {\n    case 'stop':\n      return 'stop';\n    case 'length':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    case 'function_call':\n    case 'tool_calls':\n      return 'tool-calls';\n    default:\n      return 'other';\n  }\n}\n","import { z } from 'zod/v4';\nimport { openaiErrorDataSchema } from '../openai-error';\nimport { InferSchema, lazySchema, zodSchema } from '@ai-sdk/provider-utils';\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nexport const openaiCompletionResponseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      id: z.string().nullish(),\n      created: z.number().nullish(),\n      model: z.string().nullish(),\n      choices: z.array(\n        z.object({\n          text: z.string(),\n          finish_reason: z.string(),\n          logprobs: z\n            .object({\n              tokens: z.array(z.string()),\n              token_logprobs: z.array(z.number()),\n              top_logprobs: z.array(z.record(z.string(), z.number())).nullish(),\n            })\n            .nullish(),\n        }),\n      ),\n      usage: z\n        .object({\n          prompt_tokens: z.number(),\n          completion_tokens: z.number(),\n          total_tokens: z.number(),\n        })\n        .nullish(),\n    }),\n  ),\n);\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nexport const openaiCompletionChunkSchema = lazySchema(() =>\n  zodSchema(\n    z.union([\n      z.object({\n        id: z.string().nullish(),\n        created: z.number().nullish(),\n        model: z.string().nullish(),\n        choices: z.array(\n          z.object({\n            text: z.string(),\n            finish_reason: z.string().nullish(),\n            index: z.number(),\n            logprobs: z\n              .object({\n                tokens: z.array(z.string()),\n                token_logprobs: z.array(z.number()),\n                top_logprobs: z\n                  .array(z.record(z.string(), z.number()))\n                  .nullish(),\n              })\n              .nullish(),\n          }),\n        ),\n        usage: z\n          .object({\n            prompt_tokens: z.number(),\n            completion_tokens: z.number(),\n            total_tokens: z.number(),\n          })\n          .nullish(),\n      }),\n      openaiErrorDataSchema,\n    ]),\n  ),\n);\n\nexport type OpenAICompletionChunk = InferSchema<\n  typeof openaiCompletionChunkSchema\n>;\n\nexport type OpenAICompletionResponse = InferSchema<\n  typeof openaiCompletionResponseSchema\n>;\n","import { InferSchema, lazySchema, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// https://platform.openai.com/docs/models\nexport type OpenAICompletionModelId = 'gpt-3.5-turbo-instruct' | (string & {});\n\nexport const openaiCompletionProviderOptions = lazySchema(() =>\n  zodSchema(\n    z.object({\n      /**\nEcho back the prompt in addition to the completion.\n   */\n      echo: z.boolean().optional(),\n\n      /**\nModify the likelihood of specified tokens appearing in the completion.\n\nAccepts a JSON object that maps tokens (specified by their token ID in\nthe GPT tokenizer) to an associated bias value from -100 to 100. You\ncan use this tokenizer tool to convert text to token IDs. Mathematically,\nthe bias is added to the logits generated by the model prior to sampling.\nThe exact effect will vary per model, but values between -1 and 1 should\ndecrease or increase likelihood of selection; values like -100 or 100\nshould result in a ban or exclusive selection of the relevant token.\n\nAs an example, you can pass {\"50256\": -100} to prevent the <|endoftext|>\ntoken from being generated.\n */\n      logitBias: z.record(z.string(), z.number()).optional(),\n\n      /**\nThe suffix that comes after a completion of inserted text.\n */\n      suffix: z.string().optional(),\n\n      /**\nA unique identifier representing your end-user, which can help OpenAI to\nmonitor and detect abuse. Learn more.\n */\n      user: z.string().optional(),\n\n      /**\nReturn the log probabilities of the tokens. Including logprobs will increase\nthe response size and can slow down response times. However, it can\nbe useful to better understand how the model is behaving.\nSetting to true will return the log probabilities of the tokens that\nwere generated.\nSetting to a number will return the log probabilities of the top n\ntokens that were generated.\n   */\n      logprobs: z.union([z.boolean(), z.number()]).optional(),\n    }),\n  ),\n);\n\nexport type OpenAICompletionProviderOptions = InferSchema<\n  typeof openaiCompletionProviderOptions\n>;\n","import {\n  EmbeddingModelV3,\n  TooManyEmbeddingValuesForCallError,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport {\n  OpenAIEmbeddingModelId,\n  openaiEmbeddingProviderOptions,\n} from './openai-embedding-options';\nimport { openaiTextEmbeddingResponseSchema } from './openai-embedding-api';\n\nexport class OpenAIEmbeddingModel implements EmbeddingModelV3 {\n  readonly specificationVersion = 'v3';\n  readonly modelId: OpenAIEmbeddingModelId;\n  readonly maxEmbeddingsPerCall = 2048;\n  readonly supportsParallelCalls = true;\n\n  private readonly config: OpenAIConfig;\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(modelId: OpenAIEmbeddingModelId, config: OpenAIConfig) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  async doEmbed({\n    values,\n    headers,\n    abortSignal,\n    providerOptions,\n  }: Parameters<EmbeddingModelV3['doEmbed']>[0]): Promise<\n    Awaited<ReturnType<EmbeddingModelV3['doEmbed']>>\n  > {\n    if (values.length > this.maxEmbeddingsPerCall) {\n      throw new TooManyEmbeddingValuesForCallError({\n        provider: this.provider,\n        modelId: this.modelId,\n        maxEmbeddingsPerCall: this.maxEmbeddingsPerCall,\n        values,\n      });\n    }\n\n    // Parse provider options\n    const openaiOptions =\n      (await parseProviderOptions({\n        provider: 'openai',\n        providerOptions,\n        schema: openaiEmbeddingProviderOptions,\n      })) ?? {};\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/embeddings',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        input: values,\n        encoding_format: 'float',\n        dimensions: openaiOptions.dimensions,\n        user: openaiOptions.user,\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiTextEmbeddingResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      warnings: [],\n      embeddings: response.data.map(item => item.embedding),\n      usage: response.usage\n        ? { tokens: response.usage.prompt_tokens }\n        : undefined,\n      response: { headers: responseHeaders, body: rawValue },\n    };\n  }\n}\n","import { InferSchema, lazySchema, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport type OpenAIEmbeddingModelId =\n  | 'text-embedding-3-small'\n  | 'text-embedding-3-large'\n  | 'text-embedding-ada-002'\n  | (string & {});\n\nexport const openaiEmbeddingProviderOptions = lazySchema(() =>\n  zodSchema(\n    z.object({\n      /**\nThe number of dimensions the resulting output embeddings should have.\nOnly supported in text-embedding-3 and later models.\n   */\n      dimensions: z.number().optional(),\n\n      /**\nA unique identifier representing your end-user, which can help OpenAI to\nmonitor and detect abuse. Learn more.\n*/\n      user: z.string().optional(),\n    }),\n  ),\n);\n\nexport type OpenAIEmbeddingProviderOptions = InferSchema<\n  typeof openaiEmbeddingProviderOptions\n>;\n","import { lazySchema, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nexport const openaiTextEmbeddingResponseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      data: z.array(z.object({ embedding: z.array(z.number()) })),\n      usage: z.object({ prompt_tokens: z.number() }).nullish(),\n    }),\n  ),\n);\n","import {\n  ImageModelV3,\n  ImageModelV3File,\n  SharedV3Warning,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  convertBase64ToUint8Array,\n  convertToFormData,\n  createJsonResponseHandler,\n  downloadBlob,\n  postFormDataToApi,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport { openaiImageResponseSchema } from './openai-image-api';\nimport {\n  OpenAIImageModelId,\n  hasDefaultResponseFormat,\n  modelMaxImagesPerCall,\n} from './openai-image-options';\n\ninterface OpenAIImageModelConfig extends OpenAIConfig {\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\nexport class OpenAIImageModel implements ImageModelV3 {\n  readonly specificationVersion = 'v3';\n\n  get maxImagesPerCall(): number {\n    return modelMaxImagesPerCall[this.modelId] ?? 1;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: OpenAIImageModelId,\n    private readonly config: OpenAIImageModelConfig,\n  ) {}\n\n  async doGenerate({\n    prompt,\n    files,\n    mask,\n    n,\n    size,\n    aspectRatio,\n    seed,\n    providerOptions,\n    headers,\n    abortSignal,\n  }: Parameters<ImageModelV3['doGenerate']>[0]): Promise<\n    Awaited<ReturnType<ImageModelV3['doGenerate']>>\n  > {\n    const warnings: Array<SharedV3Warning> = [];\n\n    if (aspectRatio != null) {\n      warnings.push({\n        type: 'unsupported',\n        feature: 'aspectRatio',\n        details:\n          'This model does not support aspect ratio. Use `size` instead.',\n      });\n    }\n\n    if (seed != null) {\n      warnings.push({ type: 'unsupported', feature: 'seed' });\n    }\n\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n\n    if (files != null) {\n      const { value: response, responseHeaders } = await postFormDataToApi({\n        url: this.config.url({\n          path: '/images/edits',\n          modelId: this.modelId,\n        }),\n        headers: combineHeaders(this.config.headers(), headers),\n        formData: convertToFormData<OpenAIImageEditInput>({\n          model: this.modelId,\n          prompt,\n          image: await Promise.all(\n            files.map(file =>\n              file.type === 'file'\n                ? new Blob(\n                    [\n                      file.data instanceof Uint8Array\n                        ? new Blob([file.data as BlobPart], {\n                            type: file.mediaType,\n                          })\n                        : new Blob([convertBase64ToUint8Array(file.data)], {\n                            type: file.mediaType,\n                          }),\n                    ],\n                    { type: file.mediaType },\n                  )\n                : downloadBlob(file.url),\n            ),\n          ),\n          mask: mask != null ? await fileToBlob(mask) : undefined,\n          n,\n          size,\n          ...(providerOptions.openai ?? {}),\n        }),\n        failedResponseHandler: openaiFailedResponseHandler,\n        successfulResponseHandler: createJsonResponseHandler(\n          openaiImageResponseSchema,\n        ),\n        abortSignal,\n        fetch: this.config.fetch,\n      });\n\n      return {\n        images: response.data.map(item => item.b64_json),\n        warnings,\n        usage:\n          response.usage != null\n            ? {\n                inputTokens: response.usage.input_tokens ?? undefined,\n                outputTokens: response.usage.output_tokens ?? undefined,\n                totalTokens: response.usage.total_tokens ?? undefined,\n              }\n            : undefined,\n        response: {\n          timestamp: currentDate,\n          modelId: this.modelId,\n          headers: responseHeaders,\n        },\n        providerMetadata: {\n          openai: {\n            images: response.data.map(item => ({\n              ...(item.revised_prompt\n                ? { revisedPrompt: item.revised_prompt }\n                : {}),\n              created: response.created ?? undefined,\n              size: response.size ?? undefined,\n              quality: response.quality ?? undefined,\n              background: response.background ?? undefined,\n              outputFormat: response.output_format ?? undefined,\n            })),\n          },\n        },\n      };\n    }\n\n    const { value: response, responseHeaders } = await postJsonToApi({\n      url: this.config.url({\n        path: '/images/generations',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        prompt,\n        n,\n        size,\n        ...(providerOptions.openai ?? {}),\n        ...(!hasDefaultResponseFormat.has(this.modelId)\n          ? { response_format: 'b64_json' }\n          : {}),\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiImageResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      images: response.data.map(item => item.b64_json),\n      warnings,\n      usage:\n        response.usage != null\n          ? {\n              inputTokens: response.usage.input_tokens ?? undefined,\n              outputTokens: response.usage.output_tokens ?? undefined,\n              totalTokens: response.usage.total_tokens ?? undefined,\n            }\n          : undefined,\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n      },\n      providerMetadata: {\n        openai: {\n          images: response.data.map(item => ({\n            ...(item.revised_prompt\n              ? { revisedPrompt: item.revised_prompt }\n              : {}),\n            created: response.created ?? undefined,\n            size: response.size ?? undefined,\n            quality: response.quality ?? undefined,\n            background: response.background ?? undefined,\n            outputFormat: response.output_format ?? undefined,\n          })),\n        },\n      },\n    };\n  }\n}\n\ntype OpenAIImageEditInput = {\n  /**\n   * Allows to set transparency for the background of the generated image(s).\n   * This parameter is only supported for `gpt-image-1`. Must be one of\n   * `transparent`, `opaque` or `auto` (default value). When `auto` is used, the\n   * model will automatically determine the best background for the image.\n   *\n   * If `transparent`, the output format needs to support transparency, so it\n   * should be set to either `png` (default value) or `webp`.\n   *\n   */\n  background?: 'transparent' | 'opaque' | 'auto';\n  /**\n   * The image(s) to edit. Must be a supported image file or an array of images.\n   *\n   * For `gpt-image-1`, each image should be a `png`, `webp`, or `jpg` file less\n   * than 50MB. You can provide up to 16 images.\n   *\n   * For `dall-e-2`, you can only provide one image, and it should be a square\n   * `png` file less than 4MB.\n   *\n   */\n  image: Blob | Blob[];\n  input_fidelity?: ('high' | 'low') | null;\n  /**\n   * An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. If there are multiple images provided, the mask will be applied on the first image. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.\n   */\n  mask?: Blob;\n  /**\n   * The model to use for image generation. Only `dall-e-2` and `gpt-image-1` are supported. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1` is used.\n   */\n  model?: 'dall-e-2' | 'gpt-image-1' | 'gpt-image-1-mini' | (string & {});\n  /**\n   * The number of images to generate. Must be between 1 and 10.\n   */\n  n?: number;\n  /**\n   * The compression level (0-100%) for the generated images. This parameter\n   * is only supported for `gpt-image-1` with the `webp` or `jpeg` output\n   * formats, and defaults to 100.\n   *\n   */\n  output_compression?: number;\n  /**\n   * The format in which the generated images are returned. This parameter is\n   * only supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.\n   * The default value is `png`.\n   *\n   */\n  output_format?: 'png' | 'jpeg' | 'webp';\n  partial_images?: number | null;\n  /**\n   * A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2`, and 32000 characters for `gpt-image-1`.\n   */\n  prompt?: string;\n  /**\n   * The quality of the image that will be generated. `high`, `medium` and `low` are only supported for `gpt-image-1`. `dall-e-2` only supports `standard` quality. Defaults to `auto`.\n   *\n   */\n  quality?: 'standard' | 'low' | 'medium' | 'high' | 'auto';\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter is only supported for `dall-e-2`, as `gpt-image-1` will always return base64-encoded images.\n   */\n  response_format?: 'url' | 'b64_json';\n  /**\n   * The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for `gpt-image-1`, and one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`.\n   */\n  size?: `${number}x${number}`;\n  /**\n   * Edit the image in streaming mode. Defaults to `false`. See the\n   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation) for more information.\n   *\n   */\n  stream?: boolean;\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   *\n   */\n  user?: string;\n};\n\nasync function fileToBlob(\n  file: ImageModelV3File | undefined,\n): Promise<Blob | undefined> {\n  if (!file) return undefined;\n\n  if (file.type === 'url') {\n    return downloadBlob(file.url);\n  }\n\n  const data =\n    file.data instanceof Uint8Array\n      ? file.data\n      : convertBase64ToUint8Array(file.data);\n\n  return new Blob([data as BlobPart], { type: file.mediaType });\n}\n","import { lazySchema, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// minimal version of the schema, focused on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nexport const openaiImageResponseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      created: z.number().nullish(),\n      data: z.array(\n        z.object({\n          b64_json: z.string(),\n          revised_prompt: z.string().nullish(),\n        }),\n      ),\n      background: z.string().nullish(),\n      output_format: z.string().nullish(),\n      size: z.string().nullish(),\n      quality: z.string().nullish(),\n      usage: z\n        .object({\n          input_tokens: z.number().nullish(),\n          output_tokens: z.number().nullish(),\n          total_tokens: z.number().nullish(),\n          input_tokens_details: z\n            .object({\n              image_tokens: z.number().nullish(),\n              text_tokens: z.number().nullish(),\n            })\n            .nullish(),\n        })\n        .nullish(),\n    }),\n  ),\n);\n","export type OpenAIImageModelId =\n  | 'dall-e-3'\n  | 'dall-e-2'\n  | 'gpt-image-1'\n  | 'gpt-image-1-mini'\n  | 'gpt-image-1.5'\n  | (string & {});\n\n// https://platform.openai.com/docs/guides/images\nexport const modelMaxImagesPerCall: Record<OpenAIImageModelId, number> = {\n  'dall-e-3': 1,\n  'dall-e-2': 10,\n  'gpt-image-1': 10,\n  'gpt-image-1-mini': 10,\n  'gpt-image-1.5': 10,\n};\n\nexport const hasDefaultResponseFormat = new Set([\n  'gpt-image-1',\n  'gpt-image-1-mini',\n  'gpt-image-1.5',\n]);\n","import {\n  TranscriptionModelV3,\n  TranscriptionModelV3CallOptions,\n  SharedV3Warning,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  convertBase64ToUint8Array,\n  createJsonResponseHandler,\n  mediaTypeToExtension,\n  parseProviderOptions,\n  postFormDataToApi,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport { openaiTranscriptionResponseSchema } from './openai-transcription-api';\nimport {\n  OpenAITranscriptionModelId,\n  openAITranscriptionProviderOptions,\n  OpenAITranscriptionProviderOptions,\n} from './openai-transcription-options';\n\nexport type OpenAITranscriptionCallOptions = Omit<\n  TranscriptionModelV3CallOptions,\n  'providerOptions'\n> & {\n  providerOptions?: {\n    openai?: OpenAITranscriptionProviderOptions;\n  };\n};\n\ninterface OpenAITranscriptionModelConfig extends OpenAIConfig {\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\n// https://platform.openai.com/docs/guides/speech-to-text#supported-languages\nconst languageMap = {\n  afrikaans: 'af',\n  arabic: 'ar',\n  armenian: 'hy',\n  azerbaijani: 'az',\n  belarusian: 'be',\n  bosnian: 'bs',\n  bulgarian: 'bg',\n  catalan: 'ca',\n  chinese: 'zh',\n  croatian: 'hr',\n  czech: 'cs',\n  danish: 'da',\n  dutch: 'nl',\n  english: 'en',\n  estonian: 'et',\n  finnish: 'fi',\n  french: 'fr',\n  galician: 'gl',\n  german: 'de',\n  greek: 'el',\n  hebrew: 'he',\n  hindi: 'hi',\n  hungarian: 'hu',\n  icelandic: 'is',\n  indonesian: 'id',\n  italian: 'it',\n  japanese: 'ja',\n  kannada: 'kn',\n  kazakh: 'kk',\n  korean: 'ko',\n  latvian: 'lv',\n  lithuanian: 'lt',\n  macedonian: 'mk',\n  malay: 'ms',\n  marathi: 'mr',\n  maori: 'mi',\n  nepali: 'ne',\n  norwegian: 'no',\n  persian: 'fa',\n  polish: 'pl',\n  portuguese: 'pt',\n  romanian: 'ro',\n  russian: 'ru',\n  serbian: 'sr',\n  slovak: 'sk',\n  slovenian: 'sl',\n  spanish: 'es',\n  swahili: 'sw',\n  swedish: 'sv',\n  tagalog: 'tl',\n  tamil: 'ta',\n  thai: 'th',\n  turkish: 'tr',\n  ukrainian: 'uk',\n  urdu: 'ur',\n  vietnamese: 'vi',\n  welsh: 'cy',\n};\n\nexport class OpenAITranscriptionModel implements TranscriptionModelV3 {\n  readonly specificationVersion = 'v3';\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: OpenAITranscriptionModelId,\n    private readonly config: OpenAITranscriptionModelConfig,\n  ) {}\n\n  private async getArgs({\n    audio,\n    mediaType,\n    providerOptions,\n  }: OpenAITranscriptionCallOptions) {\n    const warnings: SharedV3Warning[] = [];\n\n    // Parse provider options\n    const openAIOptions = await parseProviderOptions({\n      provider: 'openai',\n      providerOptions,\n      schema: openAITranscriptionProviderOptions,\n    });\n\n    // Create form data with base fields\n    const formData = new FormData();\n    const blob =\n      audio instanceof Uint8Array\n        ? new Blob([audio])\n        : new Blob([convertBase64ToUint8Array(audio)]);\n\n    formData.append('model', this.modelId);\n    const fileExtension = mediaTypeToExtension(mediaType);\n    formData.append(\n      'file',\n      new File([blob], 'audio', { type: mediaType }),\n      `audio.${fileExtension}`,\n    );\n\n    // Add provider-specific options\n    if (openAIOptions) {\n      const transcriptionModelOptions = {\n        include: openAIOptions.include,\n        language: openAIOptions.language,\n        prompt: openAIOptions.prompt,\n        // https://platform.openai.com/docs/api-reference/audio/createTranscription#audio_createtranscription-response_format\n        // prefer verbose_json to get segments for models that support it\n        response_format: [\n          'gpt-4o-transcribe',\n          'gpt-4o-mini-transcribe',\n        ].includes(this.modelId)\n          ? 'json'\n          : 'verbose_json',\n        temperature: openAIOptions.temperature,\n        timestamp_granularities: openAIOptions.timestampGranularities,\n      };\n\n      for (const [key, value] of Object.entries(transcriptionModelOptions)) {\n        if (value != null) {\n          if (Array.isArray(value)) {\n            for (const item of value) {\n              formData.append(`${key}[]`, String(item));\n            }\n          } else {\n            formData.append(key, String(value));\n          }\n        }\n      }\n    }\n\n    return {\n      formData,\n      warnings,\n    };\n  }\n\n  async doGenerate(\n    options: OpenAITranscriptionCallOptions,\n  ): Promise<Awaited<ReturnType<TranscriptionModelV3['doGenerate']>>> {\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n    const { formData, warnings } = await this.getArgs(options);\n\n    const {\n      value: response,\n      responseHeaders,\n      rawValue: rawResponse,\n    } = await postFormDataToApi({\n      url: this.config.url({\n        path: '/audio/transcriptions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      formData,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiTranscriptionResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const language =\n      response.language != null && response.language in languageMap\n        ? languageMap[response.language as keyof typeof languageMap]\n        : undefined;\n\n    return {\n      text: response.text,\n      segments:\n        response.segments?.map(segment => ({\n          text: segment.text,\n          startSecond: segment.start,\n          endSecond: segment.end,\n        })) ??\n        response.words?.map(word => ({\n          text: word.word,\n          startSecond: word.start,\n          endSecond: word.end,\n        })) ??\n        [],\n      language,\n      durationInSeconds: response.duration ?? undefined,\n      warnings,\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n    };\n  }\n}\n","import { lazySchema, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const openaiTranscriptionResponseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      text: z.string(),\n      language: z.string().nullish(),\n      duration: z.number().nullish(),\n      words: z\n        .array(\n          z.object({\n            word: z.string(),\n            start: z.number(),\n            end: z.number(),\n          }),\n        )\n        .nullish(),\n      segments: z\n        .array(\n          z.object({\n            id: z.number(),\n            seek: z.number(),\n            start: z.number(),\n            end: z.number(),\n            text: z.string(),\n            tokens: z.array(z.number()),\n            temperature: z.number(),\n            avg_logprob: z.number(),\n            compression_ratio: z.number(),\n            no_speech_prob: z.number(),\n          }),\n        )\n        .nullish(),\n    }),\n  ),\n);\n","import { InferSchema, lazySchema, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport type OpenAITranscriptionModelId =\n  | 'whisper-1'\n  | 'gpt-4o-mini-transcribe'\n  | 'gpt-4o-transcribe'\n  | (string & {});\n\n// https://platform.openai.com/docs/api-reference/audio/createTranscription\nexport const openAITranscriptionProviderOptions = lazySchema(() =>\n  zodSchema(\n    z.object({\n      /**\n       * Additional information to include in the transcription response.\n       */\n\n      include: z.array(z.string()).optional(),\n\n      /**\n       * The language of the input audio in ISO-639-1 format.\n       */\n      language: z.string().optional(),\n\n      /**\n       * An optional text to guide the model's style or continue a previous audio segment.\n       */\n      prompt: z.string().optional(),\n\n      /**\n       * The sampling temperature, between 0 and 1.\n       * @default 0\n       */\n      temperature: z.number().min(0).max(1).default(0).optional(),\n\n      /**\n       * The timestamp granularities to populate for this transcription.\n       * @default ['segment']\n       */\n      timestampGranularities: z\n        .array(z.enum(['word', 'segment']))\n        .default(['segment'])\n        .optional(),\n    }),\n  ),\n);\n\nexport type OpenAITranscriptionProviderOptions = InferSchema<\n  typeof openAITranscriptionProviderOptions\n>;\n","import { SpeechModelV3, SharedV3Warning } from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createBinaryResponseHandler,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport { OpenAISpeechAPITypes } from './openai-speech-api';\nimport {\n  openaiSpeechProviderOptionsSchema,\n  OpenAISpeechModelId,\n} from './openai-speech-options';\n\ninterface OpenAISpeechModelConfig extends OpenAIConfig {\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\nexport class OpenAISpeechModel implements SpeechModelV3 {\n  readonly specificationVersion = 'v3';\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: OpenAISpeechModelId,\n    private readonly config: OpenAISpeechModelConfig,\n  ) {}\n\n  private async getArgs({\n    text,\n    voice = 'alloy',\n    outputFormat = 'mp3',\n    speed,\n    instructions,\n    language,\n    providerOptions,\n  }: Parameters<SpeechModelV3['doGenerate']>[0]) {\n    const warnings: SharedV3Warning[] = [];\n\n    // Parse provider options\n    const openAIOptions = await parseProviderOptions({\n      provider: 'openai',\n      providerOptions,\n      schema: openaiSpeechProviderOptionsSchema,\n    });\n\n    // Create request body\n    const requestBody: Record<string, unknown> = {\n      model: this.modelId,\n      input: text,\n      voice,\n      response_format: 'mp3',\n      speed,\n      instructions,\n    };\n\n    if (outputFormat) {\n      if (['mp3', 'opus', 'aac', 'flac', 'wav', 'pcm'].includes(outputFormat)) {\n        requestBody.response_format = outputFormat;\n      } else {\n        warnings.push({\n          type: 'unsupported',\n          feature: 'outputFormat',\n          details: `Unsupported output format: ${outputFormat}. Using mp3 instead.`,\n        });\n      }\n    }\n\n    // Add provider-specific options\n    if (openAIOptions) {\n      const speechModelOptions: OpenAISpeechAPITypes = {};\n\n      for (const key in speechModelOptions) {\n        const value = speechModelOptions[key as keyof OpenAISpeechAPITypes];\n        if (value !== undefined) {\n          requestBody[key] = value;\n        }\n      }\n    }\n\n    if (language) {\n      warnings.push({\n        type: 'unsupported',\n        feature: 'language',\n        details: `OpenAI speech models do not support language selection. Language parameter \"${language}\" was ignored.`,\n      });\n    }\n\n    return {\n      requestBody,\n      warnings,\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<SpeechModelV3['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<SpeechModelV3['doGenerate']>>> {\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n    const { requestBody, warnings } = await this.getArgs(options);\n\n    const {\n      value: audio,\n      responseHeaders,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/audio/speech',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: requestBody,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createBinaryResponseHandler(),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      audio,\n      warnings,\n      request: {\n        body: JSON.stringify(requestBody),\n      },\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n    };\n  }\n}\n","import { InferSchema, lazySchema, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport type OpenAISpeechModelId =\n  | 'tts-1'\n  | 'tts-1-hd'\n  | 'gpt-4o-mini-tts'\n  | (string & {});\n\n// https://platform.openai.com/docs/api-reference/audio/createSpeech\nexport const openaiSpeechProviderOptionsSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      instructions: z.string().nullish(),\n      speed: z.number().min(0.25).max(4.0).default(1.0).nullish(),\n    }),\n  ),\n);\n\nexport type OpenAISpeechCallOptions = InferSchema<\n  typeof openaiSpeechProviderOptionsSchema\n>;\n","import {\n  APICallError,\n  JSONValue,\n  LanguageModelV3,\n  LanguageModelV3Prompt,\n  LanguageModelV3CallOptions,\n  LanguageModelV3Content,\n  LanguageModelV3FinishReason,\n  LanguageModelV3GenerateResult,\n  LanguageModelV3ProviderTool,\n  LanguageModelV3StreamPart,\n  LanguageModelV3StreamResult,\n  LanguageModelV3ToolApprovalRequest,\n  SharedV3ProviderMetadata,\n  SharedV3Warning,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  createToolNameMapping,\n  generateId,\n  InferSchema,\n  parseProviderOptions,\n  ParseResult,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport { getOpenAILanguageModelCapabilities } from '../openai-language-model-capabilities';\nimport { applyPatchInputSchema } from '../tool/apply-patch';\nimport {\n  codeInterpreterInputSchema,\n  codeInterpreterOutputSchema,\n} from '../tool/code-interpreter';\nimport { fileSearchOutputSchema } from '../tool/file-search';\nimport { imageGenerationOutputSchema } from '../tool/image-generation';\nimport { localShellInputSchema } from '../tool/local-shell';\nimport { mcpOutputSchema } from '../tool/mcp';\nimport { shellInputSchema } from '../tool/shell';\nimport { webSearchOutputSchema } from '../tool/web-search';\nimport {\n  convertOpenAIResponsesUsage,\n  OpenAIResponsesUsage,\n} from './convert-openai-responses-usage';\nimport { convertToOpenAIResponsesInput } from './convert-to-openai-responses-input';\nimport { mapOpenAIResponseFinishReason } from './map-openai-responses-finish-reason';\nimport {\n  OpenAIResponsesChunk,\n  openaiResponsesChunkSchema,\n  OpenAIResponsesIncludeOptions,\n  OpenAIResponsesIncludeValue,\n  OpenAIResponsesLogprobs,\n  openaiResponsesResponseSchema,\n  OpenAIResponsesWebSearchAction,\n  OpenAIResponsesApplyPatchOperationDiffDeltaChunk,\n  OpenAIResponsesApplyPatchOperationDiffDoneChunk,\n} from './openai-responses-api';\nimport {\n  OpenAIResponsesModelId,\n  openaiResponsesProviderOptionsSchema,\n  TOP_LOGPROBS_MAX,\n} from './openai-responses-options';\nimport { prepareResponsesTools } from './openai-responses-prepare-tools';\n\n/**\n * Extracts a mapping from MCP approval request IDs to their corresponding tool call IDs\n * from the prompt. When an MCP tool requires approval, we generate a tool call ID to track\n * the pending approval in our system. When the user responds to the approval (and we\n * continue the conversation), we need to map the approval request ID back to our tool call ID\n * so that tool results reference the correct tool call.\n */\nfunction extractApprovalRequestIdToToolCallIdMapping(\n  prompt: LanguageModelV3Prompt,\n): Record<string, string> {\n  const mapping: Record<string, string> = {};\n  for (const message of prompt) {\n    if (message.role !== 'assistant') continue;\n    for (const part of message.content) {\n      if (part.type !== 'tool-call') continue;\n      const approvalRequestId = part.providerOptions?.openai\n        ?.approvalRequestId as string | undefined;\n      if (approvalRequestId != null) {\n        mapping[approvalRequestId] = part.toolCallId;\n      }\n    }\n  }\n  return mapping;\n}\n\nexport class OpenAIResponsesLanguageModel implements LanguageModelV3 {\n  readonly specificationVersion = 'v3';\n\n  readonly modelId: OpenAIResponsesModelId;\n\n  private readonly config: OpenAIConfig;\n\n  constructor(modelId: OpenAIResponsesModelId, config: OpenAIConfig) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  readonly supportedUrls: Record<string, RegExp[]> = {\n    'image/*': [/^https?:\\/\\/.*$/],\n    'application/pdf': [/^https?:\\/\\/.*$/],\n  };\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private async getArgs({\n    maxOutputTokens,\n    temperature,\n    stopSequences,\n    topP,\n    topK,\n    presencePenalty,\n    frequencyPenalty,\n    seed,\n    prompt,\n    providerOptions,\n    tools,\n    toolChoice,\n    responseFormat,\n  }: LanguageModelV3CallOptions) {\n    const warnings: SharedV3Warning[] = [];\n    const modelCapabilities = getOpenAILanguageModelCapabilities(this.modelId);\n\n    if (topK != null) {\n      warnings.push({ type: 'unsupported', feature: 'topK' });\n    }\n\n    if (seed != null) {\n      warnings.push({ type: 'unsupported', feature: 'seed' });\n    }\n\n    if (presencePenalty != null) {\n      warnings.push({ type: 'unsupported', feature: 'presencePenalty' });\n    }\n\n    if (frequencyPenalty != null) {\n      warnings.push({ type: 'unsupported', feature: 'frequencyPenalty' });\n    }\n\n    if (stopSequences != null) {\n      warnings.push({ type: 'unsupported', feature: 'stopSequences' });\n    }\n\n    const openaiOptions = await parseProviderOptions({\n      provider: 'openai',\n      providerOptions,\n      schema: openaiResponsesProviderOptionsSchema,\n    });\n\n    const isReasoningModel =\n      openaiOptions?.forceReasoning ?? modelCapabilities.isReasoningModel;\n\n    if (openaiOptions?.conversation && openaiOptions?.previousResponseId) {\n      warnings.push({\n        type: 'unsupported',\n        feature: 'conversation',\n        details: 'conversation and previousResponseId cannot be used together',\n      });\n    }\n\n    const toolNameMapping = createToolNameMapping({\n      tools,\n      providerToolNames: {\n        'openai.code_interpreter': 'code_interpreter',\n        'openai.file_search': 'file_search',\n        'openai.image_generation': 'image_generation',\n        'openai.local_shell': 'local_shell',\n        'openai.shell': 'shell',\n        'openai.web_search': 'web_search',\n        'openai.web_search_preview': 'web_search_preview',\n        'openai.mcp': 'mcp',\n        'openai.apply_patch': 'apply_patch',\n      },\n    });\n\n    const { input, warnings: inputWarnings } =\n      await convertToOpenAIResponsesInput({\n        prompt,\n        toolNameMapping,\n        systemMessageMode:\n          openaiOptions?.systemMessageMode ??\n          (isReasoningModel\n            ? 'developer'\n            : modelCapabilities.systemMessageMode),\n        fileIdPrefixes: this.config.fileIdPrefixes,\n        store: openaiOptions?.store ?? true,\n        hasLocalShellTool: hasOpenAITool('openai.local_shell'),\n        hasShellTool: hasOpenAITool('openai.shell'),\n        hasApplyPatchTool: hasOpenAITool('openai.apply_patch'),\n      });\n\n    warnings.push(...inputWarnings);\n\n    const strictJsonSchema = openaiOptions?.strictJsonSchema ?? true;\n\n    let include: OpenAIResponsesIncludeOptions = openaiOptions?.include;\n\n    function addInclude(key: OpenAIResponsesIncludeValue) {\n      if (include == null) {\n        include = [key];\n      } else if (!include.includes(key)) {\n        include = [...include, key];\n      }\n    }\n\n    function hasOpenAITool(id: string) {\n      return (\n        tools?.find(tool => tool.type === 'provider' && tool.id === id) != null\n      );\n    }\n\n    // when logprobs are requested, automatically include them:\n    const topLogprobs =\n      typeof openaiOptions?.logprobs === 'number'\n        ? openaiOptions?.logprobs\n        : openaiOptions?.logprobs === true\n          ? TOP_LOGPROBS_MAX\n          : undefined;\n\n    if (topLogprobs) {\n      addInclude('message.output_text.logprobs');\n    }\n\n    // when a web search tool is present, automatically include the sources:\n    const webSearchToolName = (\n      tools?.find(\n        tool =>\n          tool.type === 'provider' &&\n          (tool.id === 'openai.web_search' ||\n            tool.id === 'openai.web_search_preview'),\n      ) as LanguageModelV3ProviderTool | undefined\n    )?.name;\n\n    if (webSearchToolName) {\n      addInclude('web_search_call.action.sources');\n    }\n\n    // when a code interpreter tool is present, automatically include the outputs:\n    if (hasOpenAITool('openai.code_interpreter')) {\n      addInclude('code_interpreter_call.outputs');\n    }\n\n    const store = openaiOptions?.store;\n\n    // store defaults to true in the OpenAI responses API, so check for false exactly:\n    if (store === false && isReasoningModel) {\n      addInclude('reasoning.encrypted_content');\n    }\n\n    const baseArgs = {\n      model: this.modelId,\n      input,\n      temperature,\n      top_p: topP,\n      max_output_tokens: maxOutputTokens,\n\n      ...((responseFormat?.type === 'json' || openaiOptions?.textVerbosity) && {\n        text: {\n          ...(responseFormat?.type === 'json' && {\n            format:\n              responseFormat.schema != null\n                ? {\n                    type: 'json_schema',\n                    strict: strictJsonSchema,\n                    name: responseFormat.name ?? 'response',\n                    description: responseFormat.description,\n                    schema: responseFormat.schema,\n                  }\n                : { type: 'json_object' },\n          }),\n          ...(openaiOptions?.textVerbosity && {\n            verbosity: openaiOptions.textVerbosity,\n          }),\n        },\n      }),\n\n      // provider options:\n      conversation: openaiOptions?.conversation,\n      max_tool_calls: openaiOptions?.maxToolCalls,\n      metadata: openaiOptions?.metadata,\n      parallel_tool_calls: openaiOptions?.parallelToolCalls,\n      previous_response_id: openaiOptions?.previousResponseId,\n      store,\n      user: openaiOptions?.user,\n      instructions: openaiOptions?.instructions,\n      service_tier: openaiOptions?.serviceTier,\n      include,\n      prompt_cache_key: openaiOptions?.promptCacheKey,\n      prompt_cache_retention: openaiOptions?.promptCacheRetention,\n      safety_identifier: openaiOptions?.safetyIdentifier,\n      top_logprobs: topLogprobs,\n      truncation: openaiOptions?.truncation,\n\n      // model-specific settings:\n      ...(isReasoningModel &&\n        (openaiOptions?.reasoningEffort != null ||\n          openaiOptions?.reasoningSummary != null) && {\n          reasoning: {\n            ...(openaiOptions?.reasoningEffort != null && {\n              effort: openaiOptions.reasoningEffort,\n            }),\n            ...(openaiOptions?.reasoningSummary != null && {\n              summary: openaiOptions.reasoningSummary,\n            }),\n          },\n        }),\n    };\n\n    // remove unsupported settings for reasoning models\n    // see https://platform.openai.com/docs/guides/reasoning#limitations\n    if (isReasoningModel) {\n      // when reasoning effort is none, gpt-5.1 models allow temperature, topP, logprobs\n      //  https://platform.openai.com/docs/guides/latest-model#gpt-5-1-parameter-compatibility\n      if (\n        !(\n          openaiOptions?.reasoningEffort === 'none' &&\n          modelCapabilities.supportsNonReasoningParameters\n        )\n      ) {\n        if (baseArgs.temperature != null) {\n          baseArgs.temperature = undefined;\n          warnings.push({\n            type: 'unsupported',\n            feature: 'temperature',\n            details: 'temperature is not supported for reasoning models',\n          });\n        }\n\n        if (baseArgs.top_p != null) {\n          baseArgs.top_p = undefined;\n          warnings.push({\n            type: 'unsupported',\n            feature: 'topP',\n            details: 'topP is not supported for reasoning models',\n          });\n        }\n      }\n    } else {\n      if (openaiOptions?.reasoningEffort != null) {\n        warnings.push({\n          type: 'unsupported',\n          feature: 'reasoningEffort',\n          details: 'reasoningEffort is not supported for non-reasoning models',\n        });\n      }\n\n      if (openaiOptions?.reasoningSummary != null) {\n        warnings.push({\n          type: 'unsupported',\n          feature: 'reasoningSummary',\n          details: 'reasoningSummary is not supported for non-reasoning models',\n        });\n      }\n    }\n\n    // Validate flex processing support\n    if (\n      openaiOptions?.serviceTier === 'flex' &&\n      !modelCapabilities.supportsFlexProcessing\n    ) {\n      warnings.push({\n        type: 'unsupported',\n        feature: 'serviceTier',\n        details:\n          'flex processing is only available for o3, o4-mini, and gpt-5 models',\n      });\n      // Remove from args if not supported\n      delete (baseArgs as any).service_tier;\n    }\n\n    // Validate priority processing support\n    if (\n      openaiOptions?.serviceTier === 'priority' &&\n      !modelCapabilities.supportsPriorityProcessing\n    ) {\n      warnings.push({\n        type: 'unsupported',\n        feature: 'serviceTier',\n        details:\n          'priority processing is only available for supported models (gpt-4, gpt-5, gpt-5-mini, o3, o4-mini) and requires Enterprise access. gpt-5-nano is not supported',\n      });\n      // Remove from args if not supported\n      delete (baseArgs as any).service_tier;\n    }\n\n    const {\n      tools: openaiTools,\n      toolChoice: openaiToolChoice,\n      toolWarnings,\n    } = await prepareResponsesTools({\n      tools,\n      toolChoice,\n    });\n\n    return {\n      webSearchToolName,\n      args: {\n        ...baseArgs,\n        tools: openaiTools,\n        tool_choice: openaiToolChoice,\n      },\n      warnings: [...warnings, ...toolWarnings],\n      store,\n      toolNameMapping,\n    };\n  }\n\n  async doGenerate(\n    options: LanguageModelV3CallOptions,\n  ): Promise<LanguageModelV3GenerateResult> {\n    const {\n      args: body,\n      warnings,\n      webSearchToolName,\n      toolNameMapping,\n    } = await this.getArgs(options);\n    const url = this.config.url({\n      path: '/responses',\n      modelId: this.modelId,\n    });\n\n    const providerKey = this.config.provider.replace('.responses', ''); // can be 'openai' or 'azure'. provider is 'openai.responses' or 'azure.responses'.\n\n    const approvalRequestIdToDummyToolCallIdFromPrompt =\n      extractApprovalRequestIdToToolCallIdMapping(options.prompt);\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url,\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiResponsesResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    if (response.error) {\n      throw new APICallError({\n        message: response.error.message,\n        url,\n        requestBodyValues: body,\n        statusCode: 400,\n        responseHeaders,\n        responseBody: rawResponse as string,\n        isRetryable: false,\n      });\n    }\n\n    const content: Array<LanguageModelV3Content> = [];\n    const logprobs: Array<OpenAIResponsesLogprobs> = [];\n\n    // flag that checks if there have been client-side tool calls (not executed by openai)\n    let hasFunctionCall = false;\n\n    // map response content to content array (defined when there is no error)\n    for (const part of response.output!) {\n      switch (part.type) {\n        case 'reasoning': {\n          // when there are no summary parts, we need to add an empty reasoning part:\n          if (part.summary.length === 0) {\n            part.summary.push({ type: 'summary_text', text: '' });\n          }\n\n          for (const summary of part.summary) {\n            content.push({\n              type: 'reasoning' as const,\n              text: summary.text,\n              providerMetadata: {\n                [providerKey]: {\n                  itemId: part.id,\n                  reasoningEncryptedContent: part.encrypted_content ?? null,\n                },\n              },\n            });\n          }\n          break;\n        }\n\n        case 'image_generation_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: toolNameMapping.toCustomToolName('image_generation'),\n            input: '{}',\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: toolNameMapping.toCustomToolName('image_generation'),\n            result: {\n              result: part.result,\n            } satisfies InferSchema<typeof imageGenerationOutputSchema>,\n          });\n\n          break;\n        }\n\n        case 'local_shell_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.call_id,\n            toolName: toolNameMapping.toCustomToolName('local_shell'),\n            input: JSON.stringify({\n              action: part.action,\n            } satisfies InferSchema<typeof localShellInputSchema>),\n            providerMetadata: {\n              [providerKey]: {\n                itemId: part.id,\n              },\n            },\n          });\n\n          break;\n        }\n\n        case 'shell_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.call_id,\n            toolName: toolNameMapping.toCustomToolName('shell'),\n            input: JSON.stringify({\n              action: {\n                commands: part.action.commands,\n              },\n            } satisfies InferSchema<typeof shellInputSchema>),\n            providerMetadata: {\n              [providerKey]: {\n                itemId: part.id,\n              },\n            },\n          });\n\n          break;\n        }\n\n        case 'message': {\n          for (const contentPart of part.content) {\n            if (\n              options.providerOptions?.openai?.logprobs &&\n              contentPart.logprobs\n            ) {\n              logprobs.push(contentPart.logprobs);\n            }\n\n            const providerMetadata: SharedV3ProviderMetadata[string] = {\n              itemId: part.id,\n              ...(contentPart.annotations.length > 0 && {\n                annotations: contentPart.annotations,\n              }),\n            };\n\n            content.push({\n              type: 'text',\n              text: contentPart.text,\n              providerMetadata: {\n                [providerKey]: providerMetadata,\n              },\n            });\n\n            for (const annotation of contentPart.annotations) {\n              if (annotation.type === 'url_citation') {\n                content.push({\n                  type: 'source',\n                  sourceType: 'url',\n                  id: this.config.generateId?.() ?? generateId(),\n                  url: annotation.url,\n                  title: annotation.title,\n                });\n              } else if (annotation.type === 'file_citation') {\n                content.push({\n                  type: 'source',\n                  sourceType: 'document',\n                  id: this.config.generateId?.() ?? generateId(),\n                  mediaType: 'text/plain',\n                  title: annotation.quote ?? annotation.filename ?? 'Document',\n                  filename: annotation.filename ?? annotation.file_id,\n                  ...(annotation.file_id\n                    ? {\n                        providerMetadata: {\n                          [providerKey]: {\n                            fileId: annotation.file_id,\n                          },\n                        },\n                      }\n                    : {}),\n                });\n              } else if (annotation.type === 'container_file_citation') {\n                content.push({\n                  type: 'source',\n                  sourceType: 'document',\n                  id: this.config.generateId?.() ?? generateId(),\n                  mediaType: 'text/plain',\n                  title:\n                    annotation.filename ?? annotation.file_id ?? 'Document',\n                  filename: annotation.filename ?? annotation.file_id,\n                  providerMetadata: {\n                    [providerKey]: {\n                      fileId: annotation.file_id,\n                      containerId: annotation.container_id,\n                      ...(annotation.index != null\n                        ? { index: annotation.index }\n                        : {}),\n                    },\n                  },\n                });\n              } else if (annotation.type === 'file_path') {\n                content.push({\n                  type: 'source',\n                  sourceType: 'document',\n                  id: this.config.generateId?.() ?? generateId(),\n                  mediaType: 'application/octet-stream',\n                  title: annotation.file_id,\n                  filename: annotation.file_id,\n                  providerMetadata: {\n                    [providerKey]: {\n                      fileId: annotation.file_id,\n                      ...(annotation.index != null\n                        ? { index: annotation.index }\n                        : {}),\n                    },\n                  },\n                });\n              }\n            }\n          }\n\n          break;\n        }\n\n        case 'function_call': {\n          hasFunctionCall = true;\n\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.call_id,\n            toolName: part.name,\n            input: part.arguments,\n            providerMetadata: {\n              [providerKey]: {\n                itemId: part.id,\n              },\n            },\n          });\n          break;\n        }\n\n        case 'web_search_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: toolNameMapping.toCustomToolName(\n              webSearchToolName ?? 'web_search',\n            ),\n            input: JSON.stringify({}),\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: toolNameMapping.toCustomToolName(\n              webSearchToolName ?? 'web_search',\n            ),\n            result: mapWebSearchOutput(part.action),\n          });\n\n          break;\n        }\n\n        case 'mcp_call': {\n          const toolCallId =\n            part.approval_request_id != null\n              ? (approvalRequestIdToDummyToolCallIdFromPrompt[\n                  part.approval_request_id\n                ] ?? part.id)\n              : part.id;\n\n          const toolName = `mcp.${part.name}`;\n\n          content.push({\n            type: 'tool-call',\n            toolCallId,\n            toolName,\n            input: part.arguments,\n            providerExecuted: true,\n            dynamic: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId,\n            toolName,\n            result: {\n              type: 'call',\n              serverLabel: part.server_label,\n              name: part.name,\n              arguments: part.arguments,\n              ...(part.output != null ? { output: part.output } : {}),\n              ...(part.error != null\n                ? { error: part.error as unknown as JSONValue }\n                : {}),\n            } satisfies InferSchema<typeof mcpOutputSchema>,\n            providerMetadata: {\n              [providerKey]: {\n                itemId: part.id,\n              },\n            },\n          });\n          break;\n        }\n\n        case 'mcp_list_tools': {\n          // skip\n          break;\n        }\n\n        case 'mcp_approval_request': {\n          const approvalRequestId = part.approval_request_id ?? part.id;\n          const dummyToolCallId = this.config.generateId?.() ?? generateId();\n          const toolName = `mcp.${part.name}`;\n\n          content.push({\n            type: 'tool-call',\n            toolCallId: dummyToolCallId,\n            toolName,\n            input: part.arguments,\n            providerExecuted: true,\n            dynamic: true,\n          });\n\n          content.push({\n            type: 'tool-approval-request',\n            approvalId: approvalRequestId,\n            toolCallId: dummyToolCallId,\n          } satisfies LanguageModelV3ToolApprovalRequest);\n          break;\n        }\n\n        case 'computer_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: toolNameMapping.toCustomToolName('computer_use'),\n            input: '',\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: toolNameMapping.toCustomToolName('computer_use'),\n            result: {\n              type: 'computer_use_tool_result',\n              status: part.status || 'completed',\n            },\n          });\n          break;\n        }\n\n        case 'file_search_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: toolNameMapping.toCustomToolName('file_search'),\n            input: '{}',\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: toolNameMapping.toCustomToolName('file_search'),\n            result: {\n              queries: part.queries,\n              results:\n                part.results?.map(result => ({\n                  attributes: result.attributes,\n                  fileId: result.file_id,\n                  filename: result.filename,\n                  score: result.score,\n                  text: result.text,\n                })) ?? null,\n            } satisfies InferSchema<typeof fileSearchOutputSchema>,\n          });\n          break;\n        }\n\n        case 'code_interpreter_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: toolNameMapping.toCustomToolName('code_interpreter'),\n            input: JSON.stringify({\n              code: part.code,\n              containerId: part.container_id,\n            } satisfies InferSchema<typeof codeInterpreterInputSchema>),\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: toolNameMapping.toCustomToolName('code_interpreter'),\n            result: {\n              outputs: part.outputs,\n            } satisfies InferSchema<typeof codeInterpreterOutputSchema>,\n          });\n          break;\n        }\n\n        case 'apply_patch_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.call_id,\n            toolName: toolNameMapping.toCustomToolName('apply_patch'),\n            input: JSON.stringify({\n              callId: part.call_id,\n              operation: part.operation,\n            } satisfies InferSchema<typeof applyPatchInputSchema>),\n            providerMetadata: {\n              [providerKey]: {\n                itemId: part.id,\n              },\n            },\n          });\n\n          break;\n        }\n      }\n    }\n\n    const providerMetadata: SharedV3ProviderMetadata = {\n      [providerKey]: { responseId: response.id },\n    };\n\n    if (logprobs.length > 0) {\n      providerMetadata[providerKey].logprobs = logprobs;\n    }\n\n    if (typeof response.service_tier === 'string') {\n      providerMetadata[providerKey].serviceTier = response.service_tier;\n    }\n\n    const usage = response.usage!; // defined when there is no error\n\n    return {\n      content,\n      finishReason: {\n        unified: mapOpenAIResponseFinishReason({\n          finishReason: response.incomplete_details?.reason,\n          hasFunctionCall,\n        }),\n        raw: response.incomplete_details?.reason ?? undefined,\n      },\n      usage: convertOpenAIResponsesUsage(usage),\n      request: { body },\n      response: {\n        id: response.id,\n        timestamp: new Date(response.created_at! * 1000),\n        modelId: response.model,\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n      providerMetadata,\n      warnings,\n    };\n  }\n\n  async doStream(\n    options: LanguageModelV3CallOptions,\n  ): Promise<LanguageModelV3StreamResult> {\n    const {\n      args: body,\n      warnings,\n      webSearchToolName,\n      toolNameMapping,\n      store,\n    } = await this.getArgs(options);\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/responses',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: {\n        ...body,\n        stream: true,\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiResponsesChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const self = this;\n    const providerKey = this.config.provider.replace('.responses', ''); // can be 'openai' or 'azure'. provider is 'openai.responses' or 'azure.responses'.\n\n    const approvalRequestIdToDummyToolCallIdFromPrompt =\n      extractApprovalRequestIdToToolCallIdMapping(options.prompt);\n\n    const approvalRequestIdToDummyToolCallIdFromStream = new Map<\n      string,\n      string\n    >();\n\n    let finishReason: LanguageModelV3FinishReason = {\n      unified: 'other',\n      raw: undefined,\n    };\n    let usage: OpenAIResponsesUsage | undefined = undefined;\n    const logprobs: Array<OpenAIResponsesLogprobs> = [];\n    let responseId: string | null = null;\n\n    const ongoingToolCalls: Record<\n      number,\n      | {\n          toolName: string;\n          toolCallId: string;\n          codeInterpreter?: {\n            containerId: string;\n          };\n          applyPatch?: {\n            hasDiff: boolean;\n            endEmitted: boolean;\n          };\n        }\n      | undefined\n    > = {};\n\n    // set annotations in 'text-end' part providerMetadata.\n    const ongoingAnnotations: Array<\n      Extract<\n        OpenAIResponsesChunk,\n        { type: 'response.output_text.annotation.added' }\n      >['annotation']\n    > = [];\n\n    // flag that checks if there have been client-side tool calls (not executed by openai)\n    let hasFunctionCall = false;\n\n    const activeReasoning: Record<\n      string,\n      {\n        encryptedContent?: string | null;\n        // summary index as string to reasoning part state:\n        summaryParts: Record<string, 'active' | 'can-conclude' | 'concluded'>;\n      }\n    > = {};\n\n    let serviceTier: string | undefined;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<OpenAIResponsesChunk>,\n          LanguageModelV3StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = { unified: 'error', raw: undefined };\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            if (isResponseOutputItemAddedChunk(value)) {\n              if (value.item.type === 'function_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: value.item.name,\n                  toolCallId: value.item.call_id,\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.call_id,\n                  toolName: value.item.name,\n                });\n              } else if (value.item.type === 'web_search_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: toolNameMapping.toCustomToolName(\n                    webSearchToolName ?? 'web_search',\n                  ),\n                  toolCallId: value.item.id,\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.id,\n                  toolName: toolNameMapping.toCustomToolName(\n                    webSearchToolName ?? 'web_search',\n                  ),\n                  providerExecuted: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: value.item.id,\n                });\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: toolNameMapping.toCustomToolName(\n                    webSearchToolName ?? 'web_search',\n                  ),\n                  input: JSON.stringify({}),\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'computer_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: toolNameMapping.toCustomToolName('computer_use'),\n                  toolCallId: value.item.id,\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.id,\n                  toolName: toolNameMapping.toCustomToolName('computer_use'),\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'code_interpreter_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName:\n                    toolNameMapping.toCustomToolName('code_interpreter'),\n                  toolCallId: value.item.id,\n                  codeInterpreter: {\n                    containerId: value.item.container_id,\n                  },\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.id,\n                  toolName:\n                    toolNameMapping.toCustomToolName('code_interpreter'),\n                  providerExecuted: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: value.item.id,\n                  delta: `{\"containerId\":\"${value.item.container_id}\",\"code\":\"`,\n                });\n              } else if (value.item.type === 'file_search_call') {\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: toolNameMapping.toCustomToolName('file_search'),\n                  input: '{}',\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'image_generation_call') {\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName:\n                    toolNameMapping.toCustomToolName('image_generation'),\n                  input: '{}',\n                  providerExecuted: true,\n                });\n              } else if (\n                value.item.type === 'mcp_call' ||\n                value.item.type === 'mcp_list_tools' ||\n                value.item.type === 'mcp_approval_request'\n              ) {\n                // Emit MCP tool-call/approval parts on output_item.done instead, so we can:\n                // - alias mcp_call IDs when an approval_request_id is present\n                // - emit a proper tool-approval-request part for MCP approvals\n              } else if (value.item.type === 'apply_patch_call') {\n                const { call_id: callId, operation } = value.item;\n\n                ongoingToolCalls[value.output_index] = {\n                  toolName: toolNameMapping.toCustomToolName('apply_patch'),\n                  toolCallId: callId,\n                  applyPatch: {\n                    // delete_file doesn't have diff\n                    hasDiff: operation.type === 'delete_file',\n                    endEmitted: operation.type === 'delete_file',\n                  },\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: callId,\n                  toolName: toolNameMapping.toCustomToolName('apply_patch'),\n                });\n\n                if (operation.type === 'delete_file') {\n                  const inputString = JSON.stringify({\n                    callId,\n                    operation,\n                  } satisfies InferSchema<typeof applyPatchInputSchema>);\n\n                  controller.enqueue({\n                    type: 'tool-input-delta',\n                    id: callId,\n                    delta: inputString,\n                  });\n\n                  controller.enqueue({\n                    type: 'tool-input-end',\n                    id: callId,\n                  });\n                } else {\n                  controller.enqueue({\n                    type: 'tool-input-delta',\n                    id: callId,\n                    delta: `{\"callId\":\"${escapeJSONDelta(callId)}\",\"operation\":{\"type\":\"${escapeJSONDelta(operation.type)}\",\"path\":\"${escapeJSONDelta(operation.path)}\",\"diff\":\"`,\n                  });\n                }\n              } else if (value.item.type === 'shell_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: toolNameMapping.toCustomToolName('shell'),\n                  toolCallId: value.item.call_id,\n                };\n              } else if (value.item.type === 'message') {\n                ongoingAnnotations.splice(0, ongoingAnnotations.length);\n                controller.enqueue({\n                  type: 'text-start',\n                  id: value.item.id,\n                  providerMetadata: {\n                    [providerKey]: {\n                      itemId: value.item.id,\n                    },\n                  },\n                });\n              } else if (\n                isResponseOutputItemAddedChunk(value) &&\n                value.item.type === 'reasoning'\n              ) {\n                activeReasoning[value.item.id] = {\n                  encryptedContent: value.item.encrypted_content,\n                  summaryParts: { 0: 'active' },\n                };\n\n                controller.enqueue({\n                  type: 'reasoning-start',\n                  id: `${value.item.id}:0`,\n                  providerMetadata: {\n                    [providerKey]: {\n                      itemId: value.item.id,\n                      reasoningEncryptedContent:\n                        value.item.encrypted_content ?? null,\n                    },\n                  },\n                });\n              }\n            } else if (isResponseOutputItemDoneChunk(value)) {\n              if (value.item.type === 'message') {\n                controller.enqueue({\n                  type: 'text-end',\n                  id: value.item.id,\n                  providerMetadata: {\n                    [providerKey]: {\n                      itemId: value.item.id,\n                      ...(ongoingAnnotations.length > 0 && {\n                        annotations: ongoingAnnotations,\n                      }),\n                    },\n                  },\n                });\n              } else if (value.item.type === 'function_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n                hasFunctionCall = true;\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: value.item.call_id,\n                });\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.call_id,\n                  toolName: value.item.name,\n                  input: value.item.arguments,\n                  providerMetadata: {\n                    [providerKey]: {\n                      itemId: value.item.id,\n                    },\n                  },\n                });\n              } else if (value.item.type === 'web_search_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: toolNameMapping.toCustomToolName(\n                    webSearchToolName ?? 'web_search',\n                  ),\n                  result: mapWebSearchOutput(value.item.action),\n                });\n              } else if (value.item.type === 'computer_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: value.item.id,\n                });\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: toolNameMapping.toCustomToolName('computer_use'),\n                  input: '',\n                  providerExecuted: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: toolNameMapping.toCustomToolName('computer_use'),\n                  result: {\n                    type: 'computer_use_tool_result',\n                    status: value.item.status || 'completed',\n                  },\n                });\n              } else if (value.item.type === 'file_search_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: toolNameMapping.toCustomToolName('file_search'),\n                  result: {\n                    queries: value.item.queries,\n                    results:\n                      value.item.results?.map(result => ({\n                        attributes: result.attributes,\n                        fileId: result.file_id,\n                        filename: result.filename,\n                        score: result.score,\n                        text: result.text,\n                      })) ?? null,\n                  } satisfies InferSchema<typeof fileSearchOutputSchema>,\n                });\n              } else if (value.item.type === 'code_interpreter_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName:\n                    toolNameMapping.toCustomToolName('code_interpreter'),\n                  result: {\n                    outputs: value.item.outputs,\n                  } satisfies InferSchema<typeof codeInterpreterOutputSchema>,\n                });\n              } else if (value.item.type === 'image_generation_call') {\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName:\n                    toolNameMapping.toCustomToolName('image_generation'),\n                  result: {\n                    result: value.item.result,\n                  } satisfies InferSchema<typeof imageGenerationOutputSchema>,\n                });\n              } else if (value.item.type === 'mcp_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                const approvalRequestId =\n                  value.item.approval_request_id ?? undefined;\n\n                // when MCP tools require approval, we track them with our own\n                // tool call IDs and then map OpenAI's approval_request_id back to our ID so results match.\n                const aliasedToolCallId =\n                  approvalRequestId != null\n                    ? (approvalRequestIdToDummyToolCallIdFromStream.get(\n                        approvalRequestId,\n                      ) ??\n                      approvalRequestIdToDummyToolCallIdFromPrompt[\n                        approvalRequestId\n                      ] ??\n                      value.item.id)\n                    : value.item.id;\n\n                const toolName = `mcp.${value.item.name}`;\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: aliasedToolCallId,\n                  toolName,\n                  input: value.item.arguments,\n                  providerExecuted: true,\n                  dynamic: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: aliasedToolCallId,\n                  toolName,\n                  result: {\n                    type: 'call',\n                    serverLabel: value.item.server_label,\n                    name: value.item.name,\n                    arguments: value.item.arguments,\n                    ...(value.item.output != null\n                      ? { output: value.item.output }\n                      : {}),\n                    ...(value.item.error != null\n                      ? { error: value.item.error as unknown as JSONValue }\n                      : {}),\n                  } satisfies InferSchema<typeof mcpOutputSchema>,\n                  providerMetadata: {\n                    [providerKey]: {\n                      itemId: value.item.id,\n                    },\n                  },\n                });\n              } else if (value.item.type === 'mcp_list_tools') {\n                // Skip listTools - we don't expose this to the UI or send it back\n                ongoingToolCalls[value.output_index] = undefined;\n\n                // skip\n              } else if (value.item.type === 'apply_patch_call') {\n                const toolCall = ongoingToolCalls[value.output_index];\n                if (\n                  toolCall?.applyPatch &&\n                  !toolCall.applyPatch.endEmitted &&\n                  value.item.operation.type !== 'delete_file'\n                ) {\n                  if (!toolCall.applyPatch.hasDiff) {\n                    controller.enqueue({\n                      type: 'tool-input-delta',\n                      id: toolCall.toolCallId,\n                      delta: escapeJSONDelta(value.item.operation.diff),\n                    });\n                  }\n\n                  controller.enqueue({\n                    type: 'tool-input-delta',\n                    id: toolCall.toolCallId,\n                    delta: '\"}}',\n                  });\n\n                  controller.enqueue({\n                    type: 'tool-input-end',\n                    id: toolCall.toolCallId,\n                  });\n\n                  toolCall.applyPatch.endEmitted = true;\n                }\n\n                // Emit the final tool-call with complete diff when status is 'completed'\n                if (toolCall && value.item.status === 'completed') {\n                  controller.enqueue({\n                    type: 'tool-call',\n                    toolCallId: toolCall.toolCallId,\n                    toolName: toolNameMapping.toCustomToolName('apply_patch'),\n                    input: JSON.stringify({\n                      callId: value.item.call_id,\n                      operation: value.item.operation,\n                    } satisfies InferSchema<typeof applyPatchInputSchema>),\n                    providerMetadata: {\n                      [providerKey]: {\n                        itemId: value.item.id,\n                      },\n                    },\n                  });\n                }\n\n                ongoingToolCalls[value.output_index] = undefined;\n              } else if (value.item.type === 'mcp_approval_request') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                const dummyToolCallId =\n                  self.config.generateId?.() ?? generateId();\n                const approvalRequestId =\n                  value.item.approval_request_id ?? value.item.id;\n                approvalRequestIdToDummyToolCallIdFromStream.set(\n                  approvalRequestId,\n                  dummyToolCallId,\n                );\n\n                const toolName = `mcp.${value.item.name}`;\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: dummyToolCallId,\n                  toolName,\n                  input: value.item.arguments,\n                  providerExecuted: true,\n                  dynamic: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-approval-request',\n                  approvalId: approvalRequestId,\n                  toolCallId: dummyToolCallId,\n                });\n              } else if (value.item.type === 'local_shell_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.call_id,\n                  toolName: toolNameMapping.toCustomToolName('local_shell'),\n                  input: JSON.stringify({\n                    action: {\n                      type: 'exec',\n                      command: value.item.action.command,\n                      timeoutMs: value.item.action.timeout_ms,\n                      user: value.item.action.user,\n                      workingDirectory: value.item.action.working_directory,\n                      env: value.item.action.env,\n                    },\n                  } satisfies InferSchema<typeof localShellInputSchema>),\n                  providerMetadata: {\n                    [providerKey]: { itemId: value.item.id },\n                  },\n                });\n              } else if (value.item.type === 'shell_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.call_id,\n                  toolName: toolNameMapping.toCustomToolName('shell'),\n                  input: JSON.stringify({\n                    action: {\n                      commands: value.item.action.commands,\n                    },\n                  } satisfies InferSchema<typeof shellInputSchema>),\n                  providerMetadata: {\n                    [providerKey]: { itemId: value.item.id },\n                  },\n                });\n              } else if (value.item.type === 'reasoning') {\n                const activeReasoningPart = activeReasoning[value.item.id];\n\n                // get all active or can-conclude summary parts' ids\n                // to conclude ongoing reasoning parts:\n                const summaryPartIndices = Object.entries(\n                  activeReasoningPart.summaryParts,\n                )\n                  .filter(\n                    ([_, status]) =>\n                      status === 'active' || status === 'can-conclude',\n                  )\n                  .map(([summaryIndex]) => summaryIndex);\n\n                for (const summaryIndex of summaryPartIndices) {\n                  controller.enqueue({\n                    type: 'reasoning-end',\n                    id: `${value.item.id}:${summaryIndex}`,\n                    providerMetadata: {\n                      [providerKey]: {\n                        itemId: value.item.id,\n                        reasoningEncryptedContent:\n                          value.item.encrypted_content ?? null,\n                      },\n                    },\n                  });\n                }\n\n                delete activeReasoning[value.item.id];\n              }\n            } else if (isResponseFunctionCallArgumentsDeltaChunk(value)) {\n              const toolCall = ongoingToolCalls[value.output_index];\n\n              if (toolCall != null) {\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.toolCallId,\n                  delta: value.delta,\n                });\n              }\n            } else if (isResponseApplyPatchCallOperationDiffDeltaChunk(value)) {\n              const toolCall = ongoingToolCalls[value.output_index];\n\n              if (toolCall?.applyPatch) {\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.toolCallId,\n                  delta: escapeJSONDelta(value.delta),\n                });\n\n                toolCall.applyPatch.hasDiff = true;\n              }\n            } else if (isResponseApplyPatchCallOperationDiffDoneChunk(value)) {\n              const toolCall = ongoingToolCalls[value.output_index];\n\n              if (toolCall?.applyPatch && !toolCall.applyPatch.endEmitted) {\n                if (!toolCall.applyPatch.hasDiff) {\n                  controller.enqueue({\n                    type: 'tool-input-delta',\n                    id: toolCall.toolCallId,\n                    delta: escapeJSONDelta(value.diff),\n                  });\n\n                  toolCall.applyPatch.hasDiff = true;\n                }\n\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.toolCallId,\n                  delta: '\"}}',\n                });\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: toolCall.toolCallId,\n                });\n\n                toolCall.applyPatch.endEmitted = true;\n              }\n            } else if (isResponseImageGenerationCallPartialImageChunk(value)) {\n              controller.enqueue({\n                type: 'tool-result',\n                toolCallId: value.item_id,\n                toolName: toolNameMapping.toCustomToolName('image_generation'),\n                result: {\n                  result: value.partial_image_b64,\n                } satisfies InferSchema<typeof imageGenerationOutputSchema>,\n                preliminary: true,\n              });\n            } else if (isResponseCodeInterpreterCallCodeDeltaChunk(value)) {\n              const toolCall = ongoingToolCalls[value.output_index];\n\n              if (toolCall != null) {\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.toolCallId,\n                  delta: escapeJSONDelta(value.delta),\n                });\n              }\n            } else if (isResponseCodeInterpreterCallCodeDoneChunk(value)) {\n              const toolCall = ongoingToolCalls[value.output_index];\n\n              if (toolCall != null) {\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.toolCallId,\n                  delta: '\"}',\n                });\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: toolCall.toolCallId,\n                });\n\n                // immediately send the tool call after the input end:\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: toolCall.toolCallId,\n                  toolName:\n                    toolNameMapping.toCustomToolName('code_interpreter'),\n                  input: JSON.stringify({\n                    code: value.code,\n                    containerId: toolCall.codeInterpreter!.containerId,\n                  } satisfies InferSchema<typeof codeInterpreterInputSchema>),\n                  providerExecuted: true,\n                });\n              }\n            } else if (isResponseCreatedChunk(value)) {\n              responseId = value.response.id;\n              controller.enqueue({\n                type: 'response-metadata',\n                id: value.response.id,\n                timestamp: new Date(value.response.created_at * 1000),\n                modelId: value.response.model,\n              });\n            } else if (isTextDeltaChunk(value)) {\n              controller.enqueue({\n                type: 'text-delta',\n                id: value.item_id,\n                delta: value.delta,\n              });\n\n              if (options.providerOptions?.openai?.logprobs && value.logprobs) {\n                logprobs.push(value.logprobs);\n              }\n            } else if (value.type === 'response.reasoning_summary_part.added') {\n              // the first reasoning start is pushed in isResponseOutputItemAddedReasoningChunk\n              if (value.summary_index > 0) {\n                const activeReasoningPart = activeReasoning[value.item_id]!;\n\n                activeReasoningPart.summaryParts[value.summary_index] =\n                  'active';\n\n                // since there is a new active summary part, we can conclude all can-conclude summary parts\n                for (const summaryIndex of Object.keys(\n                  activeReasoningPart.summaryParts,\n                )) {\n                  if (\n                    activeReasoningPart.summaryParts[summaryIndex] ===\n                    'can-conclude'\n                  ) {\n                    controller.enqueue({\n                      type: 'reasoning-end',\n                      id: `${value.item_id}:${summaryIndex}`,\n                      providerMetadata: {\n                        [providerKey]: { itemId: value.item_id },\n                      },\n                    });\n                    activeReasoningPart.summaryParts[summaryIndex] =\n                      'concluded';\n                  }\n                }\n\n                controller.enqueue({\n                  type: 'reasoning-start',\n                  id: `${value.item_id}:${value.summary_index}`,\n                  providerMetadata: {\n                    [providerKey]: {\n                      itemId: value.item_id,\n                      reasoningEncryptedContent:\n                        activeReasoning[value.item_id]?.encryptedContent ??\n                        null,\n                    },\n                  },\n                });\n              }\n            } else if (value.type === 'response.reasoning_summary_text.delta') {\n              controller.enqueue({\n                type: 'reasoning-delta',\n                id: `${value.item_id}:${value.summary_index}`,\n                delta: value.delta,\n                providerMetadata: {\n                  [providerKey]: {\n                    itemId: value.item_id,\n                  },\n                },\n              });\n            } else if (value.type === 'response.reasoning_summary_part.done') {\n              // when OpenAI stores the message data, we can immediately conclude the reasoning part\n              // since we do not need to send the encrypted content.\n              if (store) {\n                controller.enqueue({\n                  type: 'reasoning-end',\n                  id: `${value.item_id}:${value.summary_index}`,\n                  providerMetadata: {\n                    [providerKey]: { itemId: value.item_id },\n                  },\n                });\n\n                // mark the summary part as concluded\n                activeReasoning[value.item_id]!.summaryParts[\n                  value.summary_index\n                ] = 'concluded';\n              } else {\n                // mark the summary part as can-conclude only\n                // because we need to have a final summary part with the encrypted content\n                activeReasoning[value.item_id]!.summaryParts[\n                  value.summary_index\n                ] = 'can-conclude';\n              }\n            } else if (isResponseFinishedChunk(value)) {\n              finishReason = {\n                unified: mapOpenAIResponseFinishReason({\n                  finishReason: value.response.incomplete_details?.reason,\n                  hasFunctionCall,\n                }),\n                raw: value.response.incomplete_details?.reason ?? undefined,\n              };\n              usage = value.response.usage;\n              if (typeof value.response.service_tier === 'string') {\n                serviceTier = value.response.service_tier;\n              }\n            } else if (isResponseAnnotationAddedChunk(value)) {\n              ongoingAnnotations.push(value.annotation);\n              if (value.annotation.type === 'url_citation') {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'url',\n                  id: self.config.generateId?.() ?? generateId(),\n                  url: value.annotation.url,\n                  title: value.annotation.title,\n                });\n              } else if (value.annotation.type === 'file_citation') {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'document',\n                  id: self.config.generateId?.() ?? generateId(),\n                  mediaType: 'text/plain',\n                  title:\n                    value.annotation.quote ??\n                    value.annotation.filename ??\n                    'Document',\n                  filename:\n                    value.annotation.filename ?? value.annotation.file_id,\n                  ...(value.annotation.file_id\n                    ? {\n                        providerMetadata: {\n                          [providerKey]: {\n                            fileId: value.annotation.file_id,\n                          },\n                        },\n                      }\n                    : {}),\n                });\n              } else if (value.annotation.type === 'container_file_citation') {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'document',\n                  id: self.config.generateId?.() ?? generateId(),\n                  mediaType: 'text/plain',\n                  title:\n                    value.annotation.filename ??\n                    value.annotation.file_id ??\n                    'Document',\n                  filename:\n                    value.annotation.filename ?? value.annotation.file_id,\n                  providerMetadata: {\n                    [providerKey]: {\n                      fileId: value.annotation.file_id,\n                      containerId: value.annotation.container_id,\n                      ...(value.annotation.index != null\n                        ? { index: value.annotation.index }\n                        : {}),\n                    },\n                  },\n                });\n              } else if (value.annotation.type === 'file_path') {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'document',\n                  id: self.config.generateId?.() ?? generateId(),\n                  mediaType: 'application/octet-stream',\n                  title: value.annotation.file_id,\n                  filename: value.annotation.file_id,\n                  providerMetadata: {\n                    [providerKey]: {\n                      fileId: value.annotation.file_id,\n                      ...(value.annotation.index != null\n                        ? { index: value.annotation.index }\n                        : {}),\n                    },\n                  },\n                });\n              }\n            } else if (isErrorChunk(value)) {\n              controller.enqueue({ type: 'error', error: value });\n            }\n          },\n\n          flush(controller) {\n            const providerMetadata: SharedV3ProviderMetadata = {\n              [providerKey]: {\n                responseId,\n              },\n            };\n\n            if (logprobs.length > 0) {\n              providerMetadata[providerKey].logprobs = logprobs;\n            }\n\n            if (serviceTier !== undefined) {\n              providerMetadata[providerKey].serviceTier = serviceTier;\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage: convertOpenAIResponsesUsage(usage),\n              providerMetadata,\n            });\n          },\n        }),\n      ),\n      request: { body },\n      response: { headers: responseHeaders },\n    };\n  }\n}\n\nfunction isTextDeltaChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & { type: 'response.output_text.delta' } {\n  return chunk.type === 'response.output_text.delta';\n}\n\nfunction isResponseOutputItemDoneChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & { type: 'response.output_item.done' } {\n  return chunk.type === 'response.output_item.done';\n}\n\nfunction isResponseFinishedChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & {\n  type: 'response.completed' | 'response.incomplete';\n} {\n  return (\n    chunk.type === 'response.completed' || chunk.type === 'response.incomplete'\n  );\n}\n\nfunction isResponseCreatedChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & { type: 'response.created' } {\n  return chunk.type === 'response.created';\n}\n\nfunction isResponseFunctionCallArgumentsDeltaChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & {\n  type: 'response.function_call_arguments.delta';\n} {\n  return chunk.type === 'response.function_call_arguments.delta';\n}\nfunction isResponseImageGenerationCallPartialImageChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & {\n  type: 'response.image_generation_call.partial_image';\n} {\n  return chunk.type === 'response.image_generation_call.partial_image';\n}\n\nfunction isResponseCodeInterpreterCallCodeDeltaChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & {\n  type: 'response.code_interpreter_call_code.delta';\n} {\n  return chunk.type === 'response.code_interpreter_call_code.delta';\n}\n\nfunction isResponseCodeInterpreterCallCodeDoneChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & {\n  type: 'response.code_interpreter_call_code.done';\n} {\n  return chunk.type === 'response.code_interpreter_call_code.done';\n}\n\nfunction isResponseApplyPatchCallOperationDiffDeltaChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesApplyPatchOperationDiffDeltaChunk {\n  return chunk.type === 'response.apply_patch_call_operation_diff.delta';\n}\n\nfunction isResponseApplyPatchCallOperationDiffDoneChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesApplyPatchOperationDiffDoneChunk {\n  return chunk.type === 'response.apply_patch_call_operation_diff.done';\n}\n\nfunction isResponseOutputItemAddedChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & { type: 'response.output_item.added' } {\n  return chunk.type === 'response.output_item.added';\n}\n\nfunction isResponseAnnotationAddedChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & {\n  type: 'response.output_text.annotation.added';\n} {\n  return chunk.type === 'response.output_text.annotation.added';\n}\n\nfunction isErrorChunk(\n  chunk: OpenAIResponsesChunk,\n): chunk is OpenAIResponsesChunk & { type: 'error' } {\n  return chunk.type === 'error';\n}\n\nfunction mapWebSearchOutput(\n  action: OpenAIResponsesWebSearchAction,\n): InferSchema<typeof webSearchOutputSchema> {\n  switch (action.type) {\n    case 'search':\n      return {\n        action: { type: 'search', query: action.query ?? undefined },\n        // include sources when provided by the Responses API (behind include flag)\n        ...(action.sources != null && { sources: action.sources }),\n      };\n    case 'open_page':\n      return { action: { type: 'openPage', url: action.url } };\n    case 'find_in_page':\n      return {\n        action: {\n          type: 'findInPage',\n          url: action.url,\n          pattern: action.pattern,\n        },\n      };\n  }\n}\n\n// The delta is embedded in a JSON string.\n// To escape it, we use JSON.stringify and slice to remove the outer quotes.\nfunction escapeJSONDelta(delta: string) {\n  return JSON.stringify(delta).slice(1, -1);\n}\n","import { LanguageModelV3Usage } from '@ai-sdk/provider';\n\nexport type OpenAIResponsesUsage = {\n  input_tokens: number;\n  output_tokens: number;\n  input_tokens_details?: {\n    cached_tokens?: number | null;\n  } | null;\n  output_tokens_details?: {\n    reasoning_tokens?: number | null;\n  } | null;\n};\n\nexport function convertOpenAIResponsesUsage(\n  usage: OpenAIResponsesUsage | undefined | null,\n): LanguageModelV3Usage {\n  if (usage == null) {\n    return {\n      inputTokens: {\n        total: undefined,\n        noCache: undefined,\n        cacheRead: undefined,\n        cacheWrite: undefined,\n      },\n      outputTokens: {\n        total: undefined,\n        text: undefined,\n        reasoning: undefined,\n      },\n      raw: undefined,\n    };\n  }\n\n  const inputTokens = usage.input_tokens;\n  const outputTokens = usage.output_tokens;\n  const cachedTokens = usage.input_tokens_details?.cached_tokens ?? 0;\n  const reasoningTokens = usage.output_tokens_details?.reasoning_tokens ?? 0;\n\n  return {\n    inputTokens: {\n      total: inputTokens,\n      noCache: inputTokens - cachedTokens,\n      cacheRead: cachedTokens,\n      cacheWrite: undefined,\n    },\n    outputTokens: {\n      total: outputTokens,\n      text: outputTokens - reasoningTokens,\n      reasoning: reasoningTokens,\n    },\n    raw: usage,\n  };\n}\n","import {\n  LanguageModelV3Prompt,\n  LanguageModelV3ToolApprovalResponsePart,\n  SharedV3Warning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport {\n  convertToBase64,\n  isNonNullable,\n  parseProviderOptions,\n  ToolNameMapping,\n  validateTypes,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { applyPatchOutputSchema } from '../tool/apply-patch';\nimport {\n  localShellInputSchema,\n  localShellOutputSchema,\n} from '../tool/local-shell';\nimport { shellInputSchema, shellOutputSchema } from '../tool/shell';\nimport {\n  OpenAIResponsesFunctionCallOutput,\n  OpenAIResponsesInput,\n  OpenAIResponsesReasoning,\n} from './openai-responses-api';\n\n/**\n * Check if a string is a file ID based on the given prefixes\n * Returns false if prefixes is undefined (disables file ID detection)\n */\nfunction isFileId(data: string, prefixes?: readonly string[]): boolean {\n  if (!prefixes) return false;\n  return prefixes.some(prefix => data.startsWith(prefix));\n}\n\nexport async function convertToOpenAIResponsesInput({\n  prompt,\n  toolNameMapping,\n  systemMessageMode,\n  fileIdPrefixes,\n  store,\n  hasLocalShellTool = false,\n  hasShellTool = false,\n  hasApplyPatchTool = false,\n}: {\n  prompt: LanguageModelV3Prompt;\n  toolNameMapping: ToolNameMapping;\n  systemMessageMode: 'system' | 'developer' | 'remove';\n  fileIdPrefixes?: readonly string[];\n  store: boolean;\n  hasLocalShellTool?: boolean;\n  hasShellTool?: boolean;\n  hasApplyPatchTool?: boolean;\n}): Promise<{\n  input: OpenAIResponsesInput;\n  warnings: Array<SharedV3Warning>;\n}> {\n  const input: OpenAIResponsesInput = [];\n  const warnings: Array<SharedV3Warning> = [];\n  const processedApprovalIds = new Set<string>();\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        switch (systemMessageMode) {\n          case 'system': {\n            input.push({ role: 'system', content });\n            break;\n          }\n          case 'developer': {\n            input.push({ role: 'developer', content });\n            break;\n          }\n          case 'remove': {\n            warnings.push({\n              type: 'other',\n              message: 'system messages are removed for this model',\n            });\n            break;\n          }\n          default: {\n            const _exhaustiveCheck: never = systemMessageMode;\n            throw new Error(\n              `Unsupported system message mode: ${_exhaustiveCheck}`,\n            );\n          }\n        }\n        break;\n      }\n\n      case 'user': {\n        input.push({\n          role: 'user',\n          content: content.map((part, index) => {\n            switch (part.type) {\n              case 'text': {\n                return { type: 'input_text', text: part.text };\n              }\n              case 'file': {\n                if (part.mediaType.startsWith('image/')) {\n                  const mediaType =\n                    part.mediaType === 'image/*'\n                      ? 'image/jpeg'\n                      : part.mediaType;\n\n                  return {\n                    type: 'input_image',\n                    ...(part.data instanceof URL\n                      ? { image_url: part.data.toString() }\n                      : typeof part.data === 'string' &&\n                          isFileId(part.data, fileIdPrefixes)\n                        ? { file_id: part.data }\n                        : {\n                            image_url: `data:${mediaType};base64,${convertToBase64(part.data)}`,\n                          }),\n                    detail: part.providerOptions?.openai?.imageDetail,\n                  };\n                } else if (part.mediaType === 'application/pdf') {\n                  if (part.data instanceof URL) {\n                    return {\n                      type: 'input_file',\n                      file_url: part.data.toString(),\n                    };\n                  }\n                  return {\n                    type: 'input_file',\n                    ...(typeof part.data === 'string' &&\n                    isFileId(part.data, fileIdPrefixes)\n                      ? { file_id: part.data }\n                      : {\n                          filename: part.filename ?? `part-${index}.pdf`,\n                          file_data: `data:application/pdf;base64,${convertToBase64(part.data)}`,\n                        }),\n                  };\n                } else {\n                  throw new UnsupportedFunctionalityError({\n                    functionality: `file part media type ${part.mediaType}`,\n                  });\n                }\n              }\n            }\n          }),\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        const reasoningMessages: Record<string, OpenAIResponsesReasoning> = {};\n\n        for (const part of content) {\n          switch (part.type) {\n            case 'text': {\n              const id = part.providerOptions?.openai?.itemId as\n                | string\n                | undefined;\n\n              // item references reduce the payload size\n              if (store && id != null) {\n                input.push({ type: 'item_reference', id });\n                break;\n              }\n\n              input.push({\n                role: 'assistant',\n                content: [{ type: 'output_text', text: part.text }],\n                id,\n              });\n\n              break;\n            }\n            case 'tool-call': {\n              const id = (part.providerOptions?.openai?.itemId ??\n                (\n                  part as {\n                    providerMetadata?: { openai?: { itemId?: string } };\n                  }\n                ).providerMetadata?.openai?.itemId) as string | undefined;\n              if (part.providerExecuted) {\n                if (store && id != null) {\n                  input.push({ type: 'item_reference', id });\n                }\n                break;\n              }\n\n              if (store && id != null) {\n                input.push({ type: 'item_reference', id });\n                break;\n              }\n\n              const resolvedToolName = toolNameMapping.toProviderToolName(\n                part.toolName,\n              );\n\n              if (hasLocalShellTool && resolvedToolName === 'local_shell') {\n                const parsedInput = await validateTypes({\n                  value: part.input,\n                  schema: localShellInputSchema,\n                });\n                input.push({\n                  type: 'local_shell_call',\n                  call_id: part.toolCallId,\n                  id: id!,\n                  action: {\n                    type: 'exec',\n                    command: parsedInput.action.command,\n                    timeout_ms: parsedInput.action.timeoutMs,\n                    user: parsedInput.action.user,\n                    working_directory: parsedInput.action.workingDirectory,\n                    env: parsedInput.action.env,\n                  },\n                });\n\n                break;\n              }\n\n              if (hasShellTool && resolvedToolName === 'shell') {\n                const parsedInput = await validateTypes({\n                  value: part.input,\n                  schema: shellInputSchema,\n                });\n                input.push({\n                  type: 'shell_call',\n                  call_id: part.toolCallId,\n                  id: id!,\n                  status: 'completed',\n                  action: {\n                    commands: parsedInput.action.commands,\n                    timeout_ms: parsedInput.action.timeoutMs,\n                    max_output_length: parsedInput.action.maxOutputLength,\n                  },\n                });\n\n                break;\n              }\n\n              input.push({\n                type: 'function_call',\n                call_id: part.toolCallId,\n                name: resolvedToolName,\n                arguments: JSON.stringify(part.input),\n                id,\n              });\n              break;\n            }\n\n            // assistant tool result parts are from provider-executed tools:\n            case 'tool-result': {\n              // Skip execution-denied results - these are synthetic results from denied\n              // approvals and have no corresponding item in OpenAI's store.\n              // Check both the direct type and if it was transformed to json with execution-denied inside\n              if (\n                part.output.type === 'execution-denied' ||\n                (part.output.type === 'json' &&\n                  typeof part.output.value === 'object' &&\n                  part.output.value != null &&\n                  'type' in part.output.value &&\n                  part.output.value.type === 'execution-denied')\n              ) {\n                break;\n              }\n\n              if (store) {\n                const itemId =\n                  (\n                    part as {\n                      providerMetadata?: { openai?: { itemId?: string } };\n                    }\n                  ).providerMetadata?.openai?.itemId ?? part.toolCallId;\n                input.push({ type: 'item_reference', id: itemId });\n              } else {\n                warnings.push({\n                  type: 'other',\n                  message: `Results for OpenAI tool ${part.toolName} are not sent to the API when store is false`,\n                });\n              }\n\n              break;\n            }\n\n            case 'reasoning': {\n              const providerOptions = await parseProviderOptions({\n                provider: 'openai',\n                providerOptions: part.providerOptions,\n                schema: openaiResponsesReasoningProviderOptionsSchema,\n              });\n\n              const reasoningId = providerOptions?.itemId;\n\n              if (reasoningId != null) {\n                const reasoningMessage = reasoningMessages[reasoningId];\n\n                if (store) {\n                  // use item references to refer to reasoning (single reference)\n                  // when the first part is encountered\n                  if (reasoningMessage === undefined) {\n                    input.push({ type: 'item_reference', id: reasoningId });\n\n                    // store unused reasoning message to mark id as used\n                    reasoningMessages[reasoningId] = {\n                      type: 'reasoning',\n                      id: reasoningId,\n                      summary: [],\n                    };\n                  }\n                } else {\n                  const summaryParts: Array<{\n                    type: 'summary_text';\n                    text: string;\n                  }> = [];\n\n                  if (part.text.length > 0) {\n                    summaryParts.push({\n                      type: 'summary_text',\n                      text: part.text,\n                    });\n                  } else if (reasoningMessage !== undefined) {\n                    warnings.push({\n                      type: 'other',\n                      message: `Cannot append empty reasoning part to existing reasoning sequence. Skipping reasoning part: ${JSON.stringify(part)}.`,\n                    });\n                  }\n\n                  if (reasoningMessage === undefined) {\n                    reasoningMessages[reasoningId] = {\n                      type: 'reasoning',\n                      id: reasoningId,\n                      encrypted_content:\n                        providerOptions?.reasoningEncryptedContent,\n                      summary: summaryParts,\n                    };\n                    input.push(reasoningMessages[reasoningId]);\n                  } else {\n                    reasoningMessage.summary.push(...summaryParts);\n\n                    // updated encrypted content to enable setting it in the last summary part:\n                    if (providerOptions?.reasoningEncryptedContent != null) {\n                      reasoningMessage.encrypted_content =\n                        providerOptions.reasoningEncryptedContent;\n                    }\n                  }\n                }\n              } else {\n                warnings.push({\n                  type: 'other',\n                  message: `Non-OpenAI reasoning parts are not supported. Skipping reasoning part: ${JSON.stringify(part)}.`,\n                });\n              }\n              break;\n            }\n          }\n        }\n\n        break;\n      }\n\n      case 'tool': {\n        for (const part of content) {\n          if (part.type === 'tool-approval-response') {\n            const approvalResponse =\n              part as LanguageModelV3ToolApprovalResponsePart;\n\n            if (processedApprovalIds.has(approvalResponse.approvalId)) {\n              continue;\n            }\n            processedApprovalIds.add(approvalResponse.approvalId);\n\n            if (store) {\n              input.push({\n                type: 'item_reference',\n                id: approvalResponse.approvalId,\n              });\n            }\n\n            input.push({\n              type: 'mcp_approval_response',\n              approval_request_id: approvalResponse.approvalId,\n              approve: approvalResponse.approved,\n            });\n            continue;\n          }\n\n          const output = part.output;\n\n          // Skip execution-denied with approvalId - already handled via tool-approval-response\n          if (output.type === 'execution-denied') {\n            const approvalId = (\n              output.providerOptions?.openai as { approvalId?: string }\n            )?.approvalId;\n\n            if (approvalId) {\n              continue;\n            }\n          }\n\n          const resolvedToolName = toolNameMapping.toProviderToolName(\n            part.toolName,\n          );\n\n          if (\n            hasLocalShellTool &&\n            resolvedToolName === 'local_shell' &&\n            output.type === 'json'\n          ) {\n            const parsedOutput = await validateTypes({\n              value: output.value,\n              schema: localShellOutputSchema,\n            });\n\n            input.push({\n              type: 'local_shell_call_output',\n              call_id: part.toolCallId,\n              output: parsedOutput.output,\n            });\n            continue;\n          }\n\n          if (\n            hasShellTool &&\n            resolvedToolName === 'shell' &&\n            output.type === 'json'\n          ) {\n            const parsedOutput = await validateTypes({\n              value: output.value,\n              schema: shellOutputSchema,\n            });\n\n            input.push({\n              type: 'shell_call_output',\n              call_id: part.toolCallId,\n              output: parsedOutput.output.map(item => ({\n                stdout: item.stdout,\n                stderr: item.stderr,\n                outcome:\n                  item.outcome.type === 'timeout'\n                    ? { type: 'timeout' as const }\n                    : {\n                        type: 'exit' as const,\n                        exit_code: item.outcome.exitCode,\n                      },\n              })),\n            });\n            continue;\n          }\n\n          if (\n            hasApplyPatchTool &&\n            part.toolName === 'apply_patch' &&\n            output.type === 'json'\n          ) {\n            const parsedOutput = await validateTypes({\n              value: output.value,\n              schema: applyPatchOutputSchema,\n            });\n\n            input.push({\n              type: 'apply_patch_call_output',\n              call_id: part.toolCallId,\n              status: parsedOutput.status,\n              output: parsedOutput.output,\n            });\n            continue;\n          }\n\n          let contentValue: OpenAIResponsesFunctionCallOutput['output'];\n          switch (output.type) {\n            case 'text':\n            case 'error-text':\n              contentValue = output.value;\n              break;\n            case 'execution-denied':\n              contentValue = output.reason ?? 'Tool execution denied.';\n              break;\n            case 'json':\n            case 'error-json':\n              contentValue = JSON.stringify(output.value);\n              break;\n            case 'content':\n              contentValue = output.value\n                .map(item => {\n                  switch (item.type) {\n                    case 'text': {\n                      return { type: 'input_text' as const, text: item.text };\n                    }\n\n                    case 'image-data': {\n                      return {\n                        type: 'input_image' as const,\n                        image_url: `data:${item.mediaType};base64,${item.data}`,\n                      };\n                    }\n\n                    case 'file-data': {\n                      return {\n                        type: 'input_file' as const,\n                        filename: item.filename ?? 'data',\n                        file_data: `data:${item.mediaType};base64,${item.data}`,\n                      };\n                    }\n\n                    default: {\n                      warnings.push({\n                        type: 'other',\n                        message: `unsupported tool content part type: ${item.type}`,\n                      });\n                      return undefined;\n                    }\n                  }\n                })\n                .filter(isNonNullable);\n              break;\n          }\n\n          input.push({\n            type: 'function_call_output',\n            call_id: part.toolCallId,\n            output: contentValue,\n          });\n        }\n\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  return { input, warnings };\n}\n\nconst openaiResponsesReasoningProviderOptionsSchema = z.object({\n  itemId: z.string().nullish(),\n  reasoningEncryptedContent: z.string().nullish(),\n});\n\nexport type OpenAIResponsesReasoningProviderOptions = z.infer<\n  typeof openaiResponsesReasoningProviderOptionsSchema\n>;\n","import {\n  createProviderToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n/**\n * Schema for the apply_patch input - what the model sends.\n *\n * Refer the official spec here: https://platform.openai.com/docs/api-reference/responses/create#responses_create-input-input_item_list-item-apply_patch_tool_call\n *\n */\nexport const applyPatchInputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      callId: z.string(),\n      operation: z.discriminatedUnion('type', [\n        z.object({\n          type: z.literal('create_file'),\n          path: z.string(),\n          diff: z.string(),\n        }),\n        z.object({\n          type: z.literal('delete_file'),\n          path: z.string(),\n        }),\n        z.object({\n          type: z.literal('update_file'),\n          path: z.string(),\n          diff: z.string(),\n        }),\n      ]),\n    }),\n  ),\n);\n\n/**\n * Schema for the apply_patch output - what we send back.\n */\nexport const applyPatchOutputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      status: z.enum(['completed', 'failed']),\n      output: z.string().optional(),\n    }),\n  ),\n);\n\n/**\n * Schema for tool arguments (configuration options).\n * The apply_patch tool doesn't require any configuration options.\n */\nexport const applyPatchArgsSchema = lazySchema(() => zodSchema(z.object({})));\n\n/**\n * Type definitions for the apply_patch operations.\n */\nexport type ApplyPatchOperation =\n  | {\n      type: 'create_file';\n      /**\n       * Path of the file to create relative to the workspace root.\n       */\n      path: string;\n      /**\n       * Unified diff content to apply when creating the file.\n       */\n      diff: string;\n    }\n  | {\n      type: 'delete_file';\n      /**\n       * Path of the file to delete relative to the workspace root.\n       */\n      path: string;\n    }\n  | {\n      type: 'update_file';\n      /**\n       * Path of the file to update relative to the workspace root.\n       */\n      path: string;\n      /**\n       * Unified diff content to apply to the existing file.\n       */\n      diff: string;\n    };\n\n/**\n * The apply_patch tool lets GPT-5.1 create, update, and delete files in your\n * codebase using structured diffs. Instead of just suggesting edits, the model\n * emits patch operations that your application applies and then reports back on,\n * enabling iterative, multi-step code editing workflows.\n *\n * The tool factory creates a provider-defined tool that:\n * - Receives patch operations from the model (create_file, update_file, delete_file)\n * - Returns the status of applying those patches (completed or failed)\n *\n */\nexport const applyPatchToolFactory = createProviderToolFactoryWithOutputSchema<\n  {\n    /**\n     * The unique ID of the apply patch tool call generated by the model.\n     */\n    callId: string;\n\n    /**\n     * The specific create, delete, or update instruction for the apply_patch tool call.\n     */\n    operation: ApplyPatchOperation;\n  },\n  {\n    /**\n     * The status of the apply patch tool call output.\n     * - 'completed': The patch was applied successfully.\n     * - 'failed': The patch failed to apply.\n     */\n    status: 'completed' | 'failed';\n\n    /**\n     * Optional human-readable log text from the apply patch tool\n     * (e.g., patch results or errors).\n     */\n    output?: string;\n  },\n  // No configuration options for apply_patch\n  {}\n>({\n  id: 'openai.apply_patch',\n  inputSchema: applyPatchInputSchema,\n  outputSchema: applyPatchOutputSchema,\n});\n\n/**\n * The apply_patch tool lets GPT-5.1 create, update, and delete files in your\n * codebase using structured diffs. Instead of just suggesting edits, the model\n * emits patch operations that your application applies and then reports back on,\n * enabling iterative, multi-step code editing workflows.\n */\nexport const applyPatch = applyPatchToolFactory;\n","import {\n  createProviderToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const localShellInputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      action: z.object({\n        type: z.literal('exec'),\n        command: z.array(z.string()),\n        timeoutMs: z.number().optional(),\n        user: z.string().optional(),\n        workingDirectory: z.string().optional(),\n        env: z.record(z.string(), z.string()).optional(),\n      }),\n    }),\n  ),\n);\n\nexport const localShellOutputSchema = lazySchema(() =>\n  zodSchema(z.object({ output: z.string() })),\n);\n\nexport const localShell = createProviderToolFactoryWithOutputSchema<\n  {\n    /**\n     * Execute a shell command on the server.\n     */\n    action: {\n      type: 'exec';\n\n      /**\n       * The command to run.\n       */\n      command: string[];\n\n      /**\n       * Optional timeout in milliseconds for the command.\n       */\n      timeoutMs?: number;\n\n      /**\n       * Optional user to run the command as.\n       */\n      user?: string;\n\n      /**\n       * Optional working directory to run the command in.\n       */\n      workingDirectory?: string;\n\n      /**\n       * Environment variables to set for the command.\n       */\n      env?: Record<string, string>;\n    };\n  },\n  {\n    /**\n     * The output of local shell tool call.\n     */\n    output: string;\n  },\n  {}\n>({\n  id: 'openai.local_shell',\n  inputSchema: localShellInputSchema,\n  outputSchema: localShellOutputSchema,\n});\n","import {\n  createProviderToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const shellInputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      action: z.object({\n        commands: z.array(z.string()),\n        timeoutMs: z.number().optional(),\n        maxOutputLength: z.number().optional(),\n      }),\n    }),\n  ),\n);\n\nexport const shellOutputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      output: z.array(\n        z.object({\n          stdout: z.string(),\n          stderr: z.string(),\n          outcome: z.discriminatedUnion('type', [\n            z.object({ type: z.literal('timeout') }),\n            z.object({ type: z.literal('exit'), exitCode: z.number() }),\n          ]),\n        }),\n      ),\n    }),\n  ),\n);\n\nexport const shell = createProviderToolFactoryWithOutputSchema<\n  {\n    /**\n     * Shell tool action containing commands to execute.\n     */\n    action: {\n      /**\n       * A list of shell commands to execute.\n       */\n      commands: string[];\n\n      /**\n       * Optional timeout in milliseconds for the commands.\n       */\n      timeoutMs?: number;\n\n      /**\n       * Optional maximum number of characters to return from each command.\n       */\n      maxOutputLength?: number;\n    };\n  },\n  {\n    /**\n     * An array of shell call output contents.\n     */\n    output: Array<{\n      /**\n       * Standard output from the command.\n       */\n      stdout: string;\n\n      /**\n       * Standard error from the command.\n       */\n      stderr: string;\n\n      /**\n       * The outcome of the shell execution - either timeout or exit with code.\n       */\n      outcome: { type: 'timeout' } | { type: 'exit'; exitCode: number };\n    }>;\n  },\n  {}\n>({\n  id: 'openai.shell',\n  inputSchema: shellInputSchema,\n  outputSchema: shellOutputSchema,\n});\n","import { LanguageModelV3FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAIResponseFinishReason({\n  finishReason,\n  hasFunctionCall,\n}: {\n  finishReason: string | null | undefined;\n  // flag that checks if there have been client-side tool calls (not executed by openai)\n  hasFunctionCall: boolean;\n}): LanguageModelV3FinishReason['unified'] {\n  switch (finishReason) {\n    case undefined:\n    case null:\n      return hasFunctionCall ? 'tool-calls' : 'stop';\n    case 'max_output_tokens':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    default:\n      return hasFunctionCall ? 'tool-calls' : 'other';\n  }\n}\n","import { JSONSchema7 } from '@ai-sdk/provider';\nimport { InferSchema, lazySchema, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport type OpenAIResponsesInput = Array<OpenAIResponsesInputItem>;\n\nexport type OpenAIResponsesInputItem =\n  | OpenAIResponsesSystemMessage\n  | OpenAIResponsesUserMessage\n  | OpenAIResponsesAssistantMessage\n  | OpenAIResponsesFunctionCall\n  | OpenAIResponsesFunctionCallOutput\n  | OpenAIResponsesMcpApprovalResponse\n  | OpenAIResponsesComputerCall\n  | OpenAIResponsesLocalShellCall\n  | OpenAIResponsesLocalShellCallOutput\n  | OpenAIResponsesShellCall\n  | OpenAIResponsesShellCallOutput\n  | OpenAIResponsesApplyPatchCall\n  | OpenAIResponsesApplyPatchCallOutput\n  | OpenAIResponsesReasoning\n  | OpenAIResponsesItemReference;\n\nexport type OpenAIResponsesIncludeValue =\n  | 'web_search_call.action.sources'\n  | 'code_interpreter_call.outputs'\n  | 'computer_call_output.output.image_url'\n  | 'file_search_call.results'\n  | 'message.input_image.image_url'\n  | 'message.output_text.logprobs'\n  | 'reasoning.encrypted_content';\n\nexport type OpenAIResponsesIncludeOptions =\n  | Array<OpenAIResponsesIncludeValue>\n  | undefined\n  | null;\n\nexport type OpenAIResponsesApplyPatchOperationDiffDeltaChunk = {\n  type: 'response.apply_patch_call_operation_diff.delta';\n  item_id: string;\n  output_index: number;\n  delta: string;\n  obfuscation?: string | null;\n};\n\nexport type OpenAIResponsesApplyPatchOperationDiffDoneChunk = {\n  type: 'response.apply_patch_call_operation_diff.done';\n  item_id: string;\n  output_index: number;\n  diff: string;\n};\n\nexport type OpenAIResponsesSystemMessage = {\n  role: 'system' | 'developer';\n  content: string;\n};\n\nexport type OpenAIResponsesUserMessage = {\n  role: 'user';\n  content: Array<\n    | { type: 'input_text'; text: string }\n    | { type: 'input_image'; image_url: string }\n    | { type: 'input_image'; file_id: string }\n    | { type: 'input_file'; file_url: string }\n    | { type: 'input_file'; filename: string; file_data: string }\n    | { type: 'input_file'; file_id: string }\n  >;\n};\n\nexport type OpenAIResponsesAssistantMessage = {\n  role: 'assistant';\n  content: Array<{ type: 'output_text'; text: string }>;\n  id?: string;\n};\n\nexport type OpenAIResponsesFunctionCall = {\n  type: 'function_call';\n  call_id: string;\n  name: string;\n  arguments: string;\n  id?: string;\n};\n\nexport type OpenAIResponsesFunctionCallOutput = {\n  type: 'function_call_output';\n  call_id: string;\n  output:\n    | string\n    | Array<\n        | { type: 'input_text'; text: string }\n        | { type: 'input_image'; image_url: string }\n        | { type: 'input_file'; filename: string; file_data: string }\n      >;\n};\n\nexport type OpenAIResponsesMcpApprovalResponse = {\n  type: 'mcp_approval_response';\n  approval_request_id: string;\n  approve: boolean;\n};\n\nexport type OpenAIResponsesComputerCall = {\n  type: 'computer_call';\n  id: string;\n  status?: string;\n};\n\nexport type OpenAIResponsesLocalShellCall = {\n  type: 'local_shell_call';\n  id: string;\n  call_id: string;\n  action: {\n    type: 'exec';\n    command: string[];\n    timeout_ms?: number;\n    user?: string;\n    working_directory?: string;\n    env?: Record<string, string>;\n  };\n};\n\nexport type OpenAIResponsesLocalShellCallOutput = {\n  type: 'local_shell_call_output';\n  call_id: string;\n  output: string;\n};\n\n/**\n * Official OpenAI API Specifications: https://platform.openai.com/docs/api-reference/responses/object#responses-object-output-shell_tool_call\n */\nexport type OpenAIResponsesShellCall = {\n  type: 'shell_call';\n  id: string;\n  call_id: string;\n  status: 'in_progress' | 'completed' | 'incomplete';\n  action: {\n    commands: string[];\n    timeout_ms?: number;\n    max_output_length?: number;\n  };\n};\n\nexport type OpenAIResponsesShellCallOutput = {\n  type: 'shell_call_output';\n  call_id: string;\n  max_output_length?: number;\n  output: Array<{\n    stdout: string;\n    stderr: string;\n    outcome: { type: 'timeout' } | { type: 'exit'; exit_code: number };\n  }>;\n};\n\nexport type OpenAIResponsesApplyPatchCall = {\n  type: 'apply_patch_call';\n  id?: string;\n  call_id: string;\n  status: 'in_progress' | 'completed';\n  operation:\n    | {\n        type: 'create_file';\n        path: string;\n        diff: string;\n      }\n    | {\n        type: 'delete_file';\n        path: string;\n      }\n    | {\n        type: 'update_file';\n        path: string;\n        diff: string;\n      };\n};\n\nexport type OpenAIResponsesApplyPatchCallOutput = {\n  type: 'apply_patch_call_output';\n  call_id: string;\n  status: 'completed' | 'failed';\n  output?: string;\n};\n\nexport type OpenAIResponsesItemReference = {\n  type: 'item_reference';\n  id: string;\n};\n\n/**\n * A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n */\nexport type OpenAIResponsesFileSearchToolComparisonFilter = {\n  /**\n   * The key to compare against the value.\n   */\n  key: string;\n\n  /**\n   * Specifies the comparison operator: eq, ne, gt, gte, lt, lte, in, nin.\n   */\n  type: 'eq' | 'ne' | 'gt' | 'gte' | 'lt' | 'lte' | 'in' | 'nin';\n\n  /**\n   * The value to compare against the attribute key; supports string, number, boolean, or array of string types.\n   */\n  value: string | number | boolean | string[];\n};\n\n/**\n * Combine multiple filters using and or or.\n */\nexport type OpenAIResponsesFileSearchToolCompoundFilter = {\n  /**\n   * Type of operation: and or or.\n   */\n  type: 'and' | 'or';\n\n  /**\n   * Array of filters to combine. Items can be ComparisonFilter or CompoundFilter.\n   */\n  filters: Array<\n    | OpenAIResponsesFileSearchToolComparisonFilter\n    | OpenAIResponsesFileSearchToolCompoundFilter\n  >;\n};\n\nexport type OpenAIResponsesTool =\n  | {\n      type: 'function';\n      name: string;\n      description: string | undefined;\n      parameters: JSONSchema7;\n      strict?: boolean;\n    }\n  | {\n      type: 'apply_patch';\n    }\n  | {\n      type: 'web_search';\n      external_web_access: boolean | undefined;\n      filters: { allowed_domains: string[] | undefined } | undefined;\n      search_context_size: 'low' | 'medium' | 'high' | undefined;\n      user_location:\n        | {\n            type: 'approximate';\n            city?: string;\n            country?: string;\n            region?: string;\n            timezone?: string;\n          }\n        | undefined;\n    }\n  | {\n      type: 'web_search_preview';\n      search_context_size: 'low' | 'medium' | 'high' | undefined;\n      user_location:\n        | {\n            type: 'approximate';\n            city?: string;\n            country?: string;\n            region?: string;\n            timezone?: string;\n          }\n        | undefined;\n    }\n  | {\n      type: 'code_interpreter';\n      container: string | { type: 'auto'; file_ids: string[] | undefined };\n    }\n  | {\n      type: 'file_search';\n      vector_store_ids: string[];\n      max_num_results: number | undefined;\n      ranking_options:\n        | { ranker?: string; score_threshold?: number }\n        | undefined;\n      filters:\n        | OpenAIResponsesFileSearchToolComparisonFilter\n        | OpenAIResponsesFileSearchToolCompoundFilter\n        | undefined;\n    }\n  | {\n      type: 'image_generation';\n      background: 'auto' | 'opaque' | 'transparent' | undefined;\n      input_fidelity: 'low' | 'high' | undefined;\n      input_image_mask:\n        | {\n            file_id: string | undefined;\n            image_url: string | undefined;\n          }\n        | undefined;\n      model: string | undefined;\n      moderation: 'auto' | undefined;\n      output_compression: number | undefined;\n      output_format: 'png' | 'jpeg' | 'webp' | undefined;\n      partial_images: number | undefined;\n      quality: 'auto' | 'low' | 'medium' | 'high' | undefined;\n      size: 'auto' | '1024x1024' | '1024x1536' | '1536x1024' | undefined;\n    }\n\n  /**\n   * Official OpenAI API Specifications: https://platform.openai.com/docs/api-reference/responses/create#responses_create-tools-mcp_tool\n   */\n  | {\n      type: 'mcp';\n      server_label: string;\n      allowed_tools:\n        | string[]\n        | {\n            read_only?: boolean;\n            tool_names?: string[];\n          }\n        | undefined;\n      authorization: string | undefined;\n      connector_id: string | undefined;\n      headers: Record<string, string> | undefined;\n      require_approval:\n        | 'always'\n        | 'never'\n        | {\n            never?: { tool_names?: string[] };\n          }\n        | undefined;\n      server_description: string | undefined;\n      server_url: string | undefined;\n    }\n  | {\n      type: 'local_shell';\n    }\n  | {\n      type: 'shell';\n    };\n\nexport type OpenAIResponsesReasoning = {\n  type: 'reasoning';\n  id: string;\n  encrypted_content?: string | null;\n  summary: Array<{\n    type: 'summary_text';\n    text: string;\n  }>;\n};\n\nexport const openaiResponsesChunkSchema = lazySchema(() =>\n  zodSchema(\n    z.union([\n      z.object({\n        type: z.literal('response.output_text.delta'),\n        item_id: z.string(),\n        delta: z.string(),\n        logprobs: z\n          .array(\n            z.object({\n              token: z.string(),\n              logprob: z.number(),\n              top_logprobs: z.array(\n                z.object({\n                  token: z.string(),\n                  logprob: z.number(),\n                }),\n              ),\n            }),\n          )\n          .nullish(),\n      }),\n      z.object({\n        type: z.enum(['response.completed', 'response.incomplete']),\n        response: z.object({\n          incomplete_details: z.object({ reason: z.string() }).nullish(),\n          usage: z.object({\n            input_tokens: z.number(),\n            input_tokens_details: z\n              .object({ cached_tokens: z.number().nullish() })\n              .nullish(),\n            output_tokens: z.number(),\n            output_tokens_details: z\n              .object({ reasoning_tokens: z.number().nullish() })\n              .nullish(),\n          }),\n          service_tier: z.string().nullish(),\n        }),\n      }),\n      z.object({\n        type: z.literal('response.created'),\n        response: z.object({\n          id: z.string(),\n          created_at: z.number(),\n          model: z.string(),\n          service_tier: z.string().nullish(),\n        }),\n      }),\n      z.object({\n        type: z.literal('response.output_item.added'),\n        output_index: z.number(),\n        item: z.discriminatedUnion('type', [\n          z.object({\n            type: z.literal('message'),\n            id: z.string(),\n          }),\n          z.object({\n            type: z.literal('reasoning'),\n            id: z.string(),\n            encrypted_content: z.string().nullish(),\n          }),\n          z.object({\n            type: z.literal('function_call'),\n            id: z.string(),\n            call_id: z.string(),\n            name: z.string(),\n            arguments: z.string(),\n          }),\n          z.object({\n            type: z.literal('web_search_call'),\n            id: z.string(),\n            status: z.string(),\n          }),\n          z.object({\n            type: z.literal('computer_call'),\n            id: z.string(),\n            status: z.string(),\n          }),\n          z.object({\n            type: z.literal('file_search_call'),\n            id: z.string(),\n          }),\n          z.object({\n            type: z.literal('image_generation_call'),\n            id: z.string(),\n          }),\n          z.object({\n            type: z.literal('code_interpreter_call'),\n            id: z.string(),\n            container_id: z.string(),\n            code: z.string().nullable(),\n            outputs: z\n              .array(\n                z.discriminatedUnion('type', [\n                  z.object({ type: z.literal('logs'), logs: z.string() }),\n                  z.object({ type: z.literal('image'), url: z.string() }),\n                ]),\n              )\n              .nullable(),\n            status: z.string(),\n          }),\n          z.object({\n            type: z.literal('mcp_call'),\n            id: z.string(),\n            status: z.string(),\n            approval_request_id: z.string().nullish(),\n          }),\n          z.object({\n            type: z.literal('mcp_list_tools'),\n            id: z.string(),\n          }),\n          z.object({\n            type: z.literal('mcp_approval_request'),\n            id: z.string(),\n          }),\n          z.object({\n            type: z.literal('apply_patch_call'),\n            id: z.string(),\n            call_id: z.string(),\n            status: z.enum(['in_progress', 'completed']),\n            operation: z.discriminatedUnion('type', [\n              z.object({\n                type: z.literal('create_file'),\n                path: z.string(),\n                diff: z.string(),\n              }),\n              z.object({\n                type: z.literal('delete_file'),\n                path: z.string(),\n              }),\n              z.object({\n                type: z.literal('update_file'),\n                path: z.string(),\n                diff: z.string(),\n              }),\n            ]),\n          }),\n          z.object({\n            type: z.literal('shell_call'),\n            id: z.string(),\n            call_id: z.string(),\n            status: z.enum(['in_progress', 'completed', 'incomplete']),\n            action: z.object({\n              commands: z.array(z.string()),\n            }),\n          }),\n        ]),\n      }),\n      z.object({\n        type: z.literal('response.output_item.done'),\n        output_index: z.number(),\n        item: z.discriminatedUnion('type', [\n          z.object({\n            type: z.literal('message'),\n            id: z.string(),\n          }),\n          z.object({\n            type: z.literal('reasoning'),\n            id: z.string(),\n            encrypted_content: z.string().nullish(),\n          }),\n          z.object({\n            type: z.literal('function_call'),\n            id: z.string(),\n            call_id: z.string(),\n            name: z.string(),\n            arguments: z.string(),\n            status: z.literal('completed'),\n          }),\n          z.object({\n            type: z.literal('code_interpreter_call'),\n            id: z.string(),\n            code: z.string().nullable(),\n            container_id: z.string(),\n            outputs: z\n              .array(\n                z.discriminatedUnion('type', [\n                  z.object({ type: z.literal('logs'), logs: z.string() }),\n                  z.object({ type: z.literal('image'), url: z.string() }),\n                ]),\n              )\n              .nullable(),\n          }),\n          z.object({\n            type: z.literal('image_generation_call'),\n            id: z.string(),\n            result: z.string(),\n          }),\n          z.object({\n            type: z.literal('web_search_call'),\n            id: z.string(),\n            status: z.string(),\n            action: z.discriminatedUnion('type', [\n              z.object({\n                type: z.literal('search'),\n                query: z.string().nullish(),\n                sources: z\n                  .array(\n                    z.discriminatedUnion('type', [\n                      z.object({ type: z.literal('url'), url: z.string() }),\n                      z.object({ type: z.literal('api'), name: z.string() }),\n                    ]),\n                  )\n                  .nullish(),\n              }),\n              z.object({\n                type: z.literal('open_page'),\n                url: z.string().nullish(),\n              }),\n              z.object({\n                type: z.literal('find_in_page'),\n                url: z.string().nullish(),\n                pattern: z.string().nullish(),\n              }),\n            ]),\n          }),\n          z.object({\n            type: z.literal('file_search_call'),\n            id: z.string(),\n            queries: z.array(z.string()),\n            results: z\n              .array(\n                z.object({\n                  attributes: z.record(\n                    z.string(),\n                    z.union([z.string(), z.number(), z.boolean()]),\n                  ),\n                  file_id: z.string(),\n                  filename: z.string(),\n                  score: z.number(),\n                  text: z.string(),\n                }),\n              )\n              .nullish(),\n          }),\n          z.object({\n            type: z.literal('local_shell_call'),\n            id: z.string(),\n            call_id: z.string(),\n            action: z.object({\n              type: z.literal('exec'),\n              command: z.array(z.string()),\n              timeout_ms: z.number().optional(),\n              user: z.string().optional(),\n              working_directory: z.string().optional(),\n              env: z.record(z.string(), z.string()).optional(),\n            }),\n          }),\n          z.object({\n            type: z.literal('computer_call'),\n            id: z.string(),\n            status: z.literal('completed'),\n          }),\n          z.object({\n            type: z.literal('mcp_call'),\n            id: z.string(),\n            status: z.string(),\n            arguments: z.string(),\n            name: z.string(),\n            server_label: z.string(),\n            output: z.string().nullish(),\n            error: z\n              .union([\n                z.string(),\n                z\n                  .object({\n                    type: z.string().optional(),\n                    code: z.union([z.number(), z.string()]).optional(),\n                    message: z.string().optional(),\n                  })\n                  .loose(),\n              ])\n              .nullish(),\n            approval_request_id: z.string().nullish(),\n          }),\n          z.object({\n            type: z.literal('mcp_list_tools'),\n            id: z.string(),\n            server_label: z.string(),\n            tools: z.array(\n              z.object({\n                name: z.string(),\n                description: z.string().optional(),\n                input_schema: z.any(),\n                annotations: z.record(z.string(), z.unknown()).optional(),\n              }),\n            ),\n            error: z\n              .union([\n                z.string(),\n                z\n                  .object({\n                    type: z.string().optional(),\n                    code: z.union([z.number(), z.string()]).optional(),\n                    message: z.string().optional(),\n                  })\n                  .loose(),\n              ])\n              .optional(),\n          }),\n          z.object({\n            type: z.literal('mcp_approval_request'),\n            id: z.string(),\n            server_label: z.string(),\n            name: z.string(),\n            arguments: z.string(),\n            approval_request_id: z.string().optional(),\n          }),\n          z.object({\n            type: z.literal('apply_patch_call'),\n            id: z.string(),\n            call_id: z.string(),\n            status: z.enum(['in_progress', 'completed']),\n            operation: z.discriminatedUnion('type', [\n              z.object({\n                type: z.literal('create_file'),\n                path: z.string(),\n                diff: z.string(),\n              }),\n              z.object({\n                type: z.literal('delete_file'),\n                path: z.string(),\n              }),\n              z.object({\n                type: z.literal('update_file'),\n                path: z.string(),\n                diff: z.string(),\n              }),\n            ]),\n          }),\n          z.object({\n            type: z.literal('shell_call'),\n            id: z.string(),\n            call_id: z.string(),\n            status: z.enum(['in_progress', 'completed', 'incomplete']),\n            action: z.object({\n              commands: z.array(z.string()),\n            }),\n          }),\n        ]),\n      }),\n      z.object({\n        type: z.literal('response.function_call_arguments.delta'),\n        item_id: z.string(),\n        output_index: z.number(),\n        delta: z.string(),\n      }),\n      z.object({\n        type: z.literal('response.image_generation_call.partial_image'),\n        item_id: z.string(),\n        output_index: z.number(),\n        partial_image_b64: z.string(),\n      }),\n      z.object({\n        type: z.literal('response.code_interpreter_call_code.delta'),\n        item_id: z.string(),\n        output_index: z.number(),\n        delta: z.string(),\n      }),\n      z.object({\n        type: z.literal('response.code_interpreter_call_code.done'),\n        item_id: z.string(),\n        output_index: z.number(),\n        code: z.string(),\n      }),\n      z.object({\n        type: z.literal('response.output_text.annotation.added'),\n        annotation: z.discriminatedUnion('type', [\n          z.object({\n            type: z.literal('url_citation'),\n            start_index: z.number(),\n            end_index: z.number(),\n            url: z.string(),\n            title: z.string(),\n          }),\n          z.object({\n            type: z.literal('file_citation'),\n            file_id: z.string(),\n            filename: z.string().nullish(),\n            index: z.number().nullish(),\n            start_index: z.number().nullish(),\n            end_index: z.number().nullish(),\n            quote: z.string().nullish(),\n          }),\n          z.object({\n            type: z.literal('container_file_citation'),\n            container_id: z.string(),\n            file_id: z.string(),\n            filename: z.string().nullish(),\n            start_index: z.number().nullish(),\n            end_index: z.number().nullish(),\n            index: z.number().nullish(),\n          }),\n          z.object({\n            type: z.literal('file_path'),\n            file_id: z.string(),\n            index: z.number().nullish(),\n          }),\n        ]),\n      }),\n      z.object({\n        type: z.literal('response.reasoning_summary_part.added'),\n        item_id: z.string(),\n        summary_index: z.number(),\n      }),\n      z.object({\n        type: z.literal('response.reasoning_summary_text.delta'),\n        item_id: z.string(),\n        summary_index: z.number(),\n        delta: z.string(),\n      }),\n      z.object({\n        type: z.literal('response.reasoning_summary_part.done'),\n        item_id: z.string(),\n        summary_index: z.number(),\n      }),\n      z.object({\n        type: z.literal('response.apply_patch_call_operation_diff.delta'),\n        item_id: z.string(),\n        output_index: z.number(),\n        delta: z.string(),\n        obfuscation: z.string().nullish(),\n      }),\n      z.object({\n        type: z.literal('response.apply_patch_call_operation_diff.done'),\n        item_id: z.string(),\n        output_index: z.number(),\n        diff: z.string(),\n      }),\n      z.object({\n        type: z.literal('error'),\n        sequence_number: z.number(),\n        error: z.object({\n          type: z.string(),\n          code: z.string(),\n          message: z.string(),\n          param: z.string().nullish(),\n        }),\n      }),\n      z\n        .object({ type: z.string() })\n        .loose()\n        .transform(value => ({\n          type: 'unknown_chunk' as const,\n          message: value.type,\n        })), // fallback for unknown chunks\n    ]),\n  ),\n);\n\nexport type OpenAIResponsesChunk = InferSchema<\n  typeof openaiResponsesChunkSchema\n>;\n\nexport type OpenAIResponsesLogprobs = NonNullable<\n  (OpenAIResponsesChunk & {\n    type: 'response.output_text.delta';\n  })['logprobs']\n> | null;\n\nexport type OpenAIResponsesWebSearchAction = NonNullable<\n  ((OpenAIResponsesChunk & {\n    type: 'response.output_item.done';\n  })['item'] & {\n    type: 'web_search_call';\n  })['action']\n>;\n\nexport const openaiResponsesResponseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      id: z.string().optional(),\n      created_at: z.number().optional(),\n      error: z\n        .object({\n          message: z.string(),\n          type: z.string(),\n          param: z.string().nullish(),\n          code: z.string(),\n        })\n        .nullish(),\n      model: z.string().optional(),\n      output: z\n        .array(\n          z.discriminatedUnion('type', [\n            z.object({\n              type: z.literal('message'),\n              role: z.literal('assistant'),\n              id: z.string(),\n              content: z.array(\n                z.object({\n                  type: z.literal('output_text'),\n                  text: z.string(),\n                  logprobs: z\n                    .array(\n                      z.object({\n                        token: z.string(),\n                        logprob: z.number(),\n                        top_logprobs: z.array(\n                          z.object({\n                            token: z.string(),\n                            logprob: z.number(),\n                          }),\n                        ),\n                      }),\n                    )\n                    .nullish(),\n                  annotations: z.array(\n                    z.discriminatedUnion('type', [\n                      z.object({\n                        type: z.literal('url_citation'),\n                        start_index: z.number(),\n                        end_index: z.number(),\n                        url: z.string(),\n                        title: z.string(),\n                      }),\n                      z.object({\n                        type: z.literal('file_citation'),\n                        file_id: z.string(),\n                        filename: z.string().nullish(),\n                        index: z.number().nullish(),\n                        start_index: z.number().nullish(),\n                        end_index: z.number().nullish(),\n                        quote: z.string().nullish(),\n                      }),\n                      z.object({\n                        type: z.literal('container_file_citation'),\n                        container_id: z.string(),\n                        file_id: z.string(),\n                        filename: z.string().nullish(),\n                        start_index: z.number().nullish(),\n                        end_index: z.number().nullish(),\n                        index: z.number().nullish(),\n                      }),\n                      z.object({\n                        type: z.literal('file_path'),\n                        file_id: z.string(),\n                        index: z.number().nullish(),\n                      }),\n                    ]),\n                  ),\n                }),\n              ),\n            }),\n            z.object({\n              type: z.literal('web_search_call'),\n              id: z.string(),\n              status: z.string(),\n              action: z.discriminatedUnion('type', [\n                z.object({\n                  type: z.literal('search'),\n                  query: z.string().nullish(),\n                  sources: z\n                    .array(\n                      z.discriminatedUnion('type', [\n                        z.object({ type: z.literal('url'), url: z.string() }),\n                        z.object({ type: z.literal('api'), name: z.string() }),\n                      ]),\n                    )\n                    .nullish(),\n                }),\n                z.object({\n                  type: z.literal('open_page'),\n                  url: z.string().nullish(),\n                }),\n                z.object({\n                  type: z.literal('find_in_page'),\n                  url: z.string().nullish(),\n                  pattern: z.string().nullish(),\n                }),\n              ]),\n            }),\n            z.object({\n              type: z.literal('file_search_call'),\n              id: z.string(),\n              queries: z.array(z.string()),\n              results: z\n                .array(\n                  z.object({\n                    attributes: z.record(\n                      z.string(),\n                      z.union([z.string(), z.number(), z.boolean()]),\n                    ),\n                    file_id: z.string(),\n                    filename: z.string(),\n                    score: z.number(),\n                    text: z.string(),\n                  }),\n                )\n                .nullish(),\n            }),\n            z.object({\n              type: z.literal('code_interpreter_call'),\n              id: z.string(),\n              code: z.string().nullable(),\n              container_id: z.string(),\n              outputs: z\n                .array(\n                  z.discriminatedUnion('type', [\n                    z.object({ type: z.literal('logs'), logs: z.string() }),\n                    z.object({ type: z.literal('image'), url: z.string() }),\n                  ]),\n                )\n                .nullable(),\n            }),\n            z.object({\n              type: z.literal('image_generation_call'),\n              id: z.string(),\n              result: z.string(),\n            }),\n            z.object({\n              type: z.literal('local_shell_call'),\n              id: z.string(),\n              call_id: z.string(),\n              action: z.object({\n                type: z.literal('exec'),\n                command: z.array(z.string()),\n                timeout_ms: z.number().optional(),\n                user: z.string().optional(),\n                working_directory: z.string().optional(),\n                env: z.record(z.string(), z.string()).optional(),\n              }),\n            }),\n            z.object({\n              type: z.literal('function_call'),\n              call_id: z.string(),\n              name: z.string(),\n              arguments: z.string(),\n              id: z.string(),\n            }),\n            z.object({\n              type: z.literal('computer_call'),\n              id: z.string(),\n              status: z.string().optional(),\n            }),\n            z.object({\n              type: z.literal('reasoning'),\n              id: z.string(),\n              encrypted_content: z.string().nullish(),\n              summary: z.array(\n                z.object({\n                  type: z.literal('summary_text'),\n                  text: z.string(),\n                }),\n              ),\n            }),\n            z.object({\n              type: z.literal('mcp_call'),\n              id: z.string(),\n              status: z.string(),\n              arguments: z.string(),\n              name: z.string(),\n              server_label: z.string(),\n              output: z.string().nullish(),\n              error: z\n                .union([\n                  z.string(),\n                  z\n                    .object({\n                      type: z.string().optional(),\n                      code: z.union([z.number(), z.string()]).optional(),\n                      message: z.string().optional(),\n                    })\n                    .loose(),\n                ])\n                .nullish(),\n              approval_request_id: z.string().nullish(),\n            }),\n            z.object({\n              type: z.literal('mcp_list_tools'),\n              id: z.string(),\n              server_label: z.string(),\n              tools: z.array(\n                z.object({\n                  name: z.string(),\n                  description: z.string().optional(),\n                  input_schema: z.any(),\n                  annotations: z.record(z.string(), z.unknown()).optional(),\n                }),\n              ),\n              error: z\n                .union([\n                  z.string(),\n                  z\n                    .object({\n                      type: z.string().optional(),\n                      code: z.union([z.number(), z.string()]).optional(),\n                      message: z.string().optional(),\n                    })\n                    .loose(),\n                ])\n                .optional(),\n            }),\n            z.object({\n              type: z.literal('mcp_approval_request'),\n              id: z.string(),\n              server_label: z.string(),\n              name: z.string(),\n              arguments: z.string(),\n              approval_request_id: z.string().optional(),\n            }),\n            z.object({\n              type: z.literal('apply_patch_call'),\n              id: z.string(),\n              call_id: z.string(),\n              status: z.enum(['in_progress', 'completed']),\n              operation: z.discriminatedUnion('type', [\n                z.object({\n                  type: z.literal('create_file'),\n                  path: z.string(),\n                  diff: z.string(),\n                }),\n                z.object({\n                  type: z.literal('delete_file'),\n                  path: z.string(),\n                }),\n                z.object({\n                  type: z.literal('update_file'),\n                  path: z.string(),\n                  diff: z.string(),\n                }),\n              ]),\n            }),\n            z.object({\n              type: z.literal('shell_call'),\n              id: z.string(),\n              call_id: z.string(),\n              status: z.enum(['in_progress', 'completed', 'incomplete']),\n              action: z.object({\n                commands: z.array(z.string()),\n              }),\n            }),\n          ]),\n        )\n        .optional(),\n      service_tier: z.string().nullish(),\n      incomplete_details: z.object({ reason: z.string() }).nullish(),\n      usage: z\n        .object({\n          input_tokens: z.number(),\n          input_tokens_details: z\n            .object({ cached_tokens: z.number().nullish() })\n            .nullish(),\n          output_tokens: z.number(),\n          output_tokens_details: z\n            .object({ reasoning_tokens: z.number().nullish() })\n            .nullish(),\n        })\n        .optional(),\n    }),\n  ),\n);\n","import { InferSchema, lazySchema, zodSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n/**\n * `top_logprobs` request body argument can be set to an integer between\n * 0 and 20 specifying the number of most likely tokens to return at each\n * token position, each with an associated log probability.\n *\n * @see https://platform.openai.com/docs/api-reference/responses/create#responses_create-top_logprobs\n */\nexport const TOP_LOGPROBS_MAX = 20;\n\nexport const openaiResponsesReasoningModelIds = [\n  'o1',\n  'o1-2024-12-17',\n  'o3',\n  'o3-2025-04-16',\n  'o3-deep-research',\n  'o3-deep-research-2025-06-26',\n  'o3-mini',\n  'o3-mini-2025-01-31',\n  'o4-mini',\n  'o4-mini-2025-04-16',\n  'o4-mini-deep-research',\n  'o4-mini-deep-research-2025-06-26',\n  'codex-mini-latest',\n  'computer-use-preview',\n  'gpt-5',\n  'gpt-5-2025-08-07',\n  'gpt-5-codex',\n  'gpt-5-mini',\n  'gpt-5-mini-2025-08-07',\n  'gpt-5-nano',\n  'gpt-5-nano-2025-08-07',\n  'gpt-5-pro',\n  'gpt-5-pro-2025-10-06',\n  'gpt-5.1',\n  'gpt-5.1-chat-latest',\n  'gpt-5.1-codex-mini',\n  'gpt-5.1-codex',\n  'gpt-5.1-codex-max',\n  'gpt-5.2',\n  'gpt-5.2-chat-latest',\n  'gpt-5.2-pro',\n] as const;\n\nexport const openaiResponsesModelIds = [\n  'gpt-4.1',\n  'gpt-4.1-2025-04-14',\n  'gpt-4.1-mini',\n  'gpt-4.1-mini-2025-04-14',\n  'gpt-4.1-nano',\n  'gpt-4.1-nano-2025-04-14',\n  'gpt-4o',\n  'gpt-4o-2024-05-13',\n  'gpt-4o-2024-08-06',\n  'gpt-4o-2024-11-20',\n  'gpt-4o-audio-preview',\n  'gpt-4o-audio-preview-2024-10-01',\n  'gpt-4o-audio-preview-2024-12-17',\n  'gpt-4o-search-preview',\n  'gpt-4o-search-preview-2025-03-11',\n  'gpt-4o-mini-search-preview',\n  'gpt-4o-mini-search-preview-2025-03-11',\n  'gpt-4o-mini',\n  'gpt-4o-mini-2024-07-18',\n  'gpt-4-turbo',\n  'gpt-4-turbo-2024-04-09',\n  'gpt-4-turbo-preview',\n  'gpt-4-0125-preview',\n  'gpt-4-1106-preview',\n  'gpt-4',\n  'gpt-4-0613',\n  'gpt-4.5-preview',\n  'gpt-4.5-preview-2025-02-27',\n  'gpt-3.5-turbo-0125',\n  'gpt-3.5-turbo',\n  'gpt-3.5-turbo-1106',\n  'chatgpt-4o-latest',\n  'gpt-5-chat-latest',\n  ...openaiResponsesReasoningModelIds,\n] as const;\n\nexport type OpenAIResponsesModelId =\n  | 'chatgpt-4o-latest'\n  | 'gpt-3.5-turbo-0125'\n  | 'gpt-3.5-turbo-1106'\n  | 'gpt-3.5-turbo'\n  | 'gpt-4-0613'\n  | 'gpt-4-turbo-2024-04-09'\n  | 'gpt-4-turbo'\n  | 'gpt-4.1-2025-04-14'\n  | 'gpt-4.1-mini-2025-04-14'\n  | 'gpt-4.1-mini'\n  | 'gpt-4.1-nano-2025-04-14'\n  | 'gpt-4.1-nano'\n  | 'gpt-4.1'\n  | 'gpt-4'\n  | 'gpt-4o-2024-05-13'\n  | 'gpt-4o-2024-08-06'\n  | 'gpt-4o-2024-11-20'\n  | 'gpt-4o-mini-2024-07-18'\n  | 'gpt-4o-mini'\n  | 'gpt-4o'\n  | 'gpt-5.1'\n  | 'gpt-5.1-chat-latest'\n  | 'gpt-5.1-codex-mini'\n  | 'gpt-5.1-codex'\n  | 'gpt-5.1-codex-max'\n  | 'gpt-5.2'\n  | 'gpt-5.2-chat-latest'\n  | 'gpt-5.2-pro'\n  | 'gpt-5-2025-08-07'\n  | 'gpt-5-chat-latest'\n  | 'gpt-5-codex'\n  | 'gpt-5-mini-2025-08-07'\n  | 'gpt-5-mini'\n  | 'gpt-5-nano-2025-08-07'\n  | 'gpt-5-nano'\n  | 'gpt-5-pro-2025-10-06'\n  | 'gpt-5-pro'\n  | 'gpt-5'\n  | 'o1-2024-12-17'\n  | 'o1'\n  | 'o3-2025-04-16'\n  | 'o3-mini-2025-01-31'\n  | 'o3-mini'\n  | 'o3'\n  | (string & {});\n\n// TODO AI SDK 6: use optional here instead of nullish\nexport const openaiResponsesProviderOptionsSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      /**\n       * The ID of the OpenAI Conversation to continue.\n       * You must create a conversation first via the OpenAI API.\n       * Cannot be used in conjunction with `previousResponseId`.\n       * Defaults to `undefined`.\n       * @see https://platform.openai.com/docs/api-reference/conversations/create\n       */\n      conversation: z.string().nullish(),\n\n      /**\n       * The set of extra fields to include in the response (advanced, usually not needed).\n       * Example values: 'reasoning.encrypted_content', 'file_search_call.results', 'message.output_text.logprobs'.\n       */\n      include: z\n        .array(\n          z.enum([\n            'reasoning.encrypted_content', // handled internally by default, only needed for unknown reasoning models\n            'file_search_call.results',\n            'message.output_text.logprobs',\n          ]),\n        )\n        .nullish(),\n\n      /**\n       * Instructions for the model.\n       * They can be used to change the system or developer message when continuing a conversation using the `previousResponseId` option.\n       * Defaults to `undefined`.\n       */\n      instructions: z.string().nullish(),\n\n      /**\n       * Return the log probabilities of the tokens. Including logprobs will increase\n       * the response size and can slow down response times. However, it can\n       * be useful to better understand how the model is behaving.\n       *\n       * Setting to true will return the log probabilities of the tokens that\n       * were generated.\n       *\n       * Setting to a number will return the log probabilities of the top n\n       * tokens that were generated.\n       *\n       * @see https://platform.openai.com/docs/api-reference/responses/create\n       * @see https://cookbook.openai.com/examples/using_logprobs\n       */\n      logprobs: z\n        .union([z.boolean(), z.number().min(1).max(TOP_LOGPROBS_MAX)])\n        .optional(),\n\n      /**\n       * The maximum number of total calls to built-in tools that can be processed in a response.\n       * This maximum number applies across all built-in tool calls, not per individual tool.\n       * Any further attempts to call a tool by the model will be ignored.\n       */\n      maxToolCalls: z.number().nullish(),\n\n      /**\n       * Additional metadata to store with the generation.\n       */\n      metadata: z.any().nullish(),\n\n      /**\n       * Whether to use parallel tool calls. Defaults to `true`.\n       */\n      parallelToolCalls: z.boolean().nullish(),\n\n      /**\n       * The ID of the previous response. You can use it to continue a conversation.\n       * Defaults to `undefined`.\n       */\n      previousResponseId: z.string().nullish(),\n\n      /**\n       * Sets a cache key to tie this prompt to cached prefixes for better caching performance.\n       */\n      promptCacheKey: z.string().nullish(),\n\n      /**\n       * The retention policy for the prompt cache.\n       * - 'in_memory': Default. Standard prompt caching behavior.\n       * - '24h': Extended prompt caching that keeps cached prefixes active for up to 24 hours.\n       *          Currently only available for 5.1 series models.\n       *\n       * @default 'in_memory'\n       */\n      promptCacheRetention: z.enum(['in_memory', '24h']).nullish(),\n\n      /**\n       * Reasoning effort for reasoning models. Defaults to `medium`. If you use\n       * `providerOptions` to set the `reasoningEffort` option, this model setting will be ignored.\n       * Valid values: 'none' | 'minimal' | 'low' | 'medium' | 'high' | 'xhigh'\n       *\n       * The 'none' type for `reasoningEffort` is only available for OpenAI's GPT-5.1\n       * models. Also, the 'xhigh' type for `reasoningEffort` is only available for\n       * OpenAI's GPT-5.1-Codex-Max model. Setting `reasoningEffort` to 'none' or 'xhigh' with unsupported models will result in\n       * an error.\n       */\n      reasoningEffort: z.string().nullish(),\n\n      /**\n       * Controls reasoning summary output from the model.\n       * Set to \"auto\" to automatically receive the richest level available,\n       * or \"detailed\" for comprehensive summaries.\n       */\n      reasoningSummary: z.string().nullish(),\n\n      /**\n       * The identifier for safety monitoring and tracking.\n       */\n      safetyIdentifier: z.string().nullish(),\n\n      /**\n       * Service tier for the request.\n       * Set to 'flex' for 50% cheaper processing at the cost of increased latency (available for o3, o4-mini, and gpt-5 models).\n       * Set to 'priority' for faster processing with Enterprise access (available for gpt-4, gpt-5, gpt-5-mini, o3, o4-mini; gpt-5-nano is not supported).\n       *\n       * Defaults to 'auto'.\n       */\n      serviceTier: z.enum(['auto', 'flex', 'priority', 'default']).nullish(),\n\n      /**\n       * Whether to store the generation. Defaults to `true`.\n       */\n      store: z.boolean().nullish(),\n\n      /**\n       * Whether to use strict JSON schema validation.\n       * Defaults to `true`.\n       */\n      strictJsonSchema: z.boolean().nullish(),\n\n      /**\n       * Controls the verbosity of the model's responses. Lower values ('low') will result\n       * in more concise responses, while higher values ('high') will result in more verbose responses.\n       * Valid values: 'low', 'medium', 'high'.\n       */\n      textVerbosity: z.enum(['low', 'medium', 'high']).nullish(),\n\n      /**\n       * Controls output truncation. 'auto' (default) performs truncation automatically;\n       * 'disabled' turns truncation off.\n       */\n      truncation: z.enum(['auto', 'disabled']).nullish(),\n\n      /**\n       * A unique identifier representing your end-user, which can help OpenAI to\n       * monitor and detect abuse.\n       * Defaults to `undefined`.\n       * @see https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids\n       */\n      user: z.string().nullish(),\n\n      /**\n       * Override the system message mode for this model.\n       * - 'system': Use the 'system' role for system messages (default for most models)\n       * - 'developer': Use the 'developer' role for system messages (used by reasoning models)\n       * - 'remove': Remove system messages entirely\n       *\n       * If not specified, the mode is automatically determined based on the model.\n       */\n      systemMessageMode: z.enum(['system', 'developer', 'remove']).optional(),\n\n      /**\n       * Force treating this model as a reasoning model.\n       *\n       * This is useful for \"stealth\" reasoning models (e.g. via a custom baseURL)\n       * where the model ID is not recognized by the SDK's allowlist.\n       *\n       * When enabled, the SDK applies reasoning-model parameter compatibility rules\n       * and defaults `systemMessageMode` to `developer` unless overridden.\n       */\n      forceReasoning: z.boolean().optional(),\n    }),\n  ),\n);\n\nexport type OpenAIResponsesProviderOptions = InferSchema<\n  typeof openaiResponsesProviderOptionsSchema\n>;\n","import {\n  LanguageModelV3CallOptions,\n  SharedV3Warning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { validateTypes } from '@ai-sdk/provider-utils';\nimport { codeInterpreterArgsSchema } from '../tool/code-interpreter';\nimport { fileSearchArgsSchema } from '../tool/file-search';\nimport { imageGenerationArgsSchema } from '../tool/image-generation';\nimport { mcpArgsSchema } from '../tool/mcp';\nimport { webSearchArgsSchema } from '../tool/web-search';\nimport { webSearchPreviewArgsSchema } from '../tool/web-search-preview';\nimport { OpenAIResponsesTool } from './openai-responses-api';\n\nexport async function prepareResponsesTools({\n  tools,\n  toolChoice,\n}: {\n  tools: LanguageModelV3CallOptions['tools'];\n  toolChoice: LanguageModelV3CallOptions['toolChoice'] | undefined;\n}): Promise<{\n  tools?: Array<OpenAIResponsesTool>;\n  toolChoice?:\n    | 'auto'\n    | 'none'\n    | 'required'\n    | { type: 'file_search' }\n    | { type: 'web_search_preview' }\n    | { type: 'web_search' }\n    | { type: 'function'; name: string }\n    | { type: 'code_interpreter' }\n    | { type: 'mcp' }\n    | { type: 'image_generation' }\n    | { type: 'apply_patch' };\n  toolWarnings: SharedV3Warning[];\n}> {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  tools = tools?.length ? tools : undefined;\n\n  const toolWarnings: SharedV3Warning[] = [];\n\n  if (tools == null) {\n    return { tools: undefined, toolChoice: undefined, toolWarnings };\n  }\n\n  const openaiTools: Array<OpenAIResponsesTool> = [];\n\n  for (const tool of tools) {\n    switch (tool.type) {\n      case 'function':\n        openaiTools.push({\n          type: 'function',\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.inputSchema,\n          ...(tool.strict != null ? { strict: tool.strict } : {}),\n        });\n        break;\n      case 'provider': {\n        switch (tool.id) {\n          case 'openai.file_search': {\n            const args = await validateTypes({\n              value: tool.args,\n              schema: fileSearchArgsSchema,\n            });\n\n            openaiTools.push({\n              type: 'file_search',\n              vector_store_ids: args.vectorStoreIds,\n              max_num_results: args.maxNumResults,\n              ranking_options: args.ranking\n                ? {\n                    ranker: args.ranking.ranker,\n                    score_threshold: args.ranking.scoreThreshold,\n                  }\n                : undefined,\n              filters: args.filters,\n            });\n\n            break;\n          }\n          case 'openai.local_shell': {\n            openaiTools.push({\n              type: 'local_shell',\n            });\n            break;\n          }\n          case 'openai.shell': {\n            openaiTools.push({\n              type: 'shell',\n            });\n            break;\n          }\n          case 'openai.apply_patch': {\n            openaiTools.push({\n              type: 'apply_patch',\n            });\n            break;\n          }\n          case 'openai.web_search_preview': {\n            const args = await validateTypes({\n              value: tool.args,\n              schema: webSearchPreviewArgsSchema,\n            });\n            openaiTools.push({\n              type: 'web_search_preview',\n              search_context_size: args.searchContextSize,\n              user_location: args.userLocation,\n            });\n            break;\n          }\n          case 'openai.web_search': {\n            const args = await validateTypes({\n              value: tool.args,\n              schema: webSearchArgsSchema,\n            });\n            openaiTools.push({\n              type: 'web_search',\n              filters:\n                args.filters != null\n                  ? { allowed_domains: args.filters.allowedDomains }\n                  : undefined,\n              external_web_access: args.externalWebAccess,\n              search_context_size: args.searchContextSize,\n              user_location: args.userLocation,\n            });\n            break;\n          }\n          case 'openai.code_interpreter': {\n            const args = await validateTypes({\n              value: tool.args,\n              schema: codeInterpreterArgsSchema,\n            });\n\n            openaiTools.push({\n              type: 'code_interpreter',\n              container:\n                args.container == null\n                  ? { type: 'auto', file_ids: undefined }\n                  : typeof args.container === 'string'\n                    ? args.container\n                    : { type: 'auto', file_ids: args.container.fileIds },\n            });\n            break;\n          }\n          case 'openai.image_generation': {\n            const args = await validateTypes({\n              value: tool.args,\n              schema: imageGenerationArgsSchema,\n            });\n\n            openaiTools.push({\n              type: 'image_generation',\n              background: args.background,\n              input_fidelity: args.inputFidelity,\n              input_image_mask: args.inputImageMask\n                ? {\n                    file_id: args.inputImageMask.fileId,\n                    image_url: args.inputImageMask.imageUrl,\n                  }\n                : undefined,\n              model: args.model,\n              moderation: args.moderation,\n              partial_images: args.partialImages,\n              quality: args.quality,\n              output_compression: args.outputCompression,\n              output_format: args.outputFormat,\n              size: args.size,\n            });\n            break;\n          }\n          case 'openai.mcp': {\n            const args = await validateTypes({\n              value: tool.args,\n              schema: mcpArgsSchema,\n            });\n\n            const mapApprovalFilter = (filter: { toolNames?: string[] }) => ({\n              tool_names: filter.toolNames,\n            });\n\n            const requireApproval = args.requireApproval;\n            const requireApprovalParam:\n              | 'always'\n              | 'never'\n              | {\n                  never?: { tool_names?: string[] };\n                }\n              | undefined =\n              requireApproval == null\n                ? undefined\n                : typeof requireApproval === 'string'\n                  ? requireApproval\n                  : requireApproval.never != null\n                    ? { never: mapApprovalFilter(requireApproval.never) }\n                    : undefined;\n\n            openaiTools.push({\n              type: 'mcp',\n              server_label: args.serverLabel,\n              allowed_tools: Array.isArray(args.allowedTools)\n                ? args.allowedTools\n                : args.allowedTools\n                  ? {\n                      read_only: args.allowedTools.readOnly,\n                      tool_names: args.allowedTools.toolNames,\n                    }\n                  : undefined,\n              authorization: args.authorization,\n              connector_id: args.connectorId,\n              headers: args.headers,\n              require_approval: requireApprovalParam ?? 'never',\n              server_description: args.serverDescription,\n              server_url: args.serverUrl,\n            });\n\n            break;\n          }\n        }\n        break;\n      }\n      default:\n        toolWarnings.push({\n          type: 'unsupported',\n          feature: `function tool ${tool}`,\n        });\n        break;\n    }\n  }\n\n  if (toolChoice == null) {\n    return { tools: openaiTools, toolChoice: undefined, toolWarnings };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n    case 'none':\n    case 'required':\n      return { tools: openaiTools, toolChoice: type, toolWarnings };\n    case 'tool':\n      return {\n        tools: openaiTools,\n        toolChoice:\n          toolChoice.toolName === 'code_interpreter' ||\n          toolChoice.toolName === 'file_search' ||\n          toolChoice.toolName === 'image_generation' ||\n          toolChoice.toolName === 'web_search_preview' ||\n          toolChoice.toolName === 'web_search' ||\n          toolChoice.toolName === 'mcp' ||\n          toolChoice.toolName === 'apply_patch'\n            ? { type: toolChoice.toolName }\n            : { type: 'function', name: toolChoice.toolName },\n        toolWarnings,\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new UnsupportedFunctionalityError({\n        functionality: `tool choice type: ${_exhaustiveCheck}`,\n      });\n    }\n  }\n}\n","import {\n  createProviderToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const codeInterpreterInputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      code: z.string().nullish(),\n      containerId: z.string(),\n    }),\n  ),\n);\n\nexport const codeInterpreterOutputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      outputs: z\n        .array(\n          z.discriminatedUnion('type', [\n            z.object({ type: z.literal('logs'), logs: z.string() }),\n            z.object({ type: z.literal('image'), url: z.string() }),\n          ]),\n        )\n        .nullish(),\n    }),\n  ),\n);\n\nexport const codeInterpreterArgsSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      container: z\n        .union([\n          z.string(),\n          z.object({\n            fileIds: z.array(z.string()).optional(),\n          }),\n        ])\n        .optional(),\n    }),\n  ),\n);\n\ntype CodeInterpreterArgs = {\n  /**\n   * The code interpreter container.\n   * Can be a container ID\n   * or an object that specifies uploaded file IDs to make available to your code.\n   */\n  container?: string | { fileIds?: string[] };\n};\n\nexport const codeInterpreterToolFactory =\n  createProviderToolFactoryWithOutputSchema<\n    {\n      /**\n       * The code to run, or null if not available.\n       */\n      code?: string | null;\n\n      /**\n       * The ID of the container used to run the code.\n       */\n      containerId: string;\n    },\n    {\n      /**\n       * The outputs generated by the code interpreter, such as logs or images.\n       * Can be null if no outputs are available.\n       */\n      outputs?: Array<\n        | {\n            type: 'logs';\n\n            /**\n             * The logs output from the code interpreter.\n             */\n            logs: string;\n          }\n        | {\n            type: 'image';\n\n            /**\n             * The URL of the image output from the code interpreter.\n             */\n            url: string;\n          }\n      > | null;\n    },\n    CodeInterpreterArgs\n  >({\n    id: 'openai.code_interpreter',\n    inputSchema: codeInterpreterInputSchema,\n    outputSchema: codeInterpreterOutputSchema,\n  });\n\nexport const codeInterpreter = (\n  args: CodeInterpreterArgs = {}, // default\n) => {\n  return codeInterpreterToolFactory(args);\n};\n","import {\n  createProviderToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport {\n  OpenAIResponsesFileSearchToolComparisonFilter,\n  OpenAIResponsesFileSearchToolCompoundFilter,\n} from '../responses/openai-responses-api';\n\nconst comparisonFilterSchema = z.object({\n  key: z.string(),\n  type: z.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte', 'in', 'nin']),\n  value: z.union([z.string(), z.number(), z.boolean(), z.array(z.string())]),\n});\n\nconst compoundFilterSchema: z.ZodType<any> = z.object({\n  type: z.enum(['and', 'or']),\n  filters: z.array(\n    z.union([comparisonFilterSchema, z.lazy(() => compoundFilterSchema)]),\n  ),\n});\n\nexport const fileSearchArgsSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      vectorStoreIds: z.array(z.string()),\n      maxNumResults: z.number().optional(),\n      ranking: z\n        .object({\n          ranker: z.string().optional(),\n          scoreThreshold: z.number().optional(),\n        })\n        .optional(),\n      filters: z\n        .union([comparisonFilterSchema, compoundFilterSchema])\n        .optional(),\n    }),\n  ),\n);\n\nexport const fileSearchOutputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      queries: z.array(z.string()),\n      results: z\n        .array(\n          z.object({\n            attributes: z.record(z.string(), z.unknown()),\n            fileId: z.string(),\n            filename: z.string(),\n            score: z.number(),\n            text: z.string(),\n          }),\n        )\n        .nullable(),\n    }),\n  ),\n);\n\nexport const fileSearch = createProviderToolFactoryWithOutputSchema<\n  {},\n  {\n    /**\n     * The search query to execute.\n     */\n    queries: string[];\n\n    /**\n     * The results of the file search tool call.\n     */\n    results:\n      | null\n      | {\n          /**\n           * Set of 16 key-value pairs that can be attached to an object.\n           * This can be useful for storing additional information about the object\n           * in a structured format, and querying for objects via API or the dashboard.\n           * Keys are strings with a maximum length of 64 characters.\n           * Values are strings with a maximum length of 512 characters, booleans, or numbers.\n           */\n          attributes: Record<string, unknown>;\n\n          /**\n           * The unique ID of the file.\n           */\n          fileId: string;\n\n          /**\n           * The name of the file.\n           */\n          filename: string;\n\n          /**\n           * The relevance score of the file - a value between 0 and 1.\n           */\n          score: number;\n\n          /**\n           * The text that was retrieved from the file.\n           */\n          text: string;\n        }[];\n  },\n  {\n    /**\n     * List of vector store IDs to search through.\n     */\n    vectorStoreIds: string[];\n\n    /**\n     * Maximum number of search results to return. Defaults to 10.\n     */\n    maxNumResults?: number;\n\n    /**\n     * Ranking options for the search.\n     */\n    ranking?: {\n      /**\n       * The ranker to use for the file search.\n       */\n      ranker?: string;\n\n      /**\n       * The score threshold for the file search, a number between 0 and 1.\n       * Numbers closer to 1 will attempt to return only the most relevant results,\n       * but may return fewer results.\n       */\n      scoreThreshold?: number;\n    };\n\n    /**\n     * A filter to apply.\n     */\n    filters?:\n      | OpenAIResponsesFileSearchToolComparisonFilter\n      | OpenAIResponsesFileSearchToolCompoundFilter;\n  }\n>({\n  id: 'openai.file_search',\n  inputSchema: z.object({}),\n  outputSchema: fileSearchOutputSchema,\n});\n","import {\n  createProviderToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const imageGenerationArgsSchema = lazySchema(() =>\n  zodSchema(\n    z\n      .object({\n        background: z.enum(['auto', 'opaque', 'transparent']).optional(),\n        inputFidelity: z.enum(['low', 'high']).optional(),\n        inputImageMask: z\n          .object({\n            fileId: z.string().optional(),\n            imageUrl: z.string().optional(),\n          })\n          .optional(),\n        model: z.string().optional(),\n        moderation: z.enum(['auto']).optional(),\n        outputCompression: z.number().int().min(0).max(100).optional(),\n        outputFormat: z.enum(['png', 'jpeg', 'webp']).optional(),\n        partialImages: z.number().int().min(0).max(3).optional(),\n        quality: z.enum(['auto', 'low', 'medium', 'high']).optional(),\n        size: z\n          .enum(['1024x1024', '1024x1536', '1536x1024', 'auto'])\n          .optional(),\n      })\n      .strict(),\n  ),\n);\n\nconst imageGenerationInputSchema = lazySchema(() => zodSchema(z.object({})));\n\nexport const imageGenerationOutputSchema = lazySchema(() =>\n  zodSchema(z.object({ result: z.string() })),\n);\n\ntype ImageGenerationArgs = {\n  /**\n   * Background type for the generated image. Default is 'auto'.\n   */\n  background?: 'auto' | 'opaque' | 'transparent';\n\n  /**\n   * Input fidelity for the generated image. Default is 'low'.\n   */\n  inputFidelity?: 'low' | 'high';\n\n  /**\n   * Optional mask for inpainting.\n   * Contains image_url (string, optional) and file_id (string, optional).\n   */\n  inputImageMask?: {\n    /**\n     * File ID for the mask image.\n     */\n    fileId?: string;\n\n    /**\n     * Base64-encoded mask image.\n     */\n    imageUrl?: string;\n  };\n\n  /**\n   * The image generation model to use. Default: gpt-image-1.\n   */\n  model?: string;\n\n  /**\n   * Moderation level for the generated image. Default: auto.\n   */\n  moderation?: 'auto';\n\n  /**\n   * Compression level for the output image. Default: 100.\n   */\n  outputCompression?: number;\n\n  /**\n   * The output format of the generated image. One of png, webp, or jpeg.\n   * Default: png\n   */\n  outputFormat?: 'png' | 'jpeg' | 'webp';\n\n  /**\n   * Number of partial images to generate in streaming mode, from 0 (default value) to 3.\n   */\n  partialImages?: number;\n\n  /**\n   * The quality of the generated image.\n   * One of low, medium, high, or auto. Default: auto.\n   */\n  quality?: 'auto' | 'low' | 'medium' | 'high';\n\n  /**\n   * The size of the generated image.\n   * One of 1024x1024, 1024x1536, 1536x1024, or auto.\n   * Default: auto.\n   */\n  size?: 'auto' | '1024x1024' | '1024x1536' | '1536x1024';\n};\n\nconst imageGenerationToolFactory = createProviderToolFactoryWithOutputSchema<\n  {},\n  {\n    /**\n     * The generated image encoded in base64.\n     */\n    result: string;\n  },\n  ImageGenerationArgs\n>({\n  id: 'openai.image_generation',\n  inputSchema: imageGenerationInputSchema,\n  outputSchema: imageGenerationOutputSchema,\n});\n\nexport const imageGeneration = (\n  args: ImageGenerationArgs = {}, // default\n) => {\n  return imageGenerationToolFactory(args);\n};\n","import {\n  createProviderToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { JSONValue } from '@ai-sdk/provider';\nimport { z } from 'zod/v4';\n\nconst jsonValueSchema: z.ZodType<JSONValue> = z.lazy(() =>\n  z.union([\n    z.string(),\n    z.number(),\n    z.boolean(),\n    z.null(),\n    z.array(jsonValueSchema),\n    z.record(z.string(), jsonValueSchema),\n  ]),\n);\n\nexport const mcpArgsSchema = lazySchema(() =>\n  zodSchema(\n    z\n      .object({\n        serverLabel: z.string(),\n        allowedTools: z\n          .union([\n            z.array(z.string()),\n            z.object({\n              readOnly: z.boolean().optional(),\n              toolNames: z.array(z.string()).optional(),\n            }),\n          ])\n          .optional(),\n        authorization: z.string().optional(),\n        connectorId: z.string().optional(),\n        headers: z.record(z.string(), z.string()).optional(),\n\n        requireApproval: z\n          .union([\n            z.enum(['always', 'never']),\n            z.object({\n              never: z\n                .object({\n                  toolNames: z.array(z.string()).optional(),\n                })\n                .optional(),\n            }),\n          ])\n          .optional(),\n        serverDescription: z.string().optional(),\n        serverUrl: z.string().optional(),\n      })\n      .refine(\n        v => v.serverUrl != null || v.connectorId != null,\n        'One of serverUrl or connectorId must be provided.',\n      ),\n  ),\n);\n\nconst mcpInputSchema = lazySchema(() => zodSchema(z.object({})));\n\nexport const mcpOutputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      type: z.literal('call'),\n      serverLabel: z.string(),\n      name: z.string(),\n      arguments: z.string(),\n      output: z.string().nullish(),\n      error: z.union([z.string(), jsonValueSchema]).optional(),\n    }),\n  ),\n);\n\ntype McpArgs = {\n  /** A label for this MCP server, used to identify it in tool calls. */\n  serverLabel: string;\n  /** List of allowed tool names or a filter object. */\n  allowedTools?:\n    | string[]\n    | {\n        readOnly?: boolean;\n        toolNames?: string[];\n      };\n  /** OAuth access token usable with the remote MCP server or connector. */\n  authorization?: string;\n  /** Identifier for a service connector. */\n  connectorId?: string;\n  /** Optional HTTP headers to send to the MCP server. */\n  headers?: Record<string, string>;\n  /**\n   * Which tools require approval before execution.\n   */\n  requireApproval?:\n    | 'always'\n    | 'never'\n    | {\n        never?: {\n          toolNames?: string[];\n        };\n      };\n  /** Optional description of the MCP server. */\n  serverDescription?: string;\n  /** URL for the MCP server. One of serverUrl or connectorId must be provided. */\n  serverUrl?: string;\n};\n\nexport const mcpToolFactory = createProviderToolFactoryWithOutputSchema<\n  {},\n  {\n    type: 'call';\n    serverLabel: string;\n    name: string;\n    arguments: string;\n    output?: string | null;\n    error?: JSONValue;\n  },\n  McpArgs\n>({\n  id: 'openai.mcp',\n  inputSchema: mcpInputSchema,\n  outputSchema: mcpOutputSchema,\n});\n\nexport const mcp = (args: McpArgs) => mcpToolFactory(args);\n","import {\n  createProviderToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const webSearchArgsSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      externalWebAccess: z.boolean().optional(),\n      filters: z\n        .object({ allowedDomains: z.array(z.string()).optional() })\n        .optional(),\n      searchContextSize: z.enum(['low', 'medium', 'high']).optional(),\n      userLocation: z\n        .object({\n          type: z.literal('approximate'),\n          country: z.string().optional(),\n          city: z.string().optional(),\n          region: z.string().optional(),\n          timezone: z.string().optional(),\n        })\n        .optional(),\n    }),\n  ),\n);\n\nconst webSearchInputSchema = lazySchema(() => zodSchema(z.object({})));\n\nexport const webSearchOutputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      action: z.discriminatedUnion('type', [\n        z.object({\n          type: z.literal('search'),\n          query: z.string().optional(),\n        }),\n        z.object({\n          type: z.literal('openPage'),\n          url: z.string().nullish(),\n        }),\n        z.object({\n          type: z.literal('findInPage'),\n          url: z.string().nullish(),\n          pattern: z.string().nullish(),\n        }),\n      ]),\n      sources: z\n        .array(\n          z.discriminatedUnion('type', [\n            z.object({ type: z.literal('url'), url: z.string() }),\n            z.object({ type: z.literal('api'), name: z.string() }),\n          ]),\n        )\n        .optional(),\n    }),\n  ),\n);\n\nexport const webSearchToolFactory = createProviderToolFactoryWithOutputSchema<\n  {\n    // Web search doesn't take input parameters - it's controlled by the prompt\n  },\n  {\n    /**\n     * An object describing the specific action taken in this web search call.\n     * Includes details on how the model used the web (search, open_page, find_in_page).\n     */\n    action:\n      | {\n          /**\n           * Action type \"search\" - Performs a web search query.\n           */\n          type: 'search';\n\n          /**\n           * The search query.\n           */\n          query?: string;\n        }\n      | {\n          /**\n           * Action type \"openPage\" - Opens a specific URL from search results.\n           */\n          type: 'openPage';\n\n          /**\n           * The URL opened by the model.\n           */\n          url?: string | null;\n        }\n      | {\n          /**\n           * Action type \"findInPage\": Searches for a pattern within a loaded page.\n           */\n          type: 'findInPage';\n\n          /**\n           * The URL of the page searched for the pattern.\n           */\n          url?: string | null;\n\n          /**\n           * The pattern or text to search for within the page.\n           */\n          pattern?: string | null;\n        };\n\n    /**\n     * Optional sources cited by the model for the web search call.\n     */\n    sources?: Array<\n      { type: 'url'; url: string } | { type: 'api'; name: string }\n    >;\n  },\n  {\n    /**\n     * Whether to use external web access for fetching live content.\n     * - true: Fetch live web content (default)\n     * - false: Use cached/indexed results\n     */\n    externalWebAccess?: boolean;\n\n    /**\n     * Filters for the search.\n     */\n    filters?: {\n      /**\n       * Allowed domains for the search.\n       * If not provided, all domains are allowed.\n       * Subdomains of the provided domains are allowed as well.\n       */\n      allowedDomains?: string[];\n    };\n\n    /**\n     * Search context size to use for the web search.\n     * - high: Most comprehensive context, highest cost, slower response\n     * - medium: Balanced context, cost, and latency (default)\n     * - low: Least context, lowest cost, fastest response\n     */\n    searchContextSize?: 'low' | 'medium' | 'high';\n\n    /**\n     * User location information to provide geographically relevant search results.\n     */\n    userLocation?: {\n      /**\n       * Type of location (always 'approximate')\n       */\n      type: 'approximate';\n      /**\n       * Two-letter ISO country code (e.g., 'US', 'GB')\n       */\n      country?: string;\n      /**\n       * City name (free text, e.g., 'Minneapolis')\n       */\n      city?: string;\n      /**\n       * Region name (free text, e.g., 'Minnesota')\n       */\n      region?: string;\n      /**\n       * IANA timezone (e.g., 'America/Chicago')\n       */\n      timezone?: string;\n    };\n  }\n>({\n  id: 'openai.web_search',\n  inputSchema: webSearchInputSchema,\n  outputSchema: webSearchOutputSchema,\n});\n\nexport const webSearch = (\n  args: Parameters<typeof webSearchToolFactory>[0] = {}, // default\n) => webSearchToolFactory(args);\n","import {\n  createProviderToolFactoryWithOutputSchema,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const webSearchPreviewArgsSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      searchContextSize: z.enum(['low', 'medium', 'high']).optional(),\n      userLocation: z\n        .object({\n          type: z.literal('approximate'),\n          country: z.string().optional(),\n          city: z.string().optional(),\n          region: z.string().optional(),\n          timezone: z.string().optional(),\n        })\n        .optional(),\n    }),\n  ),\n);\n\nexport const webSearchPreviewInputSchema = lazySchema(() =>\n  zodSchema(z.object({})),\n);\n\nconst webSearchPreviewOutputSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      action: z.discriminatedUnion('type', [\n        z.object({\n          type: z.literal('search'),\n          query: z.string().optional(),\n        }),\n        z.object({\n          type: z.literal('openPage'),\n          url: z.string().nullish(),\n        }),\n        z.object({\n          type: z.literal('findInPage'),\n          url: z.string().nullish(),\n          pattern: z.string().nullish(),\n        }),\n      ]),\n    }),\n  ),\n);\n\nexport const webSearchPreview = createProviderToolFactoryWithOutputSchema<\n  {\n    // Web search preview doesn't take input parameters - it's controlled by the prompt\n  },\n  {\n    /**\n     * An object describing the specific action taken in this web search call.\n     * Includes details on how the model used the web (search, open_page, find_in_page).\n     */\n    action:\n      | {\n          /**\n           * Action type \"search\" - Performs a web search query.\n           */\n          type: 'search';\n\n          /**\n           * The search query.\n           */\n          query?: string;\n        }\n      | {\n          /**\n           * Action type \"openPage\" - Opens a specific URL from search results.\n           */\n          type: 'openPage';\n\n          /**\n           * The URL opened by the model.\n           */\n          url?: string | null;\n        }\n      | {\n          /**\n           * Action type \"findInPage\": Searches for a pattern within a loaded page.\n           */\n          type: 'findInPage';\n\n          /**\n           * The URL of the page searched for the pattern.\n           */\n          url?: string | null;\n\n          /**\n           * The pattern or text to search for within the page.\n           */\n          pattern?: string | null;\n        };\n  },\n  {\n    /**\n     * Search context size to use for the web search.\n     * - high: Most comprehensive context, highest cost, slower response\n     * - medium: Balanced context, cost, and latency (default)\n     * - low: Least context, lowest cost, fastest response\n     */\n    searchContextSize?: 'low' | 'medium' | 'high';\n\n    /**\n     * User location information to provide geographically relevant search results.\n     */\n    userLocation?: {\n      /**\n       * Type of location (always 'approximate')\n       */\n      type: 'approximate';\n      /**\n       * Two-letter ISO country code (e.g., 'US', 'GB')\n       */\n      country?: string;\n      /**\n       * City name (free text, e.g., 'Minneapolis')\n       */\n      city?: string;\n      /**\n       * Region name (free text, e.g., 'Minnesota')\n       */\n      region?: string;\n      /**\n       * IANA timezone (e.g., 'America/Chicago')\n       */\n      timezone?: string;\n    };\n  }\n>({\n  id: 'openai.web_search_preview',\n  inputSchema: webSearchPreviewInputSchema,\n  outputSchema: webSearchPreviewOutputSchema,\n});\n","import {\n  OpenAIChatLanguageModel,\n  OpenAICompletionLanguageModel,\n  OpenAIEmbeddingModel,\n  OpenAIImageModel,\n  OpenAIResponsesLanguageModel,\n  OpenAISpeechModel,\n  OpenAITranscriptionModel,\n} from '@ai-sdk/openai/internal';\nimport {\n  EmbeddingModelV3,\n  LanguageModelV3,\n  ProviderV3,\n  ImageModelV3,\n  SpeechModelV3,\n  TranscriptionModelV3,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  loadApiKey,\n  loadSetting,\n  withUserAgentSuffix,\n} from '@ai-sdk/provider-utils';\nimport { azureOpenaiTools } from './azure-openai-tools';\nimport { VERSION } from './version';\n\nexport interface AzureOpenAIProvider extends ProviderV3 {\n  (deploymentId: string): LanguageModelV3;\n\n  /**\n  Creates an Azure OpenAI responses API model for text generation.\n   */\n  languageModel(deploymentId: string): LanguageModelV3;\n\n  /**\nCreates an Azure OpenAI chat model for text generation.\n   */\n  chat(deploymentId: string): LanguageModelV3;\n\n  /**\nCreates an Azure OpenAI responses API model for text generation.\n   */\n  responses(deploymentId: string): LanguageModelV3;\n\n  /**\nCreates an Azure OpenAI completion model for text generation.\n   */\n  completion(deploymentId: string): LanguageModelV3;\n\n  /**\n   * Creates an Azure OpenAI model for text embeddings.\n   */\n  embedding(deploymentId: string): EmbeddingModelV3;\n\n  /**\n   * Creates an Azure OpenAI model for text embeddings.\n   */\n  embeddingModel(deploymentId: string): EmbeddingModelV3;\n\n  /**\n   * @deprecated Use `embedding` instead.\n   */\n  textEmbedding(deploymentId: string): EmbeddingModelV3;\n\n  /**\n   * @deprecated Use `embeddingModel` instead.\n   */\n  textEmbeddingModel(deploymentId: string): EmbeddingModelV3;\n\n  /**\n   * Creates an Azure OpenAI DALL-E model for image generation.\n   */\n  image(deploymentId: string): ImageModelV3;\n\n  /**\n   * Creates an Azure OpenAI DALL-E model for image generation.\n   */\n  imageModel(deploymentId: string): ImageModelV3;\n\n  /**\n   * Creates an Azure OpenAI model for audio transcription.\n   */\n  transcription(deploymentId: string): TranscriptionModelV3;\n\n  /**\n   * Creates an Azure OpenAI model for speech generation.\n   */\n  speech(deploymentId: string): SpeechModelV3;\n\n  /**\n   * AzureOpenAI-specific tools.\n   */\n  tools: typeof azureOpenaiTools;\n}\n\nexport interface AzureOpenAIProviderSettings {\n  /**\nName of the Azure OpenAI resource. Either this or `baseURL` can be used.\n\nThe resource name is used in the assembled URL: `https://{resourceName}.openai.azure.com/openai/v1{path}`.\n     */\n  resourceName?: string;\n\n  /**\nUse a different URL prefix for API calls, e.g. to use proxy servers. Either this or `resourceName` can be used.\nWhen a baseURL is provided, the resourceName is ignored.\n\nWith a baseURL, the resolved URL is `{baseURL}/v1{path}`.\n   */\n  baseURL?: string;\n\n  /**\nAPI key for authenticating requests.\n     */\n  apiKey?: string;\n\n  /**\nCustom headers to include in the requests.\n     */\n  headers?: Record<string, string>;\n\n  /**\nCustom fetch implementation. You can use it as a middleware to intercept requests,\nor to provide a custom fetch implementation for e.g. testing.\n    */\n  fetch?: FetchFunction;\n\n  /**\nCustom api version to use. Defaults to `preview`.\n    */\n  apiVersion?: string;\n\n  /**\nUse deployment-based URLs for specific model types. Set to true to use legacy deployment format:\n`{baseURL}/deployments/{deploymentId}{path}?api-version={apiVersion}` instead of\n`{baseURL}/v1{path}?api-version={apiVersion}`.\n   */\n  useDeploymentBasedUrls?: boolean;\n}\n\n/**\nCreate an Azure OpenAI provider instance.\n */\nexport function createAzure(\n  options: AzureOpenAIProviderSettings = {},\n): AzureOpenAIProvider {\n  const getHeaders = () => {\n    const baseHeaders = {\n      'api-key': loadApiKey({\n        apiKey: options.apiKey,\n        environmentVariableName: 'AZURE_API_KEY',\n        description: 'Azure OpenAI',\n      }),\n      ...options.headers,\n    };\n    return withUserAgentSuffix(baseHeaders, `ai-sdk/azure/${VERSION}`);\n  };\n\n  const getResourceName = () =>\n    loadSetting({\n      settingValue: options.resourceName,\n      settingName: 'resourceName',\n      environmentVariableName: 'AZURE_RESOURCE_NAME',\n      description: 'Azure OpenAI resource name',\n    });\n\n  const apiVersion = options.apiVersion ?? 'v1';\n\n  const url = ({ path, modelId }: { path: string; modelId: string }) => {\n    const baseUrlPrefix =\n      options.baseURL ?? `https://${getResourceName()}.openai.azure.com/openai`;\n\n    let fullUrl: URL;\n    if (options.useDeploymentBasedUrls) {\n      // Use deployment-based format for compatibility with certain Azure OpenAI models\n      fullUrl = new URL(`${baseUrlPrefix}/deployments/${modelId}${path}`);\n    } else {\n      // Use v1 API format - no deployment ID in URL\n      fullUrl = new URL(`${baseUrlPrefix}/v1${path}`);\n    }\n\n    fullUrl.searchParams.set('api-version', apiVersion);\n    return fullUrl.toString();\n  };\n\n  const createChatModel = (deploymentName: string) =>\n    new OpenAIChatLanguageModel(deploymentName, {\n      provider: 'azure.chat',\n      url,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createCompletionModel = (modelId: string) =>\n    new OpenAICompletionLanguageModel(modelId, {\n      provider: 'azure.completion',\n      url,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createEmbeddingModel = (modelId: string) =>\n    new OpenAIEmbeddingModel(modelId, {\n      provider: 'azure.embeddings',\n      headers: getHeaders,\n      url,\n      fetch: options.fetch,\n    });\n\n  const createResponsesModel = (modelId: string) =>\n    new OpenAIResponsesLanguageModel(modelId, {\n      provider: 'azure.responses',\n      url,\n      headers: getHeaders,\n      fetch: options.fetch,\n      fileIdPrefixes: ['assistant-'],\n    });\n\n  const createImageModel = (modelId: string) =>\n    new OpenAIImageModel(modelId, {\n      provider: 'azure.image',\n      url,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createTranscriptionModel = (modelId: string) =>\n    new OpenAITranscriptionModel(modelId, {\n      provider: 'azure.transcription',\n      url,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createSpeechModel = (modelId: string) =>\n    new OpenAISpeechModel(modelId, {\n      provider: 'azure.speech',\n      url,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const provider = function (deploymentId: string) {\n    if (new.target) {\n      throw new Error(\n        'The Azure OpenAI model function cannot be called with the new keyword.',\n      );\n    }\n\n    return createResponsesModel(deploymentId);\n  };\n\n  provider.specificationVersion = 'v3' as const;\n  provider.languageModel = createResponsesModel;\n  provider.chat = createChatModel;\n  provider.completion = createCompletionModel;\n  provider.embedding = createEmbeddingModel;\n  provider.embeddingModel = createEmbeddingModel;\n  provider.textEmbedding = createEmbeddingModel;\n  provider.textEmbeddingModel = createEmbeddingModel;\n  provider.image = createImageModel;\n  provider.imageModel = createImageModel;\n  provider.responses = createResponsesModel;\n  provider.transcription = createTranscriptionModel;\n  provider.speech = createSpeechModel;\n  provider.tools = azureOpenaiTools;\n  return provider;\n}\n\n/**\nDefault Azure OpenAI provider instance.\n */\nexport const azure = createAzure();\n","import {\n  codeInterpreter,\n  fileSearch,\n  imageGeneration,\n  webSearchPreview,\n} from '@ai-sdk/openai/internal';\n\nexport const azureOpenaiTools: {\n  codeInterpreter: typeof codeInterpreter;\n  fileSearch: typeof fileSearch;\n  imageGeneration: typeof imageGeneration;\n  webSearchPreview: typeof webSearchPreview;\n} = {\n  codeInterpreter,\n  fileSearch,\n  imageGeneration,\n  webSearchPreview,\n};\n","// Version string of this package injected at build time.\ndeclare const __PACKAGE_VERSION__: string | undefined;\nexport const VERSION: string =\n  typeof __PACKAGE_VERSION__ !== 'undefined'\n    ? __PACKAGE_VERSION__\n    : '0.0.0-test';\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACAA,SAAS,SAAS;AMElB,SAAS,KAAAA,UAAS;ACDlB,SAAS,KAAAC,UAAS;AODlB,SAAS,KAAAC,UAAS;ACClB,SAAS,KAAAC,UAAS;AEAlB,SAAS,KAAAC,UAAS;ACAlB,SAAS,KAAAC,UAAS;AEAlB,SAAS,KAAAC,UAAS;AGAlB,SAAS,KAAAC,UAAS;ACAlB,SAAS,KAAAC,WAAS;AEAlB,SAAS,KAAAC,WAAS;AGYlB,SAAS,KAAAC,WAAS;ACRlB,SAAS,KAAAC,WAAS;ACAlB,SAAS,KAAAC,WAAS;ACAlB,SAAS,KAAAC,WAAS;AEHlB,SAAS,KAAAC,WAAS;ACDlB,SAAS,KAAAC,WAAS;AEIlB,SAAS,KAAAC,WAAS;ACAlB,SAAS,KAAAC,WAAS;ACAlB,SAAS,KAAAC,WAAS;ACClB,SAAS,KAAAC,WAAS;ACDlB,SAAS,KAAAC,WAAS;ACAlB,SAAS,KAAAC,WAAS;A1CFX,IAAM,wBAAwB,EAAE,OAAO;EAC5C,OAAO,EAAE,OAAO;IACd,SAAS,EAAE,OAAO;;;;IAKlB,MAAM,EAAE,OAAO,EAAE,QAAQ;IACzB,OAAO,EAAE,IAAI,EAAE,QAAQ;IACvB,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,GAAG,EAAE,OAAO,CAAC,CAAC,EAAE,QAAQ;EAClD,CAAC;AACH,CAAC;AAIM,IAAM,8BAA8B,+BAA+B;EACxE,aAAa;EACb,gBAAgB,CAAA,SAAQ,KAAK,MAAM;AACrC,CAAC;ACTM,SAAS,mCACd,SACiC;AACjC,QAAM,yBACJ,QAAQ,WAAW,IAAI,KACvB,QAAQ,WAAW,SAAS,KAC3B,QAAQ,WAAW,OAAO,KAAK,CAAC,QAAQ,WAAW,YAAY;AAElE,QAAM,6BACJ,QAAQ,WAAW,OAAO,KAC1B,QAAQ,WAAW,YAAY,KAC9B,QAAQ,WAAW,OAAO,KACzB,CAAC,QAAQ,WAAW,YAAY,KAChC,CAAC,QAAQ,WAAW,YAAY,KAClC,QAAQ,WAAW,IAAI,KACvB,QAAQ,WAAW,SAAS;AAI9B,QAAM,mBACJ,QAAQ,WAAW,IAAI,KACvB,QAAQ,WAAW,IAAI,KACvB,QAAQ,WAAW,SAAS,KAC5B,QAAQ,WAAW,YAAY,KAC/B,QAAQ,WAAW,sBAAsB,KACxC,QAAQ,WAAW,OAAO,KAAK,CAAC,QAAQ,WAAW,YAAY;AAIlE,QAAM,iCACJ,QAAQ,WAAW,SAAS,KAAK,QAAQ,WAAW,SAAS;AAE/D,QAAM,oBAAoB,mBAAmB,cAAc;AAE3D,SAAO;IACL;IACA;IACA;IACA;IACA;EACF;AACF;ACrCO,SAAS,uBACd,OACsB;AAlBxB,MAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AAmBE,MAAI,SAAS,MAAM;AACjB,WAAO;MACL,aAAa;QACX,OAAO;QACP,SAAS;QACT,WAAW;QACX,YAAY;MACd;MACA,cAAc;QACZ,OAAO;QACP,MAAM;QACN,WAAW;MACb;MACA,KAAK;IACP;EACF;AAEA,QAAM,gBAAe,KAAA,MAAM,kBAAN,OAAA,KAAuB;AAC5C,QAAM,oBAAmB,KAAA,MAAM,sBAAN,OAAA,KAA2B;AACpD,QAAM,gBAAe,MAAA,KAAA,MAAM,0BAAN,OAAA,SAAA,GAA6B,kBAA7B,OAAA,KAA8C;AACnE,QAAM,mBACJ,MAAA,KAAA,MAAM,8BAAN,OAAA,SAAA,GAAiC,qBAAjC,OAAA,KAAqD;AAEvD,SAAO;IACL,aAAa;MACX,OAAO;MACP,SAAS,eAAe;MACxB,WAAW;MACX,YAAY;IACd;IACA,cAAc;MACZ,OAAO;MACP,MAAM,mBAAmB;MACzB,WAAW;IACb;IACA,KAAK;EACP;AACF;AChDO,SAAS,4BAA4B;EAC1C;EACA,oBAAoB;AACtB,GAME;AAjBF,MAAA;AAkBE,QAAM,WAA6B,CAAC;AACpC,QAAM,WAAmC,CAAC;AAE1C,aAAW,EAAE,MAAM,QAAQ,KAAK,QAAQ;AACtC,YAAQ,MAAM;MACZ,KAAK,UAAU;AACb,gBAAQ,mBAAmB;UACzB,KAAK,UAAU;AACb,qBAAS,KAAK,EAAE,MAAM,UAAU,QAAQ,CAAC;AACzC;UACF;UACA,KAAK,aAAa;AAChB,qBAAS,KAAK,EAAE,MAAM,aAAa,QAAQ,CAAC;AAC5C;UACF;UACA,KAAK,UAAU;AACb,qBAAS,KAAK;cACZ,MAAM;cACN,SAAS;YACX,CAAC;AACD;UACF;UACA,SAAS;AACP,kBAAM,mBAA0B;AAChC,kBAAM,IAAI;cACR,oCAAoC,gBAAgB;YACtD;UACF;QACF;AACA;MACF;MAEA,KAAK,QAAQ;AACX,YAAI,QAAQ,WAAW,KAAK,QAAQ,CAAC,EAAE,SAAS,QAAQ;AACtD,mBAAS,KAAK,EAAE,MAAM,QAAQ,SAAS,QAAQ,CAAC,EAAE,KAAK,CAAC;AACxD;QACF;AAEA,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS,QAAQ,IAAI,CAAC,MAAM,UAAU;AA1DhD,gBAAAC,KAAA,IAAA;AA2DY,oBAAQ,KAAK,MAAM;cACjB,KAAK,QAAQ;AACX,uBAAO,EAAE,MAAM,QAAQ,MAAM,KAAK,KAAK;cACzC;cACA,KAAK,QAAQ;AACX,oBAAI,KAAK,UAAU,WAAW,QAAQ,GAAG;AACvC,wBAAM,YACJ,KAAK,cAAc,YACf,eACA,KAAK;AAEX,yBAAO;oBACL,MAAM;oBACN,WAAW;sBACT,KACE,KAAK,gBAAgB,MACjB,KAAK,KAAK,SAAS,IACnB,QAAQ,SAAS,WAAW,gBAAgB,KAAK,IAAI,CAAC;;sBAG5D,SAAQ,MAAAA,MAAA,KAAK,oBAAL,OAAA,SAAAA,IAAsB,WAAtB,OAAA,SAAA,GAA8B;oBACxC;kBACF;gBACF,WAAW,KAAK,UAAU,WAAW,QAAQ,GAAG;AAC9C,sBAAI,KAAK,gBAAgB,KAAK;AAC5B,0BAAM,IAAI,8BAA8B;sBACtC,eAAe;oBACjB,CAAC;kBACH;AAEA,0BAAQ,KAAK,WAAW;oBACtB,KAAK,aAAa;AAChB,6BAAO;wBACL,MAAM;wBACN,aAAa;0BACX,MAAM,gBAAgB,KAAK,IAAI;0BAC/B,QAAQ;wBACV;sBACF;oBACF;oBACA,KAAK;oBACL,KAAK,cAAc;AACjB,6BAAO;wBACL,MAAM;wBACN,aAAa;0BACX,MAAM,gBAAgB,KAAK,IAAI;0BAC/B,QAAQ;wBACV;sBACF;oBACF;oBAEA,SAAS;AACP,4BAAM,IAAI,8BAA8B;wBACtC,eAAe,uCAAuC,KAAK,SAAS;sBACtE,CAAC;oBACH;kBACF;gBACF,WAAW,KAAK,cAAc,mBAAmB;AAC/C,sBAAI,KAAK,gBAAgB,KAAK;AAC5B,0BAAM,IAAI,8BAA8B;sBACtC,eAAe;oBACjB,CAAC;kBACH;AAEA,yBAAO;oBACL,MAAM;oBACN,MACE,OAAO,KAAK,SAAS,YACrB,KAAK,KAAK,WAAW,OAAO,IACxB,EAAE,SAAS,KAAK,KAAK,IACrB;sBACE,WAAU,KAAA,KAAK,aAAL,OAAA,KAAiB,QAAQ,KAAK;sBACxC,WAAW,+BAA+B,gBAAgB,KAAK,IAAI,CAAC;oBACtE;kBACR;gBACF,OAAO;AACL,wBAAM,IAAI,8BAA8B;oBACtC,eAAe,wBAAwB,KAAK,SAAS;kBACvD,CAAC;gBACH;cACF;YACF;UACF,CAAC;QACH,CAAC;AAED;MACF;MAEA,KAAK,aAAa;AAChB,YAAI,OAAO;AACX,cAAM,YAID,CAAC;AAEN,mBAAW,QAAQ,SAAS;AAC1B,kBAAQ,KAAK,MAAM;YACjB,KAAK,QAAQ;AACX,sBAAQ,KAAK;AACb;YACF;YACA,KAAK,aAAa;AAChB,wBAAU,KAAK;gBACb,IAAI,KAAK;gBACT,MAAM;gBACN,UAAU;kBACR,MAAM,KAAK;kBACX,WAAW,KAAK,UAAU,KAAK,KAAK;gBACtC;cACF,CAAC;AACD;YACF;UACF;QACF;AAEA,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,YAAY,UAAU,SAAS,IAAI,YAAY;QACjD,CAAC;AAED;MACF;MAEA,KAAK,QAAQ;AACX,mBAAW,gBAAgB,SAAS;AAClC,cAAI,aAAa,SAAS,0BAA0B;AAClD;UACF;AACA,gBAAM,SAAS,aAAa;AAE5B,cAAI;AACJ,kBAAQ,OAAO,MAAM;YACnB,KAAK;YACL,KAAK;AACH,6BAAe,OAAO;AACtB;YACF,KAAK;AACH,8BAAe,KAAA,OAAO,WAAP,OAAA,KAAiB;AAChC;YACF,KAAK;YACL,KAAK;YACL,KAAK;AACH,6BAAe,KAAK,UAAU,OAAO,KAAK;AAC1C;UACJ;AAEA,mBAAS,KAAK;YACZ,MAAM;YACN,cAAc,aAAa;YAC3B,SAAS;UACX,CAAC;QACH;AACA;MACF;MAEA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;MACzD;IACF;EACF;AAEA,SAAO,EAAE,UAAU,SAAS;AAC9B;AChOO,SAAS,oBAAoB;EAClC;EACA;EACA;AACF,GAIG;AACD,SAAO;IACL,IAAI,MAAA,OAAA,KAAM;IACV,SAAS,SAAA,OAAA,QAAS;IAClB,WAAW,UAAU,IAAI,KAAK,UAAU,GAAI,IAAI;EAClD;AACF;ACZO,SAAS,sBACd,cACwC;AACxC,UAAQ,cAAc;IACpB,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT,KAAK;IACL,KAAK;AACH,aAAO;IACT;AACE,aAAO;EACX;AACF;ACKO,IAAM,2BAA2B;EAAW,MACjD;IACED,GAAE,OAAO;MACP,IAAIA,GAAE,OAAO,EAAE,QAAQ;MACvB,SAASA,GAAE,OAAO,EAAE,QAAQ;MAC5B,OAAOA,GAAE,OAAO,EAAE,QAAQ;MAC1B,SAASA,GAAE;QACTA,GAAE,OAAO;UACP,SAASA,GAAE,OAAO;YAChB,MAAMA,GAAE,QAAQ,WAAW,EAAE,QAAQ;YACrC,SAASA,GAAE,OAAO,EAAE,QAAQ;YAC5B,YAAYA,GACT;cACCA,GAAE,OAAO;gBACP,IAAIA,GAAE,OAAO,EAAE,QAAQ;gBACvB,MAAMA,GAAE,QAAQ,UAAU;gBAC1B,UAAUA,GAAE,OAAO;kBACjB,MAAMA,GAAE,OAAO;kBACf,WAAWA,GAAE,OAAO;gBACtB,CAAC;cACH,CAAC;YACH,EACC,QAAQ;YACX,aAAaA,GACV;cACCA,GAAE,OAAO;gBACP,MAAMA,GAAE,QAAQ,cAAc;gBAC9B,cAAcA,GAAE,OAAO;kBACrB,aAAaA,GAAE,OAAO;kBACtB,WAAWA,GAAE,OAAO;kBACpB,KAAKA,GAAE,OAAO;kBACd,OAAOA,GAAE,OAAO;gBAClB,CAAC;cACH,CAAC;YACH,EACC,QAAQ;UACb,CAAC;UACD,OAAOA,GAAE,OAAO;UAChB,UAAUA,GACP,OAAO;YACN,SAASA,GACN;cACCA,GAAE,OAAO;gBACP,OAAOA,GAAE,OAAO;gBAChB,SAASA,GAAE,OAAO;gBAClB,cAAcA,GAAE;kBACdA,GAAE,OAAO;oBACP,OAAOA,GAAE,OAAO;oBAChB,SAASA,GAAE,OAAO;kBACpB,CAAC;gBACH;cACF,CAAC;YACH,EACC,QAAQ;UACb,CAAC,EACA,QAAQ;UACX,eAAeA,GAAE,OAAO,EAAE,QAAQ;QACpC,CAAC;MACH;MACA,OAAOA,GACJ,OAAO;QACN,eAAeA,GAAE,OAAO,EAAE,QAAQ;QAClC,mBAAmBA,GAAE,OAAO,EAAE,QAAQ;QACtC,cAAcA,GAAE,OAAO,EAAE,QAAQ;QACjC,uBAAuBA,GACpB,OAAO;UACN,eAAeA,GAAE,OAAO,EAAE,QAAQ;QACpC,CAAC,EACA,QAAQ;QACX,2BAA2BA,GACxB,OAAO;UACN,kBAAkBA,GAAE,OAAO,EAAE,QAAQ;UACrC,4BAA4BA,GAAE,OAAO,EAAE,QAAQ;UAC/C,4BAA4BA,GAAE,OAAO,EAAE,QAAQ;QACjD,CAAC,EACA,QAAQ;MACb,CAAC,EACA,QAAQ;IACb,CAAC;EACH;AACF;AAIO,IAAM,wBAAwB;EAAW,MAC9C;IACEA,GAAE,MAAM;MACNA,GAAE,OAAO;QACP,IAAIA,GAAE,OAAO,EAAE,QAAQ;QACvB,SAASA,GAAE,OAAO,EAAE,QAAQ;QAC5B,OAAOA,GAAE,OAAO,EAAE,QAAQ;QAC1B,SAASA,GAAE;UACTA,GAAE,OAAO;YACP,OAAOA,GACJ,OAAO;cACN,MAAMA,GAAE,KAAK,CAAC,WAAW,CAAC,EAAE,QAAQ;cACpC,SAASA,GAAE,OAAO,EAAE,QAAQ;cAC5B,YAAYA,GACT;gBACCA,GAAE,OAAO;kBACP,OAAOA,GAAE,OAAO;kBAChB,IAAIA,GAAE,OAAO,EAAE,QAAQ;kBACvB,MAAMA,GAAE,QAAQ,UAAU,EAAE,QAAQ;kBACpC,UAAUA,GAAE,OAAO;oBACjB,MAAMA,GAAE,OAAO,EAAE,QAAQ;oBACzB,WAAWA,GAAE,OAAO,EAAE,QAAQ;kBAChC,CAAC;gBACH,CAAC;cACH,EACC,QAAQ;cACX,aAAaA,GACV;gBACCA,GAAE,OAAO;kBACP,MAAMA,GAAE,QAAQ,cAAc;kBAC9B,cAAcA,GAAE,OAAO;oBACrB,aAAaA,GAAE,OAAO;oBACtB,WAAWA,GAAE,OAAO;oBACpB,KAAKA,GAAE,OAAO;oBACd,OAAOA,GAAE,OAAO;kBAClB,CAAC;gBACH,CAAC;cACH,EACC,QAAQ;YACb,CAAC,EACA,QAAQ;YACX,UAAUA,GACP,OAAO;cACN,SAASA,GACN;gBACCA,GAAE,OAAO;kBACP,OAAOA,GAAE,OAAO;kBAChB,SAASA,GAAE,OAAO;kBAClB,cAAcA,GAAE;oBACdA,GAAE,OAAO;sBACP,OAAOA,GAAE,OAAO;sBAChB,SAASA,GAAE,OAAO;oBACpB,CAAC;kBACH;gBACF,CAAC;cACH,EACC,QAAQ;YACb,CAAC,EACA,QAAQ;YACX,eAAeA,GAAE,OAAO,EAAE,QAAQ;YAClC,OAAOA,GAAE,OAAO;UAClB,CAAC;QACH;QACA,OAAOA,GACJ,OAAO;UACN,eAAeA,GAAE,OAAO,EAAE,QAAQ;UAClC,mBAAmBA,GAAE,OAAO,EAAE,QAAQ;UACtC,cAAcA,GAAE,OAAO,EAAE,QAAQ;UACjC,uBAAuBA,GACpB,OAAO;YACN,eAAeA,GAAE,OAAO,EAAE,QAAQ;UACpC,CAAC,EACA,QAAQ;UACX,2BAA2BA,GACxB,OAAO;YACN,kBAAkBA,GAAE,OAAO,EAAE,QAAQ;YACrC,4BAA4BA,GAAE,OAAO,EAAE,QAAQ;YAC/C,4BAA4BA,GAAE,OAAO,EAAE,QAAQ;UACjD,CAAC,EACA,QAAQ;QACb,CAAC,EACA,QAAQ;MACb,CAAC;MACD;IACF,CAAC;EACH;AACF;AClJO,IAAM,iCAAiCE;EAAW,MACvDC;IACEH,GAAE,OAAO;;;;;;;MAOP,WAAWA,GAAE,OAAOA,GAAE,OAAO,OAAe,GAAGA,GAAE,OAAO,CAAC,EAAE,SAAS;;;;;;;;;;MAWpE,UAAUA,GAAE,MAAM,CAACA,GAAE,QAAQ,GAAGA,GAAE,OAAO,CAAC,CAAC,EAAE,SAAS;;;;MAKtD,mBAAmBA,GAAE,QAAQ,EAAE,SAAS;;;;;MAMxC,MAAMA,GAAE,OAAO,EAAE,SAAS;;;;MAK1B,iBAAiBA,GACd,KAAK,CAAC,QAAQ,WAAW,OAAO,UAAU,QAAQ,OAAO,CAAC,EAC1D,SAAS;;;;MAKZ,qBAAqBA,GAAE,OAAO,EAAE,SAAS;;;;MAKzC,OAAOA,GAAE,QAAQ,EAAE,SAAS;;;;MAK5B,UAAUA,GAAE,OAAOA,GAAE,OAAO,EAAE,IAAI,EAAE,GAAGA,GAAE,OAAO,EAAE,IAAI,GAAG,CAAC,EAAE,SAAS;;;;MAKrE,YAAYA,GAAE,OAAOA,GAAE,OAAO,GAAGA,GAAE,IAAI,CAAC,EAAE,SAAS;;;;;;;;;;;MAYnD,aAAaA,GAAE,KAAK,CAAC,QAAQ,QAAQ,YAAY,SAAS,CAAC,EAAE,SAAS;;;;;;MAOtE,kBAAkBA,GAAE,QAAQ,EAAE,SAAS;;;;;MAMvC,eAAeA,GAAE,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;;;;;MAM1D,gBAAgBA,GAAE,OAAO,EAAE,SAAS;;;;;;;;;MAUpC,sBAAsBA,GAAE,KAAK,CAAC,aAAa,KAAK,CAAC,EAAE,SAAS;;;;;;;;MAS5D,kBAAkBA,GAAE,OAAO,EAAE,SAAS;;;;;;;;;MAUtC,mBAAmBA,GAAE,KAAK,CAAC,UAAU,aAAa,QAAQ,CAAC,EAAE,SAAS;;;;;;;;;;MAWtE,gBAAgBA,GAAE,QAAQ,EAAE,SAAS;IACvC,CAAC;EACH;AACF;ACzKO,SAAS,iBAAiB;EAC/B;EACA;AACF,GAOE;AAEA,WAAQ,SAAA,OAAA,SAAA,MAAO,UAAS,QAAQ;AAEhC,QAAM,eAAkC,CAAC;AAEzC,MAAI,SAAS,MAAM;AACjB,WAAO,EAAE,OAAO,QAAW,YAAY,QAAW,aAAa;EACjE;AAEA,QAAM,cAAwC,CAAC;AAE/C,aAAW,QAAQ,OAAO;AACxB,YAAQ,KAAK,MAAM;MACjB,KAAK;AACH,oBAAY,KAAK;UACf,MAAM;UACN,UAAU;YACR,MAAM,KAAK;YACX,aAAa,KAAK;YAClB,YAAY,KAAK;YACjB,GAAI,KAAK,UAAU,OAAO,EAAE,QAAQ,KAAK,OAAO,IAAI,CAAC;UACvD;QACF,CAAC;AACD;MACF;AACE,qBAAa,KAAK;UAChB,MAAM;UACN,SAAS,cAAc,KAAK,IAAI;QAClC,CAAC;AACD;IACJ;EACF;AAEA,MAAI,cAAc,MAAM;AACtB,WAAO,EAAE,OAAO,aAAa,YAAY,QAAW,aAAa;EACnE;AAEA,QAAM,OAAO,WAAW;AAExB,UAAQ,MAAM;IACZ,KAAK;IACL,KAAK;IACL,KAAK;AACH,aAAO,EAAE,OAAO,aAAa,YAAY,MAAM,aAAa;IAC9D,KAAK;AACH,aAAO;QACL,OAAO;QACP,YAAY;UACV,MAAM;UACN,UAAU;YACR,MAAM,WAAW;UACnB;QACF;QACA;MACF;IACF,SAAS;AACP,YAAM,mBAA0B;AAChC,YAAM,IAAII,8BAA8B;QACtC,eAAe,qBAAqB,gBAAgB;MACtD,CAAC;IACH;EACF;AACF;ATjCO,IAAM,0BAAN,MAAyD;EAW9D,YAAY,SAA4B,QAA0B;AAVlE,SAAS,uBAAuB;AAIhC,SAAS,gBAAgB;MACvB,WAAW,CAAC,iBAAiB;IAC/B;AAKE,SAAK,UAAU;AACf,SAAK,SAAS;EAChB;EAEA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAEA,MAAc,QAAQ;IACpB;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EACF,GAA+B;AApFjC,QAAA,IAAA,IAAA,IAAA,IAAA;AAqFI,UAAM,WAA8B,CAAC;AAGrC,UAAM,iBACH,KAAA,MAAM,qBAAqB;MAC1B,UAAU;MACV;MACA,QAAQ;IACV,CAAC,MAJA,OAAA,KAIM,CAAC;AAEV,UAAM,oBAAoB,mCAAmC,KAAK,OAAO;AACzE,UAAM,oBACJ,KAAA,cAAc,mBAAd,OAAA,KAAgC,kBAAkB;AAEpD,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK,EAAE,MAAM,eAAe,SAAS,OAAO,CAAC;IACxD;AAEA,UAAM,EAAE,UAAU,UAAU,gBAAgB,IAAI;MAC9C;QACE;QACA,oBACE,KAAA,cAAc,sBAAd,OAAA,KACC,mBACG,cACA,kBAAkB;MAC1B;IACF;AAEA,aAAS,KAAK,GAAG,eAAe;AAEhC,UAAM,oBAAmB,KAAA,cAAc,qBAAd,OAAA,KAAkC;AAE3D,UAAM,WAAW;;MAEf,OAAO,KAAK;;MAGZ,YAAY,cAAc;MAC1B,UACE,cAAc,aAAa,QAC3B,OAAO,cAAc,aAAa,WAC9B,OACA;MACN,cACE,OAAO,cAAc,aAAa,WAC9B,cAAc,WACd,OAAO,cAAc,aAAa,YAChC,cAAc,WACZ,IACA,SACF;MACR,MAAM,cAAc;MACpB,qBAAqB,cAAc;;MAGnC,YAAY;MACZ;MACA,OAAO;MACP,mBAAmB;MACnB,kBAAkB;MAClB,kBACE,kBAAA,OAAA,SAAA,eAAgB,UAAS,SACrB,eAAe,UAAU,OACvB;QACE,MAAM;QACN,aAAa;UACX,QAAQ,eAAe;UACvB,QAAQ;UACR,OAAM,KAAA,eAAe,SAAf,OAAA,KAAuB;UAC7B,aAAa,eAAe;QAC9B;MACF,IACA,EAAE,MAAM,cAAc,IACxB;MACN,MAAM;MACN;MACA,WAAW,cAAc;;;MAIzB,uBAAuB,cAAc;MACrC,OAAO,cAAc;MACrB,UAAU,cAAc;MACxB,YAAY,cAAc;MAC1B,kBAAkB,cAAc;MAChC,cAAc,cAAc;MAC5B,kBAAkB,cAAc;MAChC,wBAAwB,cAAc;MACtC,mBAAmB,cAAc;;MAGjC;IACF;AAIA,QAAI,kBAAkB;AAGpB,UACE,cAAc,oBAAoB,UAClC,CAAC,kBAAkB,gCACnB;AACA,YAAI,SAAS,eAAe,MAAM;AAChC,mBAAS,cAAc;AACvB,mBAAS,KAAK;YACZ,MAAM;YACN,SAAS;YACT,SAAS;UACX,CAAC;QACH;AACA,YAAI,SAAS,SAAS,MAAM;AAC1B,mBAAS,QAAQ;AACjB,mBAAS,KAAK;YACZ,MAAM;YACN,SAAS;YACT,SAAS;UACX,CAAC;QACH;AACA,YAAI,SAAS,YAAY,MAAM;AAC7B,mBAAS,WAAW;AACpB,mBAAS,KAAK;YACZ,MAAM;YACN,SAAS;UACX,CAAC;QACH;MACF;AAEA,UAAI,SAAS,qBAAqB,MAAM;AACtC,iBAAS,oBAAoB;AAC7B,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS;QACX,CAAC;MACH;AACA,UAAI,SAAS,oBAAoB,MAAM;AACrC,iBAAS,mBAAmB;AAC5B,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS;QACX,CAAC;MACH;AACA,UAAI,SAAS,cAAc,MAAM;AAC/B,iBAAS,aAAa;AACtB,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;QACX,CAAC;MACH;AAEA,UAAI,SAAS,gBAAgB,MAAM;AACjC,iBAAS,eAAe;AACxB,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;QACX,CAAC;MACH;AAGA,UAAI,SAAS,cAAc,MAAM;AAC/B,YAAI,SAAS,yBAAyB,MAAM;AAC1C,mBAAS,wBAAwB,SAAS;QAC5C;AACA,iBAAS,aAAa;MACxB;IACF,WACE,KAAK,QAAQ,WAAW,uBAAuB,KAC/C,KAAK,QAAQ,WAAW,4BAA4B,GACpD;AACA,UAAI,SAAS,eAAe,MAAM;AAChC,iBAAS,cAAc;AACvB,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SACE;QACJ,CAAC;MACH;IACF;AAGA,QACE,cAAc,gBAAgB,UAC9B,CAAC,kBAAkB,wBACnB;AACA,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SACE;MACJ,CAAC;AACD,eAAS,eAAe;IAC1B;AAGA,QACE,cAAc,gBAAgB,cAC9B,CAAC,kBAAkB,4BACnB;AACA,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SACE;MACJ,CAAC;AACD,eAAS,eAAe;IAC1B;AAEA,UAAM;MACJ,OAAO;MACP,YAAY;MACZ;IACF,IAAI,iBAAiB;MACnB;MACA;IACF,CAAC;AAED,WAAO;MACL,MAAM;QACJ,GAAG;QACH,OAAO;QACP,aAAa;MACf;MACA,UAAU,CAAC,GAAG,UAAU,GAAG,YAAY;IACzC;EACF;EAEA,MAAM,WACJ,SACwC;AA7T5C,QAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AA8TI,UAAM,EAAE,MAAM,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAE3D,UAAM;MACJ;MACA,OAAO;MACP,UAAU;IACZ,IAAI,MAAM,cAAc;MACtB,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAAS,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D;MACA,uBAAuB;MACvB,2BAA2B;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,UAAM,SAAS,SAAS,QAAQ,CAAC;AACjC,UAAM,UAAyC,CAAC;AAGhD,UAAM,OAAO,OAAO,QAAQ;AAC5B,QAAI,QAAQ,QAAQ,KAAK,SAAS,GAAG;AACnC,cAAQ,KAAK,EAAE,MAAM,QAAQ,KAAK,CAAC;IACrC;AAGA,eAAW,aAAY,KAAA,OAAO,QAAQ,eAAf,OAAA,KAA6B,CAAC,GAAG;AACtD,cAAQ,KAAK;QACX,MAAM;QACN,aAAY,KAAA,SAAS,OAAT,OAAA,KAAe,WAAW;QACtC,UAAU,SAAS,SAAS;QAC5B,OAAO,SAAS,SAAS;MAC3B,CAAC;IACH;AAGA,eAAW,eAAc,KAAA,OAAO,QAAQ,gBAAf,OAAA,KAA8B,CAAC,GAAG;AACzD,cAAQ,KAAK;QACX,MAAM;QACN,YAAY;QACZ,IAAI,WAAW;QACf,KAAK,WAAW,aAAa;QAC7B,OAAO,WAAW,aAAa;MACjC,CAAC;IACH;AAGA,UAAM,0BAAyB,KAAA,SAAS,UAAT,OAAA,SAAA,GAAgB;AAC/C,UAAM,sBAAqB,KAAA,SAAS,UAAT,OAAA,SAAA,GAAgB;AAC3C,UAAM,mBAA6C,EAAE,QAAQ,CAAC,EAAE;AAChE,SAAI,0BAAA,OAAA,SAAA,uBAAwB,+BAA8B,MAAM;AAC9D,uBAAiB,OAAO,2BACtB,0BAAA,OAAA,SAAA,uBAAwB;IAC5B;AACA,SAAI,0BAAA,OAAA,SAAA,uBAAwB,+BAA8B,MAAM;AAC9D,uBAAiB,OAAO,2BACtB,0BAAA,OAAA,SAAA,uBAAwB;IAC5B;AACA,UAAI,KAAA,OAAO,aAAP,OAAA,SAAA,GAAiB,YAAW,MAAM;AACpC,uBAAiB,OAAO,WAAW,OAAO,SAAS;IACrD;AAEA,WAAO;MACL;MACA,cAAc;QACZ,SAAS,sBAAsB,OAAO,aAAa;QACnD,MAAK,KAAA,OAAO,kBAAP,OAAA,KAAwB;MAC/B;MACA,OAAO,uBAAuB,SAAS,KAAK;MAC5C,SAAS,EAAE,KAAK;MAChB,UAAU;QACR,GAAG,oBAAoB,QAAQ;QAC/B,SAAS;QACT,MAAM;MACR;MACA;MACA;IACF;EACF;EAEA,MAAM,SACJ,SACsC;AACtC,UAAM,EAAE,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAErD,UAAM,OAAO;MACX,GAAG;MACH,QAAQ;MACR,gBAAgB;QACd,eAAe;MACjB;IACF;AAEA,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAM,cAAc;MAC/D,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAAS,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D;MACA,uBAAuB;MACvB,2BAA2B;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,UAAM,YAQD,CAAC;AAEN,QAAI,eAA4C;MAC9C,SAAS;MACT,KAAK;IACP;AACA,QAAI,QAAqC;AACzC,QAAI,oBAAoB;AACxB,QAAI,eAAe;AAEnB,UAAM,mBAA6C,EAAE,QAAQ,CAAC,EAAE;AAEhE,WAAO;MACL,QAAQ,SAAS;QACf,IAAI,gBAGF;UACA,MAAM,YAAY;AAChB,uBAAW,QAAQ,EAAE,MAAM,gBAAgB,SAAS,CAAC;UACvD;UAEA,UAAU,OAAO,YAAY;AA7cvC,gBAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AA8cY,gBAAI,QAAQ,kBAAkB;AAC5B,yBAAW,QAAQ,EAAE,MAAM,OAAO,UAAU,MAAM,SAAS,CAAC;YAC9D;AAGA,gBAAI,CAAC,MAAM,SAAS;AAClB,6BAAe,EAAE,SAAS,SAAS,KAAK,OAAU;AAClD,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;YACF;AAEA,kBAAM,QAAQ,MAAM;AAGpB,gBAAI,WAAW,OAAO;AACpB,6BAAe,EAAE,SAAS,SAAS,KAAK,OAAU;AAClD,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;YACF;AAKA,gBAAI,CAAC,mBAAmB;AACtB,oBAAM,WAAW,oBAAoB,KAAK;AAC1C,kBAAI,OAAO,OAAO,QAAQ,EAAE,KAAK,OAAO,GAAG;AACzC,oCAAoB;AACpB,2BAAW,QAAQ;kBACjB,MAAM;kBACN,GAAG,oBAAoB,KAAK;gBAC9B,CAAC;cACH;YACF;AAEA,gBAAI,MAAM,SAAS,MAAM;AACvB,sBAAQ,MAAM;AAEd,oBACE,KAAA,MAAM,MAAM,8BAAZ,OAAA,SAAA,GACI,+BAA8B,MAClC;AACA,iCAAiB,OAAO,4BACtB,KAAA,MAAM,MAAM,8BAAZ,OAAA,SAAA,GAAuC;cAC3C;AACA,oBACE,KAAA,MAAM,MAAM,8BAAZ,OAAA,SAAA,GACI,+BAA8B,MAClC;AACA,iCAAiB,OAAO,4BACtB,KAAA,MAAM,MAAM,8BAAZ,OAAA,SAAA,GAAuC;cAC3C;YACF;AAEA,kBAAM,SAAS,MAAM,QAAQ,CAAC;AAE9B,iBAAI,UAAA,OAAA,SAAA,OAAQ,kBAAiB,MAAM;AACjC,6BAAe;gBACb,SAAS,sBAAsB,OAAO,aAAa;gBACnD,KAAK,OAAO;cACd;YACF;AAEA,kBAAI,KAAA,UAAA,OAAA,SAAA,OAAQ,aAAR,OAAA,SAAA,GAAkB,YAAW,MAAM;AACrC,+BAAiB,OAAO,WAAW,OAAO,SAAS;YACrD;AAEA,iBAAI,UAAA,OAAA,SAAA,OAAQ,UAAS,MAAM;AACzB;YACF;AAEA,kBAAM,QAAQ,OAAO;AAErB,gBAAI,MAAM,WAAW,MAAM;AACzB,kBAAI,CAAC,cAAc;AACjB,2BAAW,QAAQ,EAAE,MAAM,cAAc,IAAI,IAAI,CAAC;AAClD,+BAAe;cACjB;AAEA,yBAAW,QAAQ;gBACjB,MAAM;gBACN,IAAI;gBACJ,OAAO,MAAM;cACf,CAAC;YACH;AAEA,gBAAI,MAAM,cAAc,MAAM;AAC5B,yBAAW,iBAAiB,MAAM,YAAY;AAC5C,sBAAM,QAAQ,cAAc;AAG5B,oBAAI,UAAU,KAAK,KAAK,MAAM;AAC5B,sBAAI,cAAc,SAAS,YAAY;AACrC,0BAAM,IAAI,yBAAyB;sBACjC,MAAM;sBACN,SAAS;oBACX,CAAC;kBACH;AAEA,sBAAI,cAAc,MAAM,MAAM;AAC5B,0BAAM,IAAI,yBAAyB;sBACjC,MAAM;sBACN,SAAS;oBACX,CAAC;kBACH;AAEA,wBAAI,KAAA,cAAc,aAAd,OAAA,SAAA,GAAwB,SAAQ,MAAM;AACxC,0BAAM,IAAI,yBAAyB;sBACjC,MAAM;sBACN,SAAS;oBACX,CAAC;kBACH;AAEA,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI,cAAc;oBAClB,UAAU,cAAc,SAAS;kBACnC,CAAC;AAED,4BAAU,KAAK,IAAI;oBACjB,IAAI,cAAc;oBAClB,MAAM;oBACN,UAAU;sBACR,MAAM,cAAc,SAAS;sBAC7B,YAAW,KAAA,cAAc,SAAS,cAAvB,OAAA,KAAoC;oBACjD;oBACA,aAAa;kBACf;AAEA,wBAAMC,YAAW,UAAU,KAAK;AAEhC,wBACE,KAAAA,UAAS,aAAT,OAAA,SAAA,GAAmB,SAAQ,UAC3B,KAAAA,UAAS,aAAT,OAAA,SAAA,GAAmB,cAAa,MAChC;AAEA,wBAAIA,UAAS,SAAS,UAAU,SAAS,GAAG;AAC1C,iCAAW,QAAQ;wBACjB,MAAM;wBACN,IAAIA,UAAS;wBACb,OAAOA,UAAS,SAAS;sBAC3B,CAAC;oBACH;AAIA,wBAAI,eAAeA,UAAS,SAAS,SAAS,GAAG;AAC/C,iCAAW,QAAQ;wBACjB,MAAM;wBACN,IAAIA,UAAS;sBACf,CAAC;AAED,iCAAW,QAAQ;wBACjB,MAAM;wBACN,aAAY,KAAAA,UAAS,OAAT,OAAA,KAAe,WAAW;wBACtC,UAAUA,UAAS,SAAS;wBAC5B,OAAOA,UAAS,SAAS;sBAC3B,CAAC;AACDA,gCAAS,cAAc;oBACzB;kBACF;AAEA;gBACF;AAGA,sBAAM,WAAW,UAAU,KAAK;AAEhC,oBAAI,SAAS,aAAa;AACxB;gBACF;AAEA,sBAAI,KAAA,cAAc,aAAd,OAAA,SAAA,GAAwB,cAAa,MAAM;AAC7C,2BAAS,SAAU,cACjB,MAAA,KAAA,cAAc,aAAd,OAAA,SAAA,GAAwB,cAAxB,OAAA,KAAqC;gBACzC;AAGA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,SAAS;kBACb,QAAO,KAAA,cAAc,SAAS,cAAvB,OAAA,KAAoC;gBAC7C,CAAC;AAGD,sBACE,KAAA,SAAS,aAAT,OAAA,SAAA,GAAmB,SAAQ,UAC3B,KAAA,SAAS,aAAT,OAAA,SAAA,GAAmB,cAAa,QAChC,eAAe,SAAS,SAAS,SAAS,GAC1C;AACA,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI,SAAS;kBACf,CAAC;AAED,6BAAW,QAAQ;oBACjB,MAAM;oBACN,aAAY,KAAA,SAAS,OAAT,OAAA,KAAe,WAAW;oBACtC,UAAU,SAAS,SAAS;oBAC5B,OAAO,SAAS,SAAS;kBAC3B,CAAC;AACD,2BAAS,cAAc;gBACzB;cACF;YACF;AAGA,gBAAI,MAAM,eAAe,MAAM;AAC7B,yBAAW,cAAc,MAAM,aAAa;AAC1C,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY;kBACZ,IAAI,WAAW;kBACf,KAAK,WAAW,aAAa;kBAC7B,OAAO,WAAW,aAAa;gBACjC,CAAC;cACH;YACF;UACF;UAEA,MAAM,YAAY;AAChB,gBAAI,cAAc;AAChB,yBAAW,QAAQ,EAAE,MAAM,YAAY,IAAI,IAAI,CAAC;YAClD;AAEA,uBAAW,QAAQ;cACjB,MAAM;cACN;cACA,OAAO,uBAAuB,KAAK;cACnC,GAAI,oBAAoB,OAAO,EAAE,iBAAiB,IAAI,CAAC;YACzD,CAAC;UACH;QACF,CAAC;MACH;MACA,SAAS,EAAE,KAAK;MAChB,UAAU,EAAE,SAAS,gBAAgB;IACvC;EACF;AACF;AWnrBO,SAAS,6BACd,OACsB;AAVxB,MAAA,IAAA,IAAA,IAAA;AAWE,MAAI,SAAS,MAAM;AACjB,WAAO;MACL,aAAa;QACX,OAAO;QACP,SAAS;QACT,WAAW;QACX,YAAY;MACd;MACA,cAAc;QACZ,OAAO;QACP,MAAM;QACN,WAAW;MACb;MACA,KAAK;IACP;EACF;AAEA,QAAM,gBAAe,KAAA,MAAM,kBAAN,OAAA,KAAuB;AAC5C,QAAM,oBAAmB,KAAA,MAAM,sBAAN,OAAA,KAA2B;AAEpD,SAAO;IACL,aAAa;MACX,QAAO,KAAA,MAAM,kBAAN,OAAA,KAAuB;MAC9B,SAAS;MACT,WAAW;MACX,YAAY;IACd;IACA,cAAc;MACZ,QAAO,KAAA,MAAM,sBAAN,OAAA,KAA2B;MAClC,MAAM;MACN,WAAW;IACb;IACA,KAAK;EACP;AACF;ACvCO,SAAS,gCAAgC;EAC9C;EACA,OAAO;EACP,YAAY;AACd,GAOE;AAEA,MAAI,OAAO;AAGX,MAAI,OAAO,CAAC,EAAE,SAAS,UAAU;AAC/B,YAAQ,GAAG,OAAO,CAAC,EAAE,OAAO;;;AAC5B,aAAS,OAAO,MAAM,CAAC;EACzB;AAEA,aAAW,EAAE,MAAM,QAAQ,KAAK,QAAQ;AACtC,YAAQ,MAAM;MACZ,KAAK,UAAU;AACb,cAAM,IAAI,mBAAmB;UAC3B,SAAS;UACT;QACF,CAAC;MACH;MAEA,KAAK,QAAQ;AACX,cAAM,cAAc,QACjB,IAAI,CAAA,SAAQ;AACX,kBAAQ,KAAK,MAAM;YACjB,KAAK,QAAQ;AACX,qBAAO,KAAK;YACd;UACF;QACF,CAAC,EACA,OAAO,OAAO,EACd,KAAK,EAAE;AAEV,gBAAQ,GAAG,IAAI;EAAM,WAAW;;;AAChC;MACF;MAEA,KAAK,aAAa;AAChB,cAAM,mBAAmB,QACtB,IAAI,CAAA,SAAQ;AACX,kBAAQ,KAAK,MAAM;YACjB,KAAK,QAAQ;AACX,qBAAO,KAAK;YACd;YACA,KAAK,aAAa;AAChB,oBAAM,IAAID,8BAA8B;gBACtC,eAAe;cACjB,CAAC;YACH;UACF;QACF,CAAC,EACA,KAAK,EAAE;AAEV,gBAAQ,GAAG,SAAS;EAAM,gBAAgB;;;AAC1C;MACF;MAEA,KAAK,QAAQ;AACX,cAAM,IAAIA,8BAA8B;UACtC,eAAe;QACjB,CAAC;MACH;MAEA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;MACzD;IACF;EACF;AAGA,UAAQ,GAAG,SAAS;;AAEpB,SAAO;IACL,QAAQ;IACR,eAAe,CAAC;EAAK,IAAI,GAAG;EAC9B;AACF;AC5FO,SAASE,qBAAoB;EAClC;EACA;EACA;AACF,GAIG;AACD,SAAO;IACL,IAAI,MAAA,OAAA,KAAM;IACV,SAAS,SAAA,OAAA,QAAS;IAClB,WAAW,WAAW,OAAO,IAAI,KAAK,UAAU,GAAI,IAAI;EAC1D;AACF;ACZO,SAASC,uBACd,cACwC;AACxC,UAAQ,cAAc;IACpB,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT,KAAK;IACL,KAAK;AACH,aAAO;IACT;AACE,aAAO;EACX;AACF;ACZO,IAAM,iCAAiCL;EAAW,MACvDC;IACEH,GAAE,OAAO;MACP,IAAIA,GAAE,OAAO,EAAE,QAAQ;MACvB,SAASA,GAAE,OAAO,EAAE,QAAQ;MAC5B,OAAOA,GAAE,OAAO,EAAE,QAAQ;MAC1B,SAASA,GAAE;QACTA,GAAE,OAAO;UACP,MAAMA,GAAE,OAAO;UACf,eAAeA,GAAE,OAAO;UACxB,UAAUA,GACP,OAAO;YACN,QAAQA,GAAE,MAAMA,GAAE,OAAO,CAAC;YAC1B,gBAAgBA,GAAE,MAAMA,GAAE,OAAO,CAAC;YAClC,cAAcA,GAAE,MAAMA,GAAE,OAAOA,GAAE,OAAO,GAAGA,GAAE,OAAO,CAAC,CAAC,EAAE,QAAQ;UAClE,CAAC,EACA,QAAQ;QACb,CAAC;MACH;MACA,OAAOA,GACJ,OAAO;QACN,eAAeA,GAAE,OAAO;QACxB,mBAAmBA,GAAE,OAAO;QAC5B,cAAcA,GAAE,OAAO;MACzB,CAAC,EACA,QAAQ;IACb,CAAC;EACH;AACF;AAIO,IAAM,8BAA8BE;EAAW,MACpDC;IACEH,GAAE,MAAM;MACNA,GAAE,OAAO;QACP,IAAIA,GAAE,OAAO,EAAE,QAAQ;QACvB,SAASA,GAAE,OAAO,EAAE,QAAQ;QAC5B,OAAOA,GAAE,OAAO,EAAE,QAAQ;QAC1B,SAASA,GAAE;UACTA,GAAE,OAAO;YACP,MAAMA,GAAE,OAAO;YACf,eAAeA,GAAE,OAAO,EAAE,QAAQ;YAClC,OAAOA,GAAE,OAAO;YAChB,UAAUA,GACP,OAAO;cACN,QAAQA,GAAE,MAAMA,GAAE,OAAO,CAAC;cAC1B,gBAAgBA,GAAE,MAAMA,GAAE,OAAO,CAAC;cAClC,cAAcA,GACX,MAAMA,GAAE,OAAOA,GAAE,OAAO,GAAGA,GAAE,OAAO,CAAC,CAAC,EACtC,QAAQ;YACb,CAAC,EACA,QAAQ;UACb,CAAC;QACH;QACA,OAAOA,GACJ,OAAO;UACN,eAAeA,GAAE,OAAO;UACxB,mBAAmBA,GAAE,OAAO;UAC5B,cAAcA,GAAE,OAAO;QACzB,CAAC,EACA,QAAQ;MACb,CAAC;MACD;IACF,CAAC;EACH;AACF;AClEO,IAAM,kCAAkCE;EAAW,MACxDC;IACEH,GAAE,OAAO;;;;MAIP,MAAMA,GAAE,QAAQ,EAAE,SAAS;;;;;;;;;;;;;;;MAgB3B,WAAWA,GAAE,OAAOA,GAAE,OAAO,GAAGA,GAAE,OAAO,CAAC,EAAE,SAAS;;;;MAKrD,QAAQA,GAAE,OAAO,EAAE,SAAS;;;;;MAM5B,MAAMA,GAAE,OAAO,EAAE,SAAS;;;;;;;;;;MAW1B,UAAUA,GAAE,MAAM,CAACA,GAAE,QAAQ,GAAGA,GAAE,OAAO,CAAC,CAAC,EAAE,SAAS;IACxD,CAAC;EACH;AACF;ANTO,IAAM,gCAAN,MAA+D;EAWpE,YACE,SACA,QACA;AAbF,SAAS,uBAAuB;AAsBhC,SAAS,gBAA0C;;IAEnD;AAVE,SAAK,UAAU;AACf,SAAK,SAAS;EAChB;EAVA,IAAY,sBAA8B;AACxC,WAAO,KAAK,OAAO,SAAS,MAAM,GAAG,EAAE,CAAC,EAAE,KAAK;EACjD;EAUA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAMA,MAAc,QAAQ;IACpB;IACA;IACA;IACA;IACA;IACA;IACA;IACA,eAAe;IACf;IACA;IACA;IACA;IACA;EACF,GAA+B;AAC7B,UAAM,WAA8B,CAAC;AAGrC,UAAM,gBAAgB;MACpB,GAAI,MAAMQ,qBAAqB;QAC7B,UAAU;QACV;QACA,QAAQ;MACV,CAAC;MACD,GAAI,MAAMA,qBAAqB;QAC7B,UAAU,KAAK;QACf;QACA,QAAQ;MACV,CAAC;IACH;AAEA,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK,EAAE,MAAM,eAAe,SAAS,OAAO,CAAC;IACxD;AAEA,QAAI,SAAA,OAAA,SAAA,MAAO,QAAQ;AACjB,eAAS,KAAK,EAAE,MAAM,eAAe,SAAS,QAAQ,CAAC;IACzD;AAEA,QAAI,cAAc,MAAM;AACtB,eAAS,KAAK,EAAE,MAAM,eAAe,SAAS,aAAa,CAAC;IAC9D;AAEA,QAAI,kBAAkB,QAAQ,eAAe,SAAS,QAAQ;AAC5D,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SAAS;MACX,CAAC;IACH;AAEA,UAAM,EAAE,QAAQ,kBAAkB,cAAc,IAC9C,gCAAgC,EAAE,OAAO,CAAC;AAE5C,UAAM,OAAO,CAAC,GAAI,iBAAA,OAAA,gBAAiB,CAAC,GAAI,GAAI,qBAAA,OAAA,oBAAqB,CAAC,CAAE;AAEpE,WAAO;MACL,MAAM;;QAEJ,OAAO,KAAK;;QAGZ,MAAM,cAAc;QACpB,YAAY,cAAc;QAC1B,WACE,iBAAA,OAAA,SAAA,cAAe,cAAa,OACxB,KACA,iBAAA,OAAA,SAAA,cAAe,cAAa,QAC1B,SACA,iBAAA,OAAA,SAAA,cAAe;QACvB,QAAQ,cAAc;QACtB,MAAM,cAAc;;QAGpB,YAAY;QACZ;QACA,OAAO;QACP,mBAAmB;QACnB,kBAAkB;QAClB;;QAGA,QAAQ;;QAGR,MAAM,KAAK,SAAS,IAAI,OAAO;MACjC;MACA;IACF;EACF;EAEA,MAAM,WACJ,SACwC;AApK5C,QAAA;AAqKI,UAAM,EAAE,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAErD,UAAM;MACJ;MACA,OAAO;MACP,UAAU;IACZ,IAAI,MAAMC,cAAc;MACtB,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D,MAAM;MACN,uBAAuB;MACvB,2BAA2BC;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,UAAM,SAAS,SAAS,QAAQ,CAAC;AAEjC,UAAM,mBAA6C,EAAE,QAAQ,CAAC,EAAE;AAEhE,QAAI,OAAO,YAAY,MAAM;AAC3B,uBAAiB,OAAO,WAAW,OAAO;IAC5C;AAEA,WAAO;MACL,SAAS,CAAC,EAAE,MAAM,QAAQ,MAAM,OAAO,KAAK,CAAC;MAC7C,OAAO,6BAA6B,SAAS,KAAK;MAClD,cAAc;QACZ,SAASJ,uBAAsB,OAAO,aAAa;QACnD,MAAK,KAAA,OAAO,kBAAP,OAAA,KAAwB;MAC/B;MACA,SAAS,EAAE,MAAM,KAAK;MACtB,UAAU;QACR,GAAGD,qBAAoB,QAAQ;QAC/B,SAAS;QACT,MAAM;MACR;MACA;MACA;IACF;EACF;EAEA,MAAM,SACJ,SACsC;AACtC,UAAM,EAAE,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAErD,UAAM,OAAO;MACX,GAAG;MACH,QAAQ;MAER,gBAAgB;QACd,eAAe;MACjB;IACF;AAEA,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAMG,cAAc;MAC/D,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D;MACA,uBAAuB;MACvB,2BAA2BE;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,QAAI,eAA4C;MAC9C,SAAS;MACT,KAAK;IACP;AACA,UAAM,mBAA6C,EAAE,QAAQ,CAAC,EAAE;AAChE,QAAI,QAA2C;AAC/C,QAAI,eAAe;AAEnB,WAAO;MACL,QAAQ,SAAS;QACf,IAAI,gBAGF;UACA,MAAM,YAAY;AAChB,uBAAW,QAAQ,EAAE,MAAM,gBAAgB,SAAS,CAAC;UACvD;UAEA,UAAU,OAAO,YAAY;AAC3B,gBAAI,QAAQ,kBAAkB;AAC5B,yBAAW,QAAQ,EAAE,MAAM,OAAO,UAAU,MAAM,SAAS,CAAC;YAC9D;AAGA,gBAAI,CAAC,MAAM,SAAS;AAClB,6BAAe,EAAE,SAAS,SAAS,KAAK,OAAU;AAClD,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;YACF;AAEA,kBAAM,QAAQ,MAAM;AAGpB,gBAAI,WAAW,OAAO;AACpB,6BAAe,EAAE,SAAS,SAAS,KAAK,OAAU;AAClD,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;YACF;AAEA,gBAAI,cAAc;AAChB,6BAAe;AAEf,yBAAW,QAAQ;gBACjB,MAAM;gBACN,GAAGN,qBAAoB,KAAK;cAC9B,CAAC;AAED,yBAAW,QAAQ,EAAE,MAAM,cAAc,IAAI,IAAI,CAAC;YACpD;AAEA,gBAAI,MAAM,SAAS,MAAM;AACvB,sBAAQ,MAAM;YAChB;AAEA,kBAAM,SAAS,MAAM,QAAQ,CAAC;AAE9B,iBAAI,UAAA,OAAA,SAAA,OAAQ,kBAAiB,MAAM;AACjC,6BAAe;gBACb,SAASC,uBAAsB,OAAO,aAAa;gBACnD,KAAK,OAAO;cACd;YACF;AAEA,iBAAI,UAAA,OAAA,SAAA,OAAQ,aAAY,MAAM;AAC5B,+BAAiB,OAAO,WAAW,OAAO;YAC5C;AAEA,iBAAI,UAAA,OAAA,SAAA,OAAQ,SAAQ,QAAQ,OAAO,KAAK,SAAS,GAAG;AAClD,yBAAW,QAAQ;gBACjB,MAAM;gBACN,IAAI;gBACJ,OAAO,OAAO;cAChB,CAAC;YACH;UACF;UAEA,MAAM,YAAY;AAChB,gBAAI,CAAC,cAAc;AACjB,yBAAW,QAAQ,EAAE,MAAM,YAAY,IAAI,IAAI,CAAC;YAClD;AAEA,uBAAW,QAAQ;cACjB,MAAM;cACN;cACA;cACA,OAAO,6BAA6B,KAAK;YAC3C,CAAC;UACH;QACF,CAAC;MACH;MACA,SAAS,EAAE,KAAK;MAChB,UAAU,EAAE,SAAS,gBAAgB;IACvC;EACF;AACF;AQtUO,IAAM,iCAAiCL;EAAW,MACvDC;IACEH,GAAE,OAAO;;;;;MAKP,YAAYA,GAAE,OAAO,EAAE,SAAS;;;;;MAMhC,MAAMA,GAAE,OAAO,EAAE,SAAS;IAC5B,CAAC;EACH;AACF;ACpBO,IAAM,oCAAoCE;EAAW,MAC1DC;IACEH,GAAE,OAAO;MACP,MAAMA,GAAE,MAAMA,GAAE,OAAO,EAAE,WAAWA,GAAE,MAAMA,GAAE,OAAO,CAAC,EAAE,CAAC,CAAC;MAC1D,OAAOA,GAAE,OAAO,EAAE,eAAeA,GAAE,OAAO,EAAE,CAAC,EAAE,QAAQ;IACzD,CAAC;EACH;AACF;AFMO,IAAM,uBAAN,MAAuD;EAY5D,YAAY,SAAiC,QAAsB;AAXnE,SAAS,uBAAuB;AAEhC,SAAS,uBAAuB;AAChC,SAAS,wBAAwB;AAS/B,SAAK,UAAU;AACf,SAAK,SAAS;EAChB;EAPA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAOA,MAAM,QAAQ;IACZ;IACA;IACA;IACA;EACF,GAEE;AA1CJ,QAAA;AA2CI,QAAI,OAAO,SAAS,KAAK,sBAAsB;AAC7C,YAAM,IAAI,mCAAmC;QAC3C,UAAU,KAAK;QACf,SAAS,KAAK;QACd,sBAAsB,KAAK;QAC3B;MACF,CAAC;IACH;AAGA,UAAM,iBACH,KAAA,MAAMQ,qBAAqB;MAC1B,UAAU;MACV;MACA,QAAQ;IACV,CAAC,MAJA,OAAA,KAIM,CAAC;AAEV,UAAM;MACJ;MACA,OAAO;MACP;IACF,IAAI,MAAMC,cAAc;MACtB,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,OAAO;MACtD,MAAM;QACJ,OAAO,KAAK;QACZ,OAAO;QACP,iBAAiB;QACjB,YAAY,cAAc;QAC1B,MAAM,cAAc;MACtB;MACA,uBAAuB;MACvB,2BAA2BC;QACzB;MACF;MACA;MACA,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,WAAO;MACL,UAAU,CAAC;MACX,YAAY,SAAS,KAAK,IAAI,CAAA,SAAQ,KAAK,SAAS;MACpD,OAAO,SAAS,QACZ,EAAE,QAAQ,SAAS,MAAM,cAAc,IACvC;MACJ,UAAU,EAAE,SAAS,iBAAiB,MAAM,SAAS;IACvD;EACF;AACF;AIzFO,IAAM,4BAA4BT;EAAW,MAClDC;IACEH,GAAE,OAAO;MACP,SAASA,GAAE,OAAO,EAAE,QAAQ;MAC5B,MAAMA,GAAE;QACNA,GAAE,OAAO;UACP,UAAUA,GAAE,OAAO;UACnB,gBAAgBA,GAAE,OAAO,EAAE,QAAQ;QACrC,CAAC;MACH;MACA,YAAYA,GAAE,OAAO,EAAE,QAAQ;MAC/B,eAAeA,GAAE,OAAO,EAAE,QAAQ;MAClC,MAAMA,GAAE,OAAO,EAAE,QAAQ;MACzB,SAASA,GAAE,OAAO,EAAE,QAAQ;MAC5B,OAAOA,GACJ,OAAO;QACN,cAAcA,GAAE,OAAO,EAAE,QAAQ;QACjC,eAAeA,GAAE,OAAO,EAAE,QAAQ;QAClC,cAAcA,GAAE,OAAO,EAAE,QAAQ;QACjC,sBAAsBA,GACnB,OAAO;UACN,cAAcA,GAAE,OAAO,EAAE,QAAQ;UACjC,aAAaA,GAAE,OAAO,EAAE,QAAQ;QAClC,CAAC,EACA,QAAQ;MACb,CAAC,EACA,QAAQ;IACb,CAAC;EACH;AACF;ACzBO,IAAM,wBAA4D;EACvE,YAAY;EACZ,YAAY;EACZ,eAAe;EACf,oBAAoB;EACpB,iBAAiB;AACnB;AAEO,IAAM,2BAA2B,oBAAI,IAAI;EAC9C;EACA;EACA;AACF,CAAC;AFQM,IAAM,mBAAN,MAA+C;EAWpD,YACW,SACQ,QACjB;AAFS,SAAA,UAAA;AACQ,SAAA,SAAA;AAZnB,SAAS,uBAAuB;EAa7B;EAXH,IAAI,mBAA2B;AAhCjC,QAAA;AAiCI,YAAO,KAAA,sBAAsB,KAAK,OAAO,MAAlC,OAAA,KAAuC;EAChD;EAEA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAOA,MAAM,WAAW;IACf;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EACF,GAEE;AA1DJ,QAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AA2DI,UAAM,WAAmC,CAAC;AAE1C,QAAI,eAAe,MAAM;AACvB,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SACE;MACJ,CAAC;IACH;AAEA,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK,EAAE,MAAM,eAAe,SAAS,OAAO,CAAC;IACxD;AAEA,UAAM,eAAc,MAAA,MAAA,KAAA,KAAK,OAAO,cAAZ,OAAA,SAAA,GAAuB,gBAAvB,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA0C,oBAAI,KAAK;AAEvE,QAAI,SAAS,MAAM;AACjB,YAAM,EAAE,OAAOa,WAAU,iBAAAC,iBAAgB,IAAI,MAAM,kBAAkB;QACnE,KAAK,KAAK,OAAO,IAAI;UACnB,MAAM;UACN,SAAS,KAAK;QAChB,CAAC;QACD,SAASJ,eAAe,KAAK,OAAO,QAAQ,GAAG,OAAO;QACtD,UAAU,kBAAwC;UAChD,OAAO,KAAK;UACZ;UACA,OAAO,MAAM,QAAQ;YACnB,MAAM;cAAI,CAAA,SACR,KAAK,SAAS,SACV,IAAI;gBACF;kBACE,KAAK,gBAAgB,aACjB,IAAI,KAAK,CAAC,KAAK,IAAgB,GAAG;oBAChC,MAAM,KAAK;kBACb,CAAC,IACD,IAAI,KAAK,CAAC,0BAA0B,KAAK,IAAI,CAAC,GAAG;oBAC/C,MAAM,KAAK;kBACb,CAAC;gBACP;gBACA,EAAE,MAAM,KAAK,UAAU;cACzB,IACA,aAAa,KAAK,GAAG;YAC3B;UACF;UACA,MAAM,QAAQ,OAAO,MAAM,WAAW,IAAI,IAAI;UAC9C;UACA;UACA,IAAI,KAAA,gBAAgB,WAAhB,OAAA,KAA0B,CAAC;QACjC,CAAC;QACD,uBAAuB;QACvB,2BAA2BC;UACzB;QACF;QACA;QACA,OAAO,KAAK,OAAO;MACrB,CAAC;AAED,aAAO;QACL,QAAQE,UAAS,KAAK,IAAI,CAAA,SAAQ,KAAK,QAAQ;QAC/C;QACA,OACEA,UAAS,SAAS,OACd;UACE,cAAa,KAAAA,UAAS,MAAM,iBAAf,OAAA,KAA+B;UAC5C,eAAc,KAAAA,UAAS,MAAM,kBAAf,OAAA,KAAgC;UAC9C,cAAa,KAAAA,UAAS,MAAM,iBAAf,OAAA,KAA+B;QAC9C,IACA;QACN,UAAU;UACR,WAAW;UACX,SAAS,KAAK;UACd,SAASC;QACX;QACA,kBAAkB;UAChB,QAAQ;YACN,QAAQD,UAAS,KAAK,IAAI,CAAA,SAAK;AAvI3C,kBAAAZ,KAAAc,KAAAC,KAAAC,KAAAC;AAuI+C,qBAAA;gBACjC,GAAI,KAAK,iBACL,EAAE,eAAe,KAAK,eAAe,IACrC,CAAC;gBACL,UAASjB,MAAAY,UAAS,YAAT,OAAAZ,MAAoB;gBAC7B,OAAMc,MAAAF,UAAS,SAAT,OAAAE,MAAiB;gBACvB,UAASC,MAAAH,UAAS,YAAT,OAAAG,MAAoB;gBAC7B,aAAYC,MAAAJ,UAAS,eAAT,OAAAI,MAAuB;gBACnC,eAAcC,MAAAL,UAAS,kBAAT,OAAAK,MAA0B;cAC1C;YAAA,CAAE;UACJ;QACF;MACF;IACF;AAEA,UAAM,EAAE,OAAO,UAAU,gBAAgB,IAAI,MAAMT,cAAc;MAC/D,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,OAAO;MACtD,MAAM;QACJ,OAAO,KAAK;QACZ;QACA;QACA;QACA,IAAI,KAAA,gBAAgB,WAAhB,OAAA,KAA0B,CAAC;QAC/B,GAAI,CAAC,yBAAyB,IAAI,KAAK,OAAO,IAC1C,EAAE,iBAAiB,WAAW,IAC9B,CAAC;MACP;MACA,uBAAuB;MACvB,2BAA2BC;QACzB;MACF;MACA;MACA,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,WAAO;MACL,QAAQ,SAAS,KAAK,IAAI,CAAA,SAAQ,KAAK,QAAQ;MAC/C;MACA,OACE,SAAS,SAAS,OACd;QACE,cAAa,KAAA,SAAS,MAAM,iBAAf,OAAA,KAA+B;QAC5C,eAAc,KAAA,SAAS,MAAM,kBAAf,OAAA,KAAgC;QAC9C,cAAa,KAAA,SAAS,MAAM,iBAAf,OAAA,KAA+B;MAC9C,IACA;MACN,UAAU;QACR,WAAW;QACX,SAAS,KAAK;QACd,SAAS;MACX;MACA,kBAAkB;QAChB,QAAQ;UACN,QAAQ,SAAS,KAAK,IAAI,CAAA,SAAK;AAhMzC,gBAAAV,KAAAc,KAAAC,KAAAC,KAAAC;AAgM6C,mBAAA;cACjC,GAAI,KAAK,iBACL,EAAE,eAAe,KAAK,eAAe,IACrC,CAAC;cACL,UAASjB,MAAA,SAAS,YAAT,OAAAA,MAAoB;cAC7B,OAAMc,MAAA,SAAS,SAAT,OAAAA,MAAiB;cACvB,UAASC,MAAA,SAAS,YAAT,OAAAA,MAAoB;cAC7B,aAAYC,MAAA,SAAS,eAAT,OAAAA,MAAuB;cACnC,eAAcC,MAAA,SAAS,kBAAT,OAAAA,MAA0B;YAC1C;UAAA,CAAE;QACJ;MACF;IACF;EACF;AACF;AAmFA,eAAe,WACb,MAC2B;AAC3B,MAAI,CAAC,KAAM,QAAO;AAElB,MAAI,KAAK,SAAS,OAAO;AACvB,WAAO,aAAa,KAAK,GAAG;EAC9B;AAEA,QAAM,OACJ,KAAK,gBAAgB,aACjB,KAAK,OACL,0BAA0B,KAAK,IAAI;AAEzC,SAAO,IAAI,KAAK,CAAC,IAAgB,GAAG,EAAE,MAAM,KAAK,UAAU,CAAC;AAC9D;AI7SO,IAAM,oCAAoChB;EAAW,MAC1DC;IACEH,GAAE,OAAO;MACP,MAAMA,GAAE,OAAO;MACf,UAAUA,GAAE,OAAO,EAAE,QAAQ;MAC7B,UAAUA,GAAE,OAAO,EAAE,QAAQ;MAC7B,OAAOA,GACJ;QACCA,GAAE,OAAO;UACP,MAAMA,GAAE,OAAO;UACf,OAAOA,GAAE,OAAO;UAChB,KAAKA,GAAE,OAAO;QAChB,CAAC;MACH,EACC,QAAQ;MACX,UAAUA,GACP;QACCA,GAAE,OAAO;UACP,IAAIA,GAAE,OAAO;UACb,MAAMA,GAAE,OAAO;UACf,OAAOA,GAAE,OAAO;UAChB,KAAKA,GAAE,OAAO;UACd,MAAMA,GAAE,OAAO;UACf,QAAQA,GAAE,MAAMA,GAAE,OAAO,CAAC;UAC1B,aAAaA,GAAE,OAAO;UACtB,aAAaA,GAAE,OAAO;UACtB,mBAAmBA,GAAE,OAAO;UAC5B,gBAAgBA,GAAE,OAAO;QAC3B,CAAC;MACH,EACC,QAAQ;IACb,CAAC;EACH;AACF;AC1BO,IAAM,qCAAqCE;EAAW,MAC3DC;IACEH,IAAE,OAAO;;;;MAKP,SAASA,IAAE,MAAMA,IAAE,OAAO,CAAC,EAAE,SAAS;;;;MAKtC,UAAUA,IAAE,OAAO,EAAE,SAAS;;;;MAK9B,QAAQA,IAAE,OAAO,EAAE,SAAS;;;;;MAM5B,aAAaA,IAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,QAAQ,CAAC,EAAE,SAAS;;;;;MAM1D,wBAAwBA,IACrB,MAAMA,IAAE,KAAK,CAAC,QAAQ,SAAS,CAAC,CAAC,EACjC,QAAQ,CAAC,SAAS,CAAC,EACnB,SAAS;IACd,CAAC;EACH;AACF;AFPA,IAAM,cAAc;EAClB,WAAW;EACX,QAAQ;EACR,UAAU;EACV,aAAa;EACb,YAAY;EACZ,SAAS;EACT,WAAW;EACX,SAAS;EACT,SAAS;EACT,UAAU;EACV,OAAO;EACP,QAAQ;EACR,OAAO;EACP,SAAS;EACT,UAAU;EACV,SAAS;EACT,QAAQ;EACR,UAAU;EACV,QAAQ;EACR,OAAO;EACP,QAAQ;EACR,OAAO;EACP,WAAW;EACX,WAAW;EACX,YAAY;EACZ,SAAS;EACT,UAAU;EACV,SAAS;EACT,QAAQ;EACR,QAAQ;EACR,SAAS;EACT,YAAY;EACZ,YAAY;EACZ,OAAO;EACP,SAAS;EACT,OAAO;EACP,QAAQ;EACR,WAAW;EACX,SAAS;EACT,QAAQ;EACR,YAAY;EACZ,UAAU;EACV,SAAS;EACT,SAAS;EACT,QAAQ;EACR,WAAW;EACX,SAAS;EACT,SAAS;EACT,SAAS;EACT,SAAS;EACT,OAAO;EACP,MAAM;EACN,SAAS;EACT,WAAW;EACX,MAAM;EACN,YAAY;EACZ,OAAO;AACT;AAEO,IAAM,2BAAN,MAA+D;EAOpE,YACW,SACQ,QACjB;AAFS,SAAA,UAAA;AACQ,SAAA,SAAA;AARnB,SAAS,uBAAuB;EAS7B;EAPH,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAOA,MAAc,QAAQ;IACpB;IACA;IACA;EACF,GAAmC;AACjC,UAAM,WAA8B,CAAC;AAGrC,UAAM,gBAAgB,MAAMQ,qBAAqB;MAC/C,UAAU;MACV;MACA,QAAQ;IACV,CAAC;AAGD,UAAM,WAAW,IAAI,SAAS;AAC9B,UAAM,OACJ,iBAAiB,aACb,IAAI,KAAK,CAAC,KAAK,CAAC,IAChB,IAAI,KAAK,CAACW,0BAA0B,KAAK,CAAC,CAAC;AAEjD,aAAS,OAAO,SAAS,KAAK,OAAO;AACrC,UAAM,gBAAgB,qBAAqB,SAAS;AACpD,aAAS;MACP;MACA,IAAI,KAAK,CAAC,IAAI,GAAG,SAAS,EAAE,MAAM,UAAU,CAAC;MAC7C,SAAS,aAAa;IACxB;AAGA,QAAI,eAAe;AACjB,YAAM,4BAA4B;QAChC,SAAS,cAAc;QACvB,UAAU,cAAc;QACxB,QAAQ,cAAc;;;QAGtB,iBAAiB;UACf;UACA;QACF,EAAE,SAAS,KAAK,OAAO,IACnB,SACA;QACJ,aAAa,cAAc;QAC3B,yBAAyB,cAAc;MACzC;AAEA,iBAAW,CAAC,KAAK,KAAK,KAAK,OAAO,QAAQ,yBAAyB,GAAG;AACpE,YAAI,SAAS,MAAM;AACjB,cAAI,MAAM,QAAQ,KAAK,GAAG;AACxB,uBAAW,QAAQ,OAAO;AACxB,uBAAS,OAAO,GAAG,GAAG,MAAM,OAAO,IAAI,CAAC;YAC1C;UACF,OAAO;AACL,qBAAS,OAAO,KAAK,OAAO,KAAK,CAAC;UACpC;QACF;MACF;IACF;AAEA,WAAO;MACL;MACA;IACF;EACF;EAEA,MAAM,WACJ,SACkE;AAlLtE,QAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AAmLI,UAAM,eAAc,MAAA,MAAA,KAAA,KAAK,OAAO,cAAZ,OAAA,SAAA,GAAuB,gBAAvB,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA0C,oBAAI,KAAK;AACvE,UAAM,EAAE,UAAU,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAEzD,UAAM;MACJ,OAAO;MACP;MACA,UAAU;IACZ,IAAI,MAAMC,kBAAkB;MAC1B,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASV,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D;MACA,uBAAuB;MACvB,2BAA2BC;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,UAAM,WACJ,SAAS,YAAY,QAAQ,SAAS,YAAY,cAC9C,YAAY,SAAS,QAAoC,IACzD;AAEN,WAAO;MACL,MAAM,SAAS;MACf,WACE,MAAA,MAAA,KAAA,SAAS,aAAT,OAAA,SAAA,GAAmB,IAAI,CAAA,aAAY;QACjC,MAAM,QAAQ;QACd,aAAa,QAAQ;QACrB,WAAW,QAAQ;MACrB,EAAA,MAJA,OAAA,MAKA,KAAA,SAAS,UAAT,OAAA,SAAA,GAAgB,IAAI,CAAA,UAAS;QAC3B,MAAM,KAAK;QACX,aAAa,KAAK;QAClB,WAAW,KAAK;MAClB,EAAA,MATA,OAAA,KAUA,CAAC;MACH;MACA,oBAAmB,KAAA,SAAS,aAAT,OAAA,KAAqB;MACxC;MACA,UAAU;QACR,WAAW;QACX,SAAS,KAAK;QACd,SAAS;QACT,MAAM;MACR;IACF;EACF;AACF;AI7NO,IAAM,oCAAoCT;EAAW,MAC1DC;IACEH,IAAE,OAAO;MACP,cAAcA,IAAE,OAAO,EAAE,QAAQ;MACjC,OAAOA,IAAE,OAAO,EAAE,IAAI,IAAI,EAAE,IAAI,CAAG,EAAE,QAAQ,CAAG,EAAE,QAAQ;IAC5D,CAAC;EACH;AACF;ADIO,IAAM,oBAAN,MAAiD;EAOtD,YACW,SACQ,QACjB;AAFS,SAAA,UAAA;AACQ,SAAA,SAAA;AARnB,SAAS,uBAAuB;EAS7B;EAPH,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAOA,MAAc,QAAQ;IACpB;IACA,QAAQ;IACR,eAAe;IACf;IACA;IACA;IACA;EACF,GAA+C;AAC7C,UAAM,WAA8B,CAAC;AAGrC,UAAM,gBAAgB,MAAMQ,qBAAqB;MAC/C,UAAU;MACV;MACA,QAAQ;IACV,CAAC;AAGD,UAAM,cAAuC;MAC3C,OAAO,KAAK;MACZ,OAAO;MACP;MACA,iBAAiB;MACjB;MACA;IACF;AAEA,QAAI,cAAc;AAChB,UAAI,CAAC,OAAO,QAAQ,OAAO,QAAQ,OAAO,KAAK,EAAE,SAAS,YAAY,GAAG;AACvE,oBAAY,kBAAkB;MAChC,OAAO;AACL,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS,8BAA8B,YAAY;QACrD,CAAC;MACH;IACF;AAGA,QAAI,eAAe;AACjB,YAAM,qBAA2C,CAAC;AAElD,iBAAW,OAAO,oBAAoB;AACpC,cAAM,QAAQ,mBAAmB,GAAiC;AAClE,YAAI,UAAU,QAAW;AACvB,sBAAY,GAAG,IAAI;QACrB;MACF;IACF;AAEA,QAAI,UAAU;AACZ,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SAAS,+EAA+E,QAAQ;MAClG,CAAC;IACH;AAEA,WAAO;MACL;MACA;IACF;EACF;EAEA,MAAM,WACJ,SAC2D;AArG/D,QAAA,IAAA,IAAA;AAsGI,UAAM,eAAc,MAAA,MAAA,KAAA,KAAK,OAAO,cAAZ,OAAA,SAAA,GAAuB,gBAAvB,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA0C,oBAAI,KAAK;AACvE,UAAM,EAAE,aAAa,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAE5D,UAAM;MACJ,OAAO;MACP;MACA,UAAU;IACZ,IAAI,MAAMC,cAAc;MACtB,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D,MAAM;MACN,uBAAuB;MACvB,2BAA2B,4BAA4B;MACvD,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,WAAO;MACL;MACA;MACA,SAAS;QACP,MAAM,KAAK,UAAU,WAAW;MAClC;MACA,UAAU;QACR,WAAW;QACX,SAAS,KAAK;QACd,SAAS;QACT,MAAM;MACR;IACF;EACF;AACF;AG3HO,SAAS,4BACd,OACsB;AAfxB,MAAA,IAAA,IAAA,IAAA;AAgBE,MAAI,SAAS,MAAM;AACjB,WAAO;MACL,aAAa;QACX,OAAO;QACP,SAAS;QACT,WAAW;QACX,YAAY;MACd;MACA,cAAc;QACZ,OAAO;QACP,MAAM;QACN,WAAW;MACb;MACA,KAAK;IACP;EACF;AAEA,QAAM,cAAc,MAAM;AAC1B,QAAM,eAAe,MAAM;AAC3B,QAAM,gBAAe,MAAA,KAAA,MAAM,yBAAN,OAAA,SAAA,GAA4B,kBAA5B,OAAA,KAA6C;AAClE,QAAM,mBAAkB,MAAA,KAAA,MAAM,0BAAN,OAAA,SAAA,GAA6B,qBAA7B,OAAA,KAAiD;AAEzE,SAAO;IACL,aAAa;MACX,OAAO;MACP,SAAS,cAAc;MACvB,WAAW;MACX,YAAY;IACd;IACA,cAAc;MACZ,OAAO;MACP,MAAM,eAAe;MACrB,WAAW;IACb;IACA,KAAK;EACP;AACF;AEvCO,IAAM,wBAAwBR;EAAW,MAC9CC;IACEH,IAAE,OAAO;MACP,QAAQA,IAAE,OAAO;MACjB,WAAWA,IAAE,mBAAmB,QAAQ;QACtCA,IAAE,OAAO;UACP,MAAMA,IAAE,QAAQ,aAAa;UAC7B,MAAMA,IAAE,OAAO;UACf,MAAMA,IAAE,OAAO;QACjB,CAAC;QACDA,IAAE,OAAO;UACP,MAAMA,IAAE,QAAQ,aAAa;UAC7B,MAAMA,IAAE,OAAO;QACjB,CAAC;QACDA,IAAE,OAAO;UACP,MAAMA,IAAE,QAAQ,aAAa;UAC7B,MAAMA,IAAE,OAAO;UACf,MAAMA,IAAE,OAAO;QACjB,CAAC;MACH,CAAC;IACH,CAAC;EACH;AACF;AAKO,IAAM,yBAAyBE;EAAW,MAC/CC;IACEH,IAAE,OAAO;MACP,QAAQA,IAAE,KAAK,CAAC,aAAa,QAAQ,CAAC;MACtC,QAAQA,IAAE,OAAO,EAAE,SAAS;IAC9B,CAAC;EACH;AACF;AAMO,IAAM,uBAAuBE,WAAW,MAAMC,UAAUH,IAAE,OAAO,CAAC,CAAC,CAAC,CAAC;AA+CrE,IAAM,wBAAwB,0CA4BnC;EACA,IAAI;EACJ,aAAa;EACb,cAAc;AAChB,CAAC;AC7HM,IAAM,wBAAwBqB;EAAW,MAC9CC;IACEC,IAAE,OAAO;MACP,QAAQA,IAAE,OAAO;QACf,MAAMA,IAAE,QAAQ,MAAM;QACtB,SAASA,IAAE,MAAMA,IAAE,OAAO,CAAC;QAC3B,WAAWA,IAAE,OAAO,EAAE,SAAS;QAC/B,MAAMA,IAAE,OAAO,EAAE,SAAS;QAC1B,kBAAkBA,IAAE,OAAO,EAAE,SAAS;QACtC,KAAKA,IAAE,OAAOA,IAAE,OAAO,GAAGA,IAAE,OAAO,CAAC,EAAE,SAAS;MACjD,CAAC;IACH,CAAC;EACH;AACF;AAEO,IAAM,yBAAyBF;EAAW,MAC/CC,UAAUC,IAAE,OAAO,EAAE,QAAQA,IAAE,OAAO,EAAE,CAAC,CAAC;AAC5C;AAEO,IAAM,aAAaC,0CAyCxB;EACA,IAAI;EACJ,aAAa;EACb,cAAc;AAChB,CAAC;AChEM,IAAM,mBAAmBH;EAAW,MACzCC;IACEC,IAAE,OAAO;MACP,QAAQA,IAAE,OAAO;QACf,UAAUA,IAAE,MAAMA,IAAE,OAAO,CAAC;QAC5B,WAAWA,IAAE,OAAO,EAAE,SAAS;QAC/B,iBAAiBA,IAAE,OAAO,EAAE,SAAS;MACvC,CAAC;IACH,CAAC;EACH;AACF;AAEO,IAAM,oBAAoBF;EAAW,MAC1CC;IACEC,IAAE,OAAO;MACP,QAAQA,IAAE;QACRA,IAAE,OAAO;UACP,QAAQA,IAAE,OAAO;UACjB,QAAQA,IAAE,OAAO;UACjB,SAASA,IAAE,mBAAmB,QAAQ;YACpCA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,SAAS,EAAE,CAAC;YACvCA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,MAAM,GAAG,UAAUA,IAAE,OAAO,EAAE,CAAC;UAC5D,CAAC;QACH,CAAC;MACH;IACF,CAAC;EACH;AACF;AAEO,IAAM,QAAQC,0CA4CnB;EACA,IAAI;EACJ,aAAa;EACb,cAAc;AAChB,CAAC;AHtDD,SAAS,SAAS,MAAc,UAAuC;AACrE,MAAI,CAAC,SAAU,QAAO;AACtB,SAAO,SAAS,KAAK,CAAA,WAAU,KAAK,WAAW,MAAM,CAAC;AACxD;AAEA,eAAsB,8BAA8B;EAClD;EACA;EACA;EACA;EACA;EACA,oBAAoB;EACpB,eAAe;EACf,oBAAoB;AACtB,GAYG;AAxDH,MAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AAyDE,QAAM,QAA8B,CAAC;AACrC,QAAM,WAAmC,CAAC;AAC1C,QAAM,uBAAuB,oBAAI,IAAY;AAE7C,aAAW,EAAE,MAAM,QAAQ,KAAK,QAAQ;AACtC,YAAQ,MAAM;MACZ,KAAK,UAAU;AACb,gBAAQ,mBAAmB;UACzB,KAAK,UAAU;AACb,kBAAM,KAAK,EAAE,MAAM,UAAU,QAAQ,CAAC;AACtC;UACF;UACA,KAAK,aAAa;AAChB,kBAAM,KAAK,EAAE,MAAM,aAAa,QAAQ,CAAC;AACzC;UACF;UACA,KAAK,UAAU;AACb,qBAAS,KAAK;cACZ,MAAM;cACN,SAAS;YACX,CAAC;AACD;UACF;UACA,SAAS;AACP,kBAAM,mBAA0B;AAChC,kBAAM,IAAI;cACR,oCAAoC,gBAAgB;YACtD;UACF;QACF;AACA;MACF;MAEA,KAAK,QAAQ;AACX,cAAM,KAAK;UACT,MAAM;UACN,SAAS,QAAQ,IAAI,CAAC,MAAM,UAAU;AA7FhD,gBAAAC,KAAAC,KAAAC;AA8FY,oBAAQ,KAAK,MAAM;cACjB,KAAK,QAAQ;AACX,uBAAO,EAAE,MAAM,cAAc,MAAM,KAAK,KAAK;cAC/C;cACA,KAAK,QAAQ;AACX,oBAAI,KAAK,UAAU,WAAW,QAAQ,GAAG;AACvC,wBAAM,YACJ,KAAK,cAAc,YACf,eACA,KAAK;AAEX,yBAAO;oBACL,MAAM;oBACN,GAAI,KAAK,gBAAgB,MACrB,EAAE,WAAW,KAAK,KAAK,SAAS,EAAE,IAClC,OAAO,KAAK,SAAS,YACnB,SAAS,KAAK,MAAM,cAAc,IAClC,EAAE,SAAS,KAAK,KAAK,IACrB;sBACE,WAAW,QAAQ,SAAS,WAAWC,gBAAgB,KAAK,IAAI,CAAC;oBACnE;oBACN,SAAQF,OAAAD,MAAA,KAAK,oBAAL,OAAA,SAAAA,IAAsB,WAAtB,OAAA,SAAAC,IAA8B;kBACxC;gBACF,WAAW,KAAK,cAAc,mBAAmB;AAC/C,sBAAI,KAAK,gBAAgB,KAAK;AAC5B,2BAAO;sBACL,MAAM;sBACN,UAAU,KAAK,KAAK,SAAS;oBAC/B;kBACF;AACA,yBAAO;oBACL,MAAM;oBACN,GAAI,OAAO,KAAK,SAAS,YACzB,SAAS,KAAK,MAAM,cAAc,IAC9B,EAAE,SAAS,KAAK,KAAK,IACrB;sBACE,WAAUC,MAAA,KAAK,aAAL,OAAAA,MAAiB,QAAQ,KAAK;sBACxC,WAAW,+BAA+BC,gBAAgB,KAAK,IAAI,CAAC;oBACtE;kBACN;gBACF,OAAO;AACL,wBAAM,IAAIC,8BAA8B;oBACtC,eAAe,wBAAwB,KAAK,SAAS;kBACvD,CAAC;gBACH;cACF;YACF;UACF,CAAC;QACH,CAAC;AAED;MACF;MAEA,KAAK,aAAa;AAChB,cAAM,oBAA8D,CAAC;AAErE,mBAAW,QAAQ,SAAS;AAC1B,kBAAQ,KAAK,MAAM;YACjB,KAAK,QAAQ;AACX,oBAAM,MAAK,MAAA,KAAA,KAAK,oBAAL,OAAA,SAAA,GAAsB,WAAtB,OAAA,SAAA,GAA8B;AAKzC,kBAAI,SAAS,MAAM,MAAM;AACvB,sBAAM,KAAK,EAAE,MAAM,kBAAkB,GAAG,CAAC;AACzC;cACF;AAEA,oBAAM,KAAK;gBACT,MAAM;gBACN,SAAS,CAAC,EAAE,MAAM,eAAe,MAAM,KAAK,KAAK,CAAC;gBAClD;cACF,CAAC;AAED;YACF;YACA,KAAK,aAAa;AAChB,oBAAM,MAAM,MAAA,MAAA,KAAA,KAAK,oBAAL,OAAA,SAAA,GAAsB,WAAtB,OAAA,SAAA,GAA8B,WAA9B,OAAA,MAER,MAAA,KAAA,KAGA,qBAHA,OAAA,SAAA,GAGkB,WAHlB,OAAA,SAAA,GAG0B;AAC9B,kBAAI,KAAK,kBAAkB;AACzB,oBAAI,SAAS,MAAM,MAAM;AACvB,wBAAM,KAAK,EAAE,MAAM,kBAAkB,GAAG,CAAC;gBAC3C;AACA;cACF;AAEA,kBAAI,SAAS,MAAM,MAAM;AACvB,sBAAM,KAAK,EAAE,MAAM,kBAAkB,GAAG,CAAC;AACzC;cACF;AAEA,oBAAM,mBAAmB,gBAAgB;gBACvC,KAAK;cACP;AAEA,kBAAI,qBAAqB,qBAAqB,eAAe;AAC3D,sBAAM,cAAc,MAAM,cAAc;kBACtC,OAAO,KAAK;kBACZ,QAAQ;gBACV,CAAC;AACD,sBAAM,KAAK;kBACT,MAAM;kBACN,SAAS,KAAK;kBACd;kBACA,QAAQ;oBACN,MAAM;oBACN,SAAS,YAAY,OAAO;oBAC5B,YAAY,YAAY,OAAO;oBAC/B,MAAM,YAAY,OAAO;oBACzB,mBAAmB,YAAY,OAAO;oBACtC,KAAK,YAAY,OAAO;kBAC1B;gBACF,CAAC;AAED;cACF;AAEA,kBAAI,gBAAgB,qBAAqB,SAAS;AAChD,sBAAM,cAAc,MAAM,cAAc;kBACtC,OAAO,KAAK;kBACZ,QAAQ;gBACV,CAAC;AACD,sBAAM,KAAK;kBACT,MAAM;kBACN,SAAS,KAAK;kBACd;kBACA,QAAQ;kBACR,QAAQ;oBACN,UAAU,YAAY,OAAO;oBAC7B,YAAY,YAAY,OAAO;oBAC/B,mBAAmB,YAAY,OAAO;kBACxC;gBACF,CAAC;AAED;cACF;AAEA,oBAAM,KAAK;gBACT,MAAM;gBACN,SAAS,KAAK;gBACd,MAAM;gBACN,WAAW,KAAK,UAAU,KAAK,KAAK;gBACpC;cACF,CAAC;AACD;YACF;;YAGA,KAAK,eAAe;AAIlB,kBACE,KAAK,OAAO,SAAS,sBACpB,KAAK,OAAO,SAAS,UACpB,OAAO,KAAK,OAAO,UAAU,YAC7B,KAAK,OAAO,SAAS,QACrB,UAAU,KAAK,OAAO,SACtB,KAAK,OAAO,MAAM,SAAS,oBAC7B;AACA;cACF;AAEA,kBAAI,OAAO;AACT,sBAAM,UAEF,MAAA,MAAA,KAAA,KAGA,qBAHA,OAAA,SAAA,GAGkB,WAHlB,OAAA,SAAA,GAG0B,WAH1B,OAAA,KAGoC,KAAK;AAC7C,sBAAM,KAAK,EAAE,MAAM,kBAAkB,IAAI,OAAO,CAAC;cACnD,OAAO;AACL,yBAAS,KAAK;kBACZ,MAAM;kBACN,SAAS,2BAA2B,KAAK,QAAQ;gBACnD,CAAC;cACH;AAEA;YACF;YAEA,KAAK,aAAa;AAChB,oBAAM,kBAAkB,MAAMC,qBAAqB;gBACjD,UAAU;gBACV,iBAAiB,KAAK;gBACtB,QAAQ;cACV,CAAC;AAED,oBAAM,cAAc,mBAAA,OAAA,SAAA,gBAAiB;AAErC,kBAAI,eAAe,MAAM;AACvB,sBAAM,mBAAmB,kBAAkB,WAAW;AAEtD,oBAAI,OAAO;AAGT,sBAAI,qBAAqB,QAAW;AAClC,0BAAM,KAAK,EAAE,MAAM,kBAAkB,IAAI,YAAY,CAAC;AAGtD,sCAAkB,WAAW,IAAI;sBAC/B,MAAM;sBACN,IAAI;sBACJ,SAAS,CAAC;oBACZ;kBACF;gBACF,OAAO;AACL,wBAAM,eAGD,CAAC;AAEN,sBAAI,KAAK,KAAK,SAAS,GAAG;AACxB,iCAAa,KAAK;sBAChB,MAAM;sBACN,MAAM,KAAK;oBACb,CAAC;kBACH,WAAW,qBAAqB,QAAW;AACzC,6BAAS,KAAK;sBACZ,MAAM;sBACN,SAAS,+FAA+F,KAAK,UAAU,IAAI,CAAC;oBAC9H,CAAC;kBACH;AAEA,sBAAI,qBAAqB,QAAW;AAClC,sCAAkB,WAAW,IAAI;sBAC/B,MAAM;sBACN,IAAI;sBACJ,mBACE,mBAAA,OAAA,SAAA,gBAAiB;sBACnB,SAAS;oBACX;AACA,0BAAM,KAAK,kBAAkB,WAAW,CAAC;kBAC3C,OAAO;AACL,qCAAiB,QAAQ,KAAK,GAAG,YAAY;AAG7C,yBAAI,mBAAA,OAAA,SAAA,gBAAiB,8BAA6B,MAAM;AACtD,uCAAiB,oBACf,gBAAgB;oBACpB;kBACF;gBACF;cACF,OAAO;AACL,yBAAS,KAAK;kBACZ,MAAM;kBACN,SAAS,0EAA0E,KAAK,UAAU,IAAI,CAAC;gBACzG,CAAC;cACH;AACA;YACF;UACF;QACF;AAEA;MACF;MAEA,KAAK,QAAQ;AACX,mBAAW,QAAQ,SAAS;AAC1B,cAAI,KAAK,SAAS,0BAA0B;AAC1C,kBAAM,mBACJ;AAEF,gBAAI,qBAAqB,IAAI,iBAAiB,UAAU,GAAG;AACzD;YACF;AACA,iCAAqB,IAAI,iBAAiB,UAAU;AAEpD,gBAAI,OAAO;AACT,oBAAM,KAAK;gBACT,MAAM;gBACN,IAAI,iBAAiB;cACvB,CAAC;YACH;AAEA,kBAAM,KAAK;cACT,MAAM;cACN,qBAAqB,iBAAiB;cACtC,SAAS,iBAAiB;YAC5B,CAAC;AACD;UACF;AAEA,gBAAM,SAAS,KAAK;AAGpB,cAAI,OAAO,SAAS,oBAAoB;AACtC,kBAAM,cACJ,MAAA,KAAA,OAAO,oBAAP,OAAA,SAAA,GAAwB,WAAxB,OAAA,SAAA,GACC;AAEH,gBAAI,YAAY;AACd;YACF;UACF;AAEA,gBAAM,mBAAmB,gBAAgB;YACvC,KAAK;UACP;AAEA,cACE,qBACA,qBAAqB,iBACrB,OAAO,SAAS,QAChB;AACA,kBAAM,eAAe,MAAM,cAAc;cACvC,OAAO,OAAO;cACd,QAAQ;YACV,CAAC;AAED,kBAAM,KAAK;cACT,MAAM;cACN,SAAS,KAAK;cACd,QAAQ,aAAa;YACvB,CAAC;AACD;UACF;AAEA,cACE,gBACA,qBAAqB,WACrB,OAAO,SAAS,QAChB;AACA,kBAAM,eAAe,MAAM,cAAc;cACvC,OAAO,OAAO;cACd,QAAQ;YACV,CAAC;AAED,kBAAM,KAAK;cACT,MAAM;cACN,SAAS,KAAK;cACd,QAAQ,aAAa,OAAO,IAAI,CAAA,UAAS;gBACvC,QAAQ,KAAK;gBACb,QAAQ,KAAK;gBACb,SACE,KAAK,QAAQ,SAAS,YAClB,EAAE,MAAM,UAAmB,IAC3B;kBACE,MAAM;kBACN,WAAW,KAAK,QAAQ;gBAC1B;cACR,EAAE;YACJ,CAAC;AACD;UACF;AAEA,cACE,qBACA,KAAK,aAAa,iBAClB,OAAO,SAAS,QAChB;AACA,kBAAM,eAAe,MAAM,cAAc;cACvC,OAAO,OAAO;cACd,QAAQ;YACV,CAAC;AAED,kBAAM,KAAK;cACT,MAAM;cACN,SAAS,KAAK;cACd,QAAQ,aAAa;cACrB,QAAQ,aAAa;YACvB,CAAC;AACD;UACF;AAEA,cAAI;AACJ,kBAAQ,OAAO,MAAM;YACnB,KAAK;YACL,KAAK;AACH,6BAAe,OAAO;AACtB;YACF,KAAK;AACH,8BAAe,KAAA,OAAO,WAAP,OAAA,KAAiB;AAChC;YACF,KAAK;YACL,KAAK;AACH,6BAAe,KAAK,UAAU,OAAO,KAAK;AAC1C;YACF,KAAK;AACH,6BAAe,OAAO,MACnB,IAAI,CAAA,SAAQ;AA/d7B,oBAAAL;AAgekB,wBAAQ,KAAK,MAAM;kBACjB,KAAK,QAAQ;AACX,2BAAO,EAAE,MAAM,cAAuB,MAAM,KAAK,KAAK;kBACxD;kBAEA,KAAK,cAAc;AACjB,2BAAO;sBACL,MAAM;sBACN,WAAW,QAAQ,KAAK,SAAS,WAAW,KAAK,IAAI;oBACvD;kBACF;kBAEA,KAAK,aAAa;AAChB,2BAAO;sBACL,MAAM;sBACN,WAAUA,MAAA,KAAK,aAAL,OAAAA,MAAiB;sBAC3B,WAAW,QAAQ,KAAK,SAAS,WAAW,KAAK,IAAI;oBACvD;kBACF;kBAEA,SAAS;AACP,6BAAS,KAAK;sBACZ,MAAM;sBACN,SAAS,uCAAuC,KAAK,IAAI;oBAC3D,CAAC;AACD,2BAAO;kBACT;gBACF;cACF,CAAC,EACA,OAAO,aAAa;AACvB;UACJ;AAEA,gBAAM,KAAK;YACT,MAAM;YACN,SAAS,KAAK;YACd,QAAQ;UACV,CAAC;QACH;AAEA;MACF;MAEA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;MACzD;IACF;EACF;AAEA,SAAO,EAAE,OAAO,SAAS;AAC3B;AAEA,IAAM,gDAAgDF,IAAE,OAAO;EAC7D,QAAQA,IAAE,OAAO,EAAE,QAAQ;EAC3B,2BAA2BA,IAAE,OAAO,EAAE,QAAQ;AAChD,CAAC;AIthBM,SAAS,8BAA8B;EAC5C;EACA;AACF,GAI2C;AACzC,UAAQ,cAAc;IACpB,KAAK;IACL,KAAK;AACH,aAAO,kBAAkB,eAAe;IAC1C,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT;AACE,aAAO,kBAAkB,eAAe;EAC5C;AACF;ACiUO,IAAM,6BAA6BF;EAAW,MACnDC;IACEC,IAAE,MAAM;MACNA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,4BAA4B;QAC5C,SAASA,IAAE,OAAO;QAClB,OAAOA,IAAE,OAAO;QAChB,UAAUA,IACP;UACCA,IAAE,OAAO;YACP,OAAOA,IAAE,OAAO;YAChB,SAASA,IAAE,OAAO;YAClB,cAAcA,IAAE;cACdA,IAAE,OAAO;gBACP,OAAOA,IAAE,OAAO;gBAChB,SAASA,IAAE,OAAO;cACpB,CAAC;YACH;UACF,CAAC;QACH,EACC,QAAQ;MACb,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,KAAK,CAAC,sBAAsB,qBAAqB,CAAC;QAC1D,UAAUA,IAAE,OAAO;UACjB,oBAAoBA,IAAE,OAAO,EAAE,QAAQA,IAAE,OAAO,EAAE,CAAC,EAAE,QAAQ;UAC7D,OAAOA,IAAE,OAAO;YACd,cAAcA,IAAE,OAAO;YACvB,sBAAsBA,IACnB,OAAO,EAAE,eAAeA,IAAE,OAAO,EAAE,QAAQ,EAAE,CAAC,EAC9C,QAAQ;YACX,eAAeA,IAAE,OAAO;YACxB,uBAAuBA,IACpB,OAAO,EAAE,kBAAkBA,IAAE,OAAO,EAAE,QAAQ,EAAE,CAAC,EACjD,QAAQ;UACb,CAAC;UACD,cAAcA,IAAE,OAAO,EAAE,QAAQ;QACnC,CAAC;MACH,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,kBAAkB;QAClC,UAAUA,IAAE,OAAO;UACjB,IAAIA,IAAE,OAAO;UACb,YAAYA,IAAE,OAAO;UACrB,OAAOA,IAAE,OAAO;UAChB,cAAcA,IAAE,OAAO,EAAE,QAAQ;QACnC,CAAC;MACH,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,4BAA4B;QAC5C,cAAcA,IAAE,OAAO;QACvB,MAAMA,IAAE,mBAAmB,QAAQ;UACjCA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,SAAS;YACzB,IAAIA,IAAE,OAAO;UACf,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,WAAW;YAC3B,IAAIA,IAAE,OAAO;YACb,mBAAmBA,IAAE,OAAO,EAAE,QAAQ;UACxC,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,eAAe;YAC/B,IAAIA,IAAE,OAAO;YACb,SAASA,IAAE,OAAO;YAClB,MAAMA,IAAE,OAAO;YACf,WAAWA,IAAE,OAAO;UACtB,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,iBAAiB;YACjC,IAAIA,IAAE,OAAO;YACb,QAAQA,IAAE,OAAO;UACnB,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,eAAe;YAC/B,IAAIA,IAAE,OAAO;YACb,QAAQA,IAAE,OAAO;UACnB,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,kBAAkB;YAClC,IAAIA,IAAE,OAAO;UACf,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,uBAAuB;YACvC,IAAIA,IAAE,OAAO;UACf,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,uBAAuB;YACvC,IAAIA,IAAE,OAAO;YACb,cAAcA,IAAE,OAAO;YACvB,MAAMA,IAAE,OAAO,EAAE,SAAS;YAC1B,SAASA,IACN;cACCA,IAAE,mBAAmB,QAAQ;gBAC3BA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,MAAM,GAAG,MAAMA,IAAE,OAAO,EAAE,CAAC;gBACtDA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,OAAO,GAAG,KAAKA,IAAE,OAAO,EAAE,CAAC;cACxD,CAAC;YACH,EACC,SAAS;YACZ,QAAQA,IAAE,OAAO;UACnB,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,UAAU;YAC1B,IAAIA,IAAE,OAAO;YACb,QAAQA,IAAE,OAAO;YACjB,qBAAqBA,IAAE,OAAO,EAAE,QAAQ;UAC1C,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,gBAAgB;YAChC,IAAIA,IAAE,OAAO;UACf,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,sBAAsB;YACtC,IAAIA,IAAE,OAAO;UACf,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,kBAAkB;YAClC,IAAIA,IAAE,OAAO;YACb,SAASA,IAAE,OAAO;YAClB,QAAQA,IAAE,KAAK,CAAC,eAAe,WAAW,CAAC;YAC3C,WAAWA,IAAE,mBAAmB,QAAQ;cACtCA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,aAAa;gBAC7B,MAAMA,IAAE,OAAO;gBACf,MAAMA,IAAE,OAAO;cACjB,CAAC;cACDA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,aAAa;gBAC7B,MAAMA,IAAE,OAAO;cACjB,CAAC;cACDA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,aAAa;gBAC7B,MAAMA,IAAE,OAAO;gBACf,MAAMA,IAAE,OAAO;cACjB,CAAC;YACH,CAAC;UACH,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,YAAY;YAC5B,IAAIA,IAAE,OAAO;YACb,SAASA,IAAE,OAAO;YAClB,QAAQA,IAAE,KAAK,CAAC,eAAe,aAAa,YAAY,CAAC;YACzD,QAAQA,IAAE,OAAO;cACf,UAAUA,IAAE,MAAMA,IAAE,OAAO,CAAC;YAC9B,CAAC;UACH,CAAC;QACH,CAAC;MACH,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,2BAA2B;QAC3C,cAAcA,IAAE,OAAO;QACvB,MAAMA,IAAE,mBAAmB,QAAQ;UACjCA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,SAAS;YACzB,IAAIA,IAAE,OAAO;UACf,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,WAAW;YAC3B,IAAIA,IAAE,OAAO;YACb,mBAAmBA,IAAE,OAAO,EAAE,QAAQ;UACxC,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,eAAe;YAC/B,IAAIA,IAAE,OAAO;YACb,SAASA,IAAE,OAAO;YAClB,MAAMA,IAAE,OAAO;YACf,WAAWA,IAAE,OAAO;YACpB,QAAQA,IAAE,QAAQ,WAAW;UAC/B,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,uBAAuB;YACvC,IAAIA,IAAE,OAAO;YACb,MAAMA,IAAE,OAAO,EAAE,SAAS;YAC1B,cAAcA,IAAE,OAAO;YACvB,SAASA,IACN;cACCA,IAAE,mBAAmB,QAAQ;gBAC3BA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,MAAM,GAAG,MAAMA,IAAE,OAAO,EAAE,CAAC;gBACtDA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,OAAO,GAAG,KAAKA,IAAE,OAAO,EAAE,CAAC;cACxD,CAAC;YACH,EACC,SAAS;UACd,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,uBAAuB;YACvC,IAAIA,IAAE,OAAO;YACb,QAAQA,IAAE,OAAO;UACnB,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,iBAAiB;YACjC,IAAIA,IAAE,OAAO;YACb,QAAQA,IAAE,OAAO;YACjB,QAAQA,IAAE,mBAAmB,QAAQ;cACnCA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,QAAQ;gBACxB,OAAOA,IAAE,OAAO,EAAE,QAAQ;gBAC1B,SAASA,IACN;kBACCA,IAAE,mBAAmB,QAAQ;oBAC3BA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,KAAK,GAAG,KAAKA,IAAE,OAAO,EAAE,CAAC;oBACpDA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,KAAK,GAAG,MAAMA,IAAE,OAAO,EAAE,CAAC;kBACvD,CAAC;gBACH,EACC,QAAQ;cACb,CAAC;cACDA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,WAAW;gBAC3B,KAAKA,IAAE,OAAO,EAAE,QAAQ;cAC1B,CAAC;cACDA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,cAAc;gBAC9B,KAAKA,IAAE,OAAO,EAAE,QAAQ;gBACxB,SAASA,IAAE,OAAO,EAAE,QAAQ;cAC9B,CAAC;YACH,CAAC;UACH,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,kBAAkB;YAClC,IAAIA,IAAE,OAAO;YACb,SAASA,IAAE,MAAMA,IAAE,OAAO,CAAC;YAC3B,SAASA,IACN;cACCA,IAAE,OAAO;gBACP,YAAYA,IAAE;kBACZA,IAAE,OAAO;kBACTA,IAAE,MAAM,CAACA,IAAE,OAAO,GAAGA,IAAE,OAAO,GAAGA,IAAE,QAAQ,CAAC,CAAC;gBAC/C;gBACA,SAASA,IAAE,OAAO;gBAClB,UAAUA,IAAE,OAAO;gBACnB,OAAOA,IAAE,OAAO;gBAChB,MAAMA,IAAE,OAAO;cACjB,CAAC;YACH,EACC,QAAQ;UACb,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,kBAAkB;YAClC,IAAIA,IAAE,OAAO;YACb,SAASA,IAAE,OAAO;YAClB,QAAQA,IAAE,OAAO;cACf,MAAMA,IAAE,QAAQ,MAAM;cACtB,SAASA,IAAE,MAAMA,IAAE,OAAO,CAAC;cAC3B,YAAYA,IAAE,OAAO,EAAE,SAAS;cAChC,MAAMA,IAAE,OAAO,EAAE,SAAS;cAC1B,mBAAmBA,IAAE,OAAO,EAAE,SAAS;cACvC,KAAKA,IAAE,OAAOA,IAAE,OAAO,GAAGA,IAAE,OAAO,CAAC,EAAE,SAAS;YACjD,CAAC;UACH,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,eAAe;YAC/B,IAAIA,IAAE,OAAO;YACb,QAAQA,IAAE,QAAQ,WAAW;UAC/B,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,UAAU;YAC1B,IAAIA,IAAE,OAAO;YACb,QAAQA,IAAE,OAAO;YACjB,WAAWA,IAAE,OAAO;YACpB,MAAMA,IAAE,OAAO;YACf,cAAcA,IAAE,OAAO;YACvB,QAAQA,IAAE,OAAO,EAAE,QAAQ;YAC3B,OAAOA,IACJ,MAAM;cACLA,IAAE,OAAO;cACTA,IACG,OAAO;gBACN,MAAMA,IAAE,OAAO,EAAE,SAAS;gBAC1B,MAAMA,IAAE,MAAM,CAACA,IAAE,OAAO,GAAGA,IAAE,OAAO,CAAC,CAAC,EAAE,SAAS;gBACjD,SAASA,IAAE,OAAO,EAAE,SAAS;cAC/B,CAAC,EACA,MAAM;YACX,CAAC,EACA,QAAQ;YACX,qBAAqBA,IAAE,OAAO,EAAE,QAAQ;UAC1C,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,gBAAgB;YAChC,IAAIA,IAAE,OAAO;YACb,cAAcA,IAAE,OAAO;YACvB,OAAOA,IAAE;cACPA,IAAE,OAAO;gBACP,MAAMA,IAAE,OAAO;gBACf,aAAaA,IAAE,OAAO,EAAE,SAAS;gBACjC,cAAcA,IAAE,IAAI;gBACpB,aAAaA,IAAE,OAAOA,IAAE,OAAO,GAAGA,IAAE,QAAQ,CAAC,EAAE,SAAS;cAC1D,CAAC;YACH;YACA,OAAOA,IACJ,MAAM;cACLA,IAAE,OAAO;cACTA,IACG,OAAO;gBACN,MAAMA,IAAE,OAAO,EAAE,SAAS;gBAC1B,MAAMA,IAAE,MAAM,CAACA,IAAE,OAAO,GAAGA,IAAE,OAAO,CAAC,CAAC,EAAE,SAAS;gBACjD,SAASA,IAAE,OAAO,EAAE,SAAS;cAC/B,CAAC,EACA,MAAM;YACX,CAAC,EACA,SAAS;UACd,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,sBAAsB;YACtC,IAAIA,IAAE,OAAO;YACb,cAAcA,IAAE,OAAO;YACvB,MAAMA,IAAE,OAAO;YACf,WAAWA,IAAE,OAAO;YACpB,qBAAqBA,IAAE,OAAO,EAAE,SAAS;UAC3C,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,kBAAkB;YAClC,IAAIA,IAAE,OAAO;YACb,SAASA,IAAE,OAAO;YAClB,QAAQA,IAAE,KAAK,CAAC,eAAe,WAAW,CAAC;YAC3C,WAAWA,IAAE,mBAAmB,QAAQ;cACtCA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,aAAa;gBAC7B,MAAMA,IAAE,OAAO;gBACf,MAAMA,IAAE,OAAO;cACjB,CAAC;cACDA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,aAAa;gBAC7B,MAAMA,IAAE,OAAO;cACjB,CAAC;cACDA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,aAAa;gBAC7B,MAAMA,IAAE,OAAO;gBACf,MAAMA,IAAE,OAAO;cACjB,CAAC;YACH,CAAC;UACH,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,YAAY;YAC5B,IAAIA,IAAE,OAAO;YACb,SAASA,IAAE,OAAO;YAClB,QAAQA,IAAE,KAAK,CAAC,eAAe,aAAa,YAAY,CAAC;YACzD,QAAQA,IAAE,OAAO;cACf,UAAUA,IAAE,MAAMA,IAAE,OAAO,CAAC;YAC9B,CAAC;UACH,CAAC;QACH,CAAC;MACH,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,wCAAwC;QACxD,SAASA,IAAE,OAAO;QAClB,cAAcA,IAAE,OAAO;QACvB,OAAOA,IAAE,OAAO;MAClB,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,8CAA8C;QAC9D,SAASA,IAAE,OAAO;QAClB,cAAcA,IAAE,OAAO;QACvB,mBAAmBA,IAAE,OAAO;MAC9B,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,2CAA2C;QAC3D,SAASA,IAAE,OAAO;QAClB,cAAcA,IAAE,OAAO;QACvB,OAAOA,IAAE,OAAO;MAClB,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,0CAA0C;QAC1D,SAASA,IAAE,OAAO;QAClB,cAAcA,IAAE,OAAO;QACvB,MAAMA,IAAE,OAAO;MACjB,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,uCAAuC;QACvD,YAAYA,IAAE,mBAAmB,QAAQ;UACvCA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,cAAc;YAC9B,aAAaA,IAAE,OAAO;YACtB,WAAWA,IAAE,OAAO;YACpB,KAAKA,IAAE,OAAO;YACd,OAAOA,IAAE,OAAO;UAClB,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,eAAe;YAC/B,SAASA,IAAE,OAAO;YAClB,UAAUA,IAAE,OAAO,EAAE,QAAQ;YAC7B,OAAOA,IAAE,OAAO,EAAE,QAAQ;YAC1B,aAAaA,IAAE,OAAO,EAAE,QAAQ;YAChC,WAAWA,IAAE,OAAO,EAAE,QAAQ;YAC9B,OAAOA,IAAE,OAAO,EAAE,QAAQ;UAC5B,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,yBAAyB;YACzC,cAAcA,IAAE,OAAO;YACvB,SAASA,IAAE,OAAO;YAClB,UAAUA,IAAE,OAAO,EAAE,QAAQ;YAC7B,aAAaA,IAAE,OAAO,EAAE,QAAQ;YAChC,WAAWA,IAAE,OAAO,EAAE,QAAQ;YAC9B,OAAOA,IAAE,OAAO,EAAE,QAAQ;UAC5B,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,WAAW;YAC3B,SAASA,IAAE,OAAO;YAClB,OAAOA,IAAE,OAAO,EAAE,QAAQ;UAC5B,CAAC;QACH,CAAC;MACH,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,uCAAuC;QACvD,SAASA,IAAE,OAAO;QAClB,eAAeA,IAAE,OAAO;MAC1B,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,uCAAuC;QACvD,SAASA,IAAE,OAAO;QAClB,eAAeA,IAAE,OAAO;QACxB,OAAOA,IAAE,OAAO;MAClB,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,sCAAsC;QACtD,SAASA,IAAE,OAAO;QAClB,eAAeA,IAAE,OAAO;MAC1B,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,gDAAgD;QAChE,SAASA,IAAE,OAAO;QAClB,cAAcA,IAAE,OAAO;QACvB,OAAOA,IAAE,OAAO;QAChB,aAAaA,IAAE,OAAO,EAAE,QAAQ;MAClC,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,+CAA+C;QAC/D,SAASA,IAAE,OAAO;QAClB,cAAcA,IAAE,OAAO;QACvB,MAAMA,IAAE,OAAO;MACjB,CAAC;MACDA,IAAE,OAAO;QACP,MAAMA,IAAE,QAAQ,OAAO;QACvB,iBAAiBA,IAAE,OAAO;QAC1B,OAAOA,IAAE,OAAO;UACd,MAAMA,IAAE,OAAO;UACf,MAAMA,IAAE,OAAO;UACf,SAASA,IAAE,OAAO;UAClB,OAAOA,IAAE,OAAO,EAAE,QAAQ;QAC5B,CAAC;MACH,CAAC;MACDA,IACG,OAAO,EAAE,MAAMA,IAAE,OAAO,EAAE,CAAC,EAC3B,MAAM,EACN,UAAU,CAAA,WAAU;QACnB,MAAM;QACN,SAAS,MAAM;MACjB,EAAE;;IACN,CAAC;EACH;AACF;AAoBO,IAAM,gCAAgCF;EAAW,MACtDC;IACEC,IAAE,OAAO;MACP,IAAIA,IAAE,OAAO,EAAE,SAAS;MACxB,YAAYA,IAAE,OAAO,EAAE,SAAS;MAChC,OAAOA,IACJ,OAAO;QACN,SAASA,IAAE,OAAO;QAClB,MAAMA,IAAE,OAAO;QACf,OAAOA,IAAE,OAAO,EAAE,QAAQ;QAC1B,MAAMA,IAAE,OAAO;MACjB,CAAC,EACA,QAAQ;MACX,OAAOA,IAAE,OAAO,EAAE,SAAS;MAC3B,QAAQA,IACL;QACCA,IAAE,mBAAmB,QAAQ;UAC3BA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,SAAS;YACzB,MAAMA,IAAE,QAAQ,WAAW;YAC3B,IAAIA,IAAE,OAAO;YACb,SAASA,IAAE;cACTA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,aAAa;gBAC7B,MAAMA,IAAE,OAAO;gBACf,UAAUA,IACP;kBACCA,IAAE,OAAO;oBACP,OAAOA,IAAE,OAAO;oBAChB,SAASA,IAAE,OAAO;oBAClB,cAAcA,IAAE;sBACdA,IAAE,OAAO;wBACP,OAAOA,IAAE,OAAO;wBAChB,SAASA,IAAE,OAAO;sBACpB,CAAC;oBACH;kBACF,CAAC;gBACH,EACC,QAAQ;gBACX,aAAaA,IAAE;kBACbA,IAAE,mBAAmB,QAAQ;oBAC3BA,IAAE,OAAO;sBACP,MAAMA,IAAE,QAAQ,cAAc;sBAC9B,aAAaA,IAAE,OAAO;sBACtB,WAAWA,IAAE,OAAO;sBACpB,KAAKA,IAAE,OAAO;sBACd,OAAOA,IAAE,OAAO;oBAClB,CAAC;oBACDA,IAAE,OAAO;sBACP,MAAMA,IAAE,QAAQ,eAAe;sBAC/B,SAASA,IAAE,OAAO;sBAClB,UAAUA,IAAE,OAAO,EAAE,QAAQ;sBAC7B,OAAOA,IAAE,OAAO,EAAE,QAAQ;sBAC1B,aAAaA,IAAE,OAAO,EAAE,QAAQ;sBAChC,WAAWA,IAAE,OAAO,EAAE,QAAQ;sBAC9B,OAAOA,IAAE,OAAO,EAAE,QAAQ;oBAC5B,CAAC;oBACDA,IAAE,OAAO;sBACP,MAAMA,IAAE,QAAQ,yBAAyB;sBACzC,cAAcA,IAAE,OAAO;sBACvB,SAASA,IAAE,OAAO;sBAClB,UAAUA,IAAE,OAAO,EAAE,QAAQ;sBAC7B,aAAaA,IAAE,OAAO,EAAE,QAAQ;sBAChC,WAAWA,IAAE,OAAO,EAAE,QAAQ;sBAC9B,OAAOA,IAAE,OAAO,EAAE,QAAQ;oBAC5B,CAAC;oBACDA,IAAE,OAAO;sBACP,MAAMA,IAAE,QAAQ,WAAW;sBAC3B,SAASA,IAAE,OAAO;sBAClB,OAAOA,IAAE,OAAO,EAAE,QAAQ;oBAC5B,CAAC;kBACH,CAAC;gBACH;cACF,CAAC;YACH;UACF,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,iBAAiB;YACjC,IAAIA,IAAE,OAAO;YACb,QAAQA,IAAE,OAAO;YACjB,QAAQA,IAAE,mBAAmB,QAAQ;cACnCA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,QAAQ;gBACxB,OAAOA,IAAE,OAAO,EAAE,QAAQ;gBAC1B,SAASA,IACN;kBACCA,IAAE,mBAAmB,QAAQ;oBAC3BA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,KAAK,GAAG,KAAKA,IAAE,OAAO,EAAE,CAAC;oBACpDA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,KAAK,GAAG,MAAMA,IAAE,OAAO,EAAE,CAAC;kBACvD,CAAC;gBACH,EACC,QAAQ;cACb,CAAC;cACDA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,WAAW;gBAC3B,KAAKA,IAAE,OAAO,EAAE,QAAQ;cAC1B,CAAC;cACDA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,cAAc;gBAC9B,KAAKA,IAAE,OAAO,EAAE,QAAQ;gBACxB,SAASA,IAAE,OAAO,EAAE,QAAQ;cAC9B,CAAC;YACH,CAAC;UACH,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,kBAAkB;YAClC,IAAIA,IAAE,OAAO;YACb,SAASA,IAAE,MAAMA,IAAE,OAAO,CAAC;YAC3B,SAASA,IACN;cACCA,IAAE,OAAO;gBACP,YAAYA,IAAE;kBACZA,IAAE,OAAO;kBACTA,IAAE,MAAM,CAACA,IAAE,OAAO,GAAGA,IAAE,OAAO,GAAGA,IAAE,QAAQ,CAAC,CAAC;gBAC/C;gBACA,SAASA,IAAE,OAAO;gBAClB,UAAUA,IAAE,OAAO;gBACnB,OAAOA,IAAE,OAAO;gBAChB,MAAMA,IAAE,OAAO;cACjB,CAAC;YACH,EACC,QAAQ;UACb,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,uBAAuB;YACvC,IAAIA,IAAE,OAAO;YACb,MAAMA,IAAE,OAAO,EAAE,SAAS;YAC1B,cAAcA,IAAE,OAAO;YACvB,SAASA,IACN;cACCA,IAAE,mBAAmB,QAAQ;gBAC3BA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,MAAM,GAAG,MAAMA,IAAE,OAAO,EAAE,CAAC;gBACtDA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,OAAO,GAAG,KAAKA,IAAE,OAAO,EAAE,CAAC;cACxD,CAAC;YACH,EACC,SAAS;UACd,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,uBAAuB;YACvC,IAAIA,IAAE,OAAO;YACb,QAAQA,IAAE,OAAO;UACnB,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,kBAAkB;YAClC,IAAIA,IAAE,OAAO;YACb,SAASA,IAAE,OAAO;YAClB,QAAQA,IAAE,OAAO;cACf,MAAMA,IAAE,QAAQ,MAAM;cACtB,SAASA,IAAE,MAAMA,IAAE,OAAO,CAAC;cAC3B,YAAYA,IAAE,OAAO,EAAE,SAAS;cAChC,MAAMA,IAAE,OAAO,EAAE,SAAS;cAC1B,mBAAmBA,IAAE,OAAO,EAAE,SAAS;cACvC,KAAKA,IAAE,OAAOA,IAAE,OAAO,GAAGA,IAAE,OAAO,CAAC,EAAE,SAAS;YACjD,CAAC;UACH,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,eAAe;YAC/B,SAASA,IAAE,OAAO;YAClB,MAAMA,IAAE,OAAO;YACf,WAAWA,IAAE,OAAO;YACpB,IAAIA,IAAE,OAAO;UACf,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,eAAe;YAC/B,IAAIA,IAAE,OAAO;YACb,QAAQA,IAAE,OAAO,EAAE,SAAS;UAC9B,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,WAAW;YAC3B,IAAIA,IAAE,OAAO;YACb,mBAAmBA,IAAE,OAAO,EAAE,QAAQ;YACtC,SAASA,IAAE;cACTA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,cAAc;gBAC9B,MAAMA,IAAE,OAAO;cACjB,CAAC;YACH;UACF,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,UAAU;YAC1B,IAAIA,IAAE,OAAO;YACb,QAAQA,IAAE,OAAO;YACjB,WAAWA,IAAE,OAAO;YACpB,MAAMA,IAAE,OAAO;YACf,cAAcA,IAAE,OAAO;YACvB,QAAQA,IAAE,OAAO,EAAE,QAAQ;YAC3B,OAAOA,IACJ,MAAM;cACLA,IAAE,OAAO;cACTA,IACG,OAAO;gBACN,MAAMA,IAAE,OAAO,EAAE,SAAS;gBAC1B,MAAMA,IAAE,MAAM,CAACA,IAAE,OAAO,GAAGA,IAAE,OAAO,CAAC,CAAC,EAAE,SAAS;gBACjD,SAASA,IAAE,OAAO,EAAE,SAAS;cAC/B,CAAC,EACA,MAAM;YACX,CAAC,EACA,QAAQ;YACX,qBAAqBA,IAAE,OAAO,EAAE,QAAQ;UAC1C,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,gBAAgB;YAChC,IAAIA,IAAE,OAAO;YACb,cAAcA,IAAE,OAAO;YACvB,OAAOA,IAAE;cACPA,IAAE,OAAO;gBACP,MAAMA,IAAE,OAAO;gBACf,aAAaA,IAAE,OAAO,EAAE,SAAS;gBACjC,cAAcA,IAAE,IAAI;gBACpB,aAAaA,IAAE,OAAOA,IAAE,OAAO,GAAGA,IAAE,QAAQ,CAAC,EAAE,SAAS;cAC1D,CAAC;YACH;YACA,OAAOA,IACJ,MAAM;cACLA,IAAE,OAAO;cACTA,IACG,OAAO;gBACN,MAAMA,IAAE,OAAO,EAAE,SAAS;gBAC1B,MAAMA,IAAE,MAAM,CAACA,IAAE,OAAO,GAAGA,IAAE,OAAO,CAAC,CAAC,EAAE,SAAS;gBACjD,SAASA,IAAE,OAAO,EAAE,SAAS;cAC/B,CAAC,EACA,MAAM;YACX,CAAC,EACA,SAAS;UACd,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,sBAAsB;YACtC,IAAIA,IAAE,OAAO;YACb,cAAcA,IAAE,OAAO;YACvB,MAAMA,IAAE,OAAO;YACf,WAAWA,IAAE,OAAO;YACpB,qBAAqBA,IAAE,OAAO,EAAE,SAAS;UAC3C,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,kBAAkB;YAClC,IAAIA,IAAE,OAAO;YACb,SAASA,IAAE,OAAO;YAClB,QAAQA,IAAE,KAAK,CAAC,eAAe,WAAW,CAAC;YAC3C,WAAWA,IAAE,mBAAmB,QAAQ;cACtCA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,aAAa;gBAC7B,MAAMA,IAAE,OAAO;gBACf,MAAMA,IAAE,OAAO;cACjB,CAAC;cACDA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,aAAa;gBAC7B,MAAMA,IAAE,OAAO;cACjB,CAAC;cACDA,IAAE,OAAO;gBACP,MAAMA,IAAE,QAAQ,aAAa;gBAC7B,MAAMA,IAAE,OAAO;gBACf,MAAMA,IAAE,OAAO;cACjB,CAAC;YACH,CAAC;UACH,CAAC;UACDA,IAAE,OAAO;YACP,MAAMA,IAAE,QAAQ,YAAY;YAC5B,IAAIA,IAAE,OAAO;YACb,SAASA,IAAE,OAAO;YAClB,QAAQA,IAAE,KAAK,CAAC,eAAe,aAAa,YAAY,CAAC;YACzD,QAAQA,IAAE,OAAO;cACf,UAAUA,IAAE,MAAMA,IAAE,OAAO,CAAC;YAC9B,CAAC;UACH,CAAC;QACH,CAAC;MACH,EACC,SAAS;MACZ,cAAcA,IAAE,OAAO,EAAE,QAAQ;MACjC,oBAAoBA,IAAE,OAAO,EAAE,QAAQA,IAAE,OAAO,EAAE,CAAC,EAAE,QAAQ;MAC7D,OAAOA,IACJ,OAAO;QACN,cAAcA,IAAE,OAAO;QACvB,sBAAsBA,IACnB,OAAO,EAAE,eAAeA,IAAE,OAAO,EAAE,QAAQ,EAAE,CAAC,EAC9C,QAAQ;QACX,eAAeA,IAAE,OAAO;QACxB,uBAAuBA,IACpB,OAAO,EAAE,kBAAkBA,IAAE,OAAO,EAAE,QAAQ,EAAE,CAAC,EACjD,QAAQ;MACb,CAAC,EACA,SAAS;IACd,CAAC;EACH;AACF;AC3jCO,IAAM,mBAAmB;AAEzB,IAAM,mCAAmC;EAC9C;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;AACF;AAEO,IAAM,0BAA0B;EACrC;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA,GAAG;AACL;AAkDO,IAAM,uCAAuCF;EAAW,MAC7DC;IACEC,IAAE,OAAO;;;;;;;;MAQP,cAAcA,IAAE,OAAO,EAAE,QAAQ;;;;;MAMjC,SAASA,IACN;QACCA,IAAE,KAAK;UACL;;UACA;UACA;QACF,CAAC;MACH,EACC,QAAQ;;;;;;MAOX,cAAcA,IAAE,OAAO,EAAE,QAAQ;;;;;;;;;;;;;;;MAgBjC,UAAUA,IACP,MAAM,CAACA,IAAE,QAAQ,GAAGA,IAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,gBAAgB,CAAC,CAAC,EAC5D,SAAS;;;;;;MAOZ,cAAcA,IAAE,OAAO,EAAE,QAAQ;;;;MAKjC,UAAUA,IAAE,IAAI,EAAE,QAAQ;;;;MAK1B,mBAAmBA,IAAE,QAAQ,EAAE,QAAQ;;;;;MAMvC,oBAAoBA,IAAE,OAAO,EAAE,QAAQ;;;;MAKvC,gBAAgBA,IAAE,OAAO,EAAE,QAAQ;;;;;;;;;MAUnC,sBAAsBA,IAAE,KAAK,CAAC,aAAa,KAAK,CAAC,EAAE,QAAQ;;;;;;;;;;;MAY3D,iBAAiBA,IAAE,OAAO,EAAE,QAAQ;;;;;;MAOpC,kBAAkBA,IAAE,OAAO,EAAE,QAAQ;;;;MAKrC,kBAAkBA,IAAE,OAAO,EAAE,QAAQ;;;;;;;;MASrC,aAAaA,IAAE,KAAK,CAAC,QAAQ,QAAQ,YAAY,SAAS,CAAC,EAAE,QAAQ;;;;MAKrE,OAAOA,IAAE,QAAQ,EAAE,QAAQ;;;;;MAM3B,kBAAkBA,IAAE,QAAQ,EAAE,QAAQ;;;;;;MAOtC,eAAeA,IAAE,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAAE,QAAQ;;;;;MAMzD,YAAYA,IAAE,KAAK,CAAC,QAAQ,UAAU,CAAC,EAAE,QAAQ;;;;;;;MAQjD,MAAMA,IAAE,OAAO,EAAE,QAAQ;;;;;;;;;MAUzB,mBAAmBA,IAAE,KAAK,CAAC,UAAU,aAAa,QAAQ,CAAC,EAAE,SAAS;;;;;;;;;;MAWtE,gBAAgBA,IAAE,QAAQ,EAAE,SAAS;IACvC,CAAC;EACH;AACF;AE5SO,IAAM,6BAA6BF;EAAW,MACnDC;IACEC,IAAE,OAAO;MACP,MAAMA,IAAE,OAAO,EAAE,QAAQ;MACzB,aAAaA,IAAE,OAAO;IACxB,CAAC;EACH;AACF;AAEO,IAAM,8BAA8BF;EAAW,MACpDC;IACEC,IAAE,OAAO;MACP,SAASA,IACN;QACCA,IAAE,mBAAmB,QAAQ;UAC3BA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,MAAM,GAAG,MAAMA,IAAE,OAAO,EAAE,CAAC;UACtDA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,OAAO,GAAG,KAAKA,IAAE,OAAO,EAAE,CAAC;QACxD,CAAC;MACH,EACC,QAAQ;IACb,CAAC;EACH;AACF;AAEO,IAAM,4BAA4BF;EAAW,MAClDC;IACEC,IAAE,OAAO;MACP,WAAWA,IACR,MAAM;QACLA,IAAE,OAAO;QACTA,IAAE,OAAO;UACP,SAASA,IAAE,MAAMA,IAAE,OAAO,CAAC,EAAE,SAAS;QACxC,CAAC;MACH,CAAC,EACA,SAAS;IACd,CAAC;EACH;AACF;AAWO,IAAM,6BACXC,0CAqCE;EACA,IAAI;EACJ,aAAa;EACb,cAAc;AAChB,CAAC;AAEI,IAAM,kBAAkB,CAC7B,OAA4B,CAAC,MAC1B;AACH,SAAO,2BAA2B,IAAI;AACxC;AC5FA,IAAM,yBAAyBD,IAAE,OAAO;EACtC,KAAKA,IAAE,OAAO;EACd,MAAMA,IAAE,KAAK,CAAC,MAAM,MAAM,MAAM,OAAO,MAAM,OAAO,MAAM,KAAK,CAAC;EAChE,OAAOA,IAAE,MAAM,CAACA,IAAE,OAAO,GAAGA,IAAE,OAAO,GAAGA,IAAE,QAAQ,GAAGA,IAAE,MAAMA,IAAE,OAAO,CAAC,CAAC,CAAC;AAC3E,CAAC;AAED,IAAM,uBAAuCA,IAAE,OAAO;EACpD,MAAMA,IAAE,KAAK,CAAC,OAAO,IAAI,CAAC;EAC1B,SAASA,IAAE;IACTA,IAAE,MAAM,CAAC,wBAAwBA,IAAE,KAAK,MAAM,oBAAoB,CAAC,CAAC;EACtE;AACF,CAAC;AAEM,IAAM,uBAAuBF;EAAW,MAC7CC;IACEC,IAAE,OAAO;MACP,gBAAgBA,IAAE,MAAMA,IAAE,OAAO,CAAC;MAClC,eAAeA,IAAE,OAAO,EAAE,SAAS;MACnC,SAASA,IACN,OAAO;QACN,QAAQA,IAAE,OAAO,EAAE,SAAS;QAC5B,gBAAgBA,IAAE,OAAO,EAAE,SAAS;MACtC,CAAC,EACA,SAAS;MACZ,SAASA,IACN,MAAM,CAAC,wBAAwB,oBAAoB,CAAC,EACpD,SAAS;IACd,CAAC;EACH;AACF;AAEO,IAAM,yBAAyBF;EAAW,MAC/CC;IACEC,IAAE,OAAO;MACP,SAASA,IAAE,MAAMA,IAAE,OAAO,CAAC;MAC3B,SAASA,IACN;QACCA,IAAE,OAAO;UACP,YAAYA,IAAE,OAAOA,IAAE,OAAO,GAAGA,IAAE,QAAQ,CAAC;UAC5C,QAAQA,IAAE,OAAO;UACjB,UAAUA,IAAE,OAAO;UACnB,OAAOA,IAAE,OAAO;UAChB,MAAMA,IAAE,OAAO;QACjB,CAAC;MACH,EACC,SAAS;IACd,CAAC;EACH;AACF;AAEO,IAAM,aAAaC,0CA+ExB;EACA,IAAI;EACJ,aAAaD,IAAE,OAAO,CAAC,CAAC;EACxB,cAAc;AAChB,CAAC;ACzIM,IAAM,4BAA4BF;EAAW,MAClDC;IACEC,IACG,OAAO;MACN,YAAYA,IAAE,KAAK,CAAC,QAAQ,UAAU,aAAa,CAAC,EAAE,SAAS;MAC/D,eAAeA,IAAE,KAAK,CAAC,OAAO,MAAM,CAAC,EAAE,SAAS;MAChD,gBAAgBA,IACb,OAAO;QACN,QAAQA,IAAE,OAAO,EAAE,SAAS;QAC5B,UAAUA,IAAE,OAAO,EAAE,SAAS;MAChC,CAAC,EACA,SAAS;MACZ,OAAOA,IAAE,OAAO,EAAE,SAAS;MAC3B,YAAYA,IAAE,KAAK,CAAC,MAAM,CAAC,EAAE,SAAS;MACtC,mBAAmBA,IAAE,OAAO,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,IAAI,GAAG,EAAE,SAAS;MAC7D,cAAcA,IAAE,KAAK,CAAC,OAAO,QAAQ,MAAM,CAAC,EAAE,SAAS;MACvD,eAAeA,IAAE,OAAO,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,SAAS;MACvD,SAASA,IAAE,KAAK,CAAC,QAAQ,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;MAC5D,MAAMA,IACH,KAAK,CAAC,aAAa,aAAa,aAAa,MAAM,CAAC,EACpD,SAAS;IACd,CAAC,EACA,OAAO;EACZ;AACF;AAEA,IAAM,6BAA6BF,WAAW,MAAMC,UAAUC,IAAE,OAAO,CAAC,CAAC,CAAC,CAAC;AAEpE,IAAM,8BAA8BF;EAAW,MACpDC,UAAUC,IAAE,OAAO,EAAE,QAAQA,IAAE,OAAO,EAAE,CAAC,CAAC;AAC5C;AAqEA,IAAM,6BAA6BC,0CASjC;EACA,IAAI;EACJ,aAAa;EACb,cAAc;AAChB,CAAC;AAEM,IAAM,kBAAkB,CAC7B,OAA4B,CAAC,MAC1B;AACH,SAAO,2BAA2B,IAAI;AACxC;ACrHA,IAAM,kBAAwCD,IAAE;EAAK,MACnDA,IAAE,MAAM;IACNA,IAAE,OAAO;IACTA,IAAE,OAAO;IACTA,IAAE,QAAQ;IACVA,IAAE,KAAK;IACPA,IAAE,MAAM,eAAe;IACvBA,IAAE,OAAOA,IAAE,OAAO,GAAG,eAAe;EACtC,CAAC;AACH;AAEO,IAAM,gBAAgBF;EAAW,MACtCC;IACEC,IACG,OAAO;MACN,aAAaA,IAAE,OAAO;MACtB,cAAcA,IACX,MAAM;QACLA,IAAE,MAAMA,IAAE,OAAO,CAAC;QAClBA,IAAE,OAAO;UACP,UAAUA,IAAE,QAAQ,EAAE,SAAS;UAC/B,WAAWA,IAAE,MAAMA,IAAE,OAAO,CAAC,EAAE,SAAS;QAC1C,CAAC;MACH,CAAC,EACA,SAAS;MACZ,eAAeA,IAAE,OAAO,EAAE,SAAS;MACnC,aAAaA,IAAE,OAAO,EAAE,SAAS;MACjC,SAASA,IAAE,OAAOA,IAAE,OAAO,GAAGA,IAAE,OAAO,CAAC,EAAE,SAAS;MAEnD,iBAAiBA,IACd,MAAM;QACLA,IAAE,KAAK,CAAC,UAAU,OAAO,CAAC;QAC1BA,IAAE,OAAO;UACP,OAAOA,IACJ,OAAO;YACN,WAAWA,IAAE,MAAMA,IAAE,OAAO,CAAC,EAAE,SAAS;UAC1C,CAAC,EACA,SAAS;QACd,CAAC;MACH,CAAC,EACA,SAAS;MACZ,mBAAmBA,IAAE,OAAO,EAAE,SAAS;MACvC,WAAWA,IAAE,OAAO,EAAE,SAAS;IACjC,CAAC,EACA;MACC,CAAA,MAAK,EAAE,aAAa,QAAQ,EAAE,eAAe;MAC7C;IACF;EACJ;AACF;AAEA,IAAM,iBAAiBF,WAAW,MAAMC,UAAUC,IAAE,OAAO,CAAC,CAAC,CAAC,CAAC;AAExD,IAAM,kBAAkBF;EAAW,MACxCC;IACEC,IAAE,OAAO;MACP,MAAMA,IAAE,QAAQ,MAAM;MACtB,aAAaA,IAAE,OAAO;MACtB,MAAMA,IAAE,OAAO;MACf,WAAWA,IAAE,OAAO;MACpB,QAAQA,IAAE,OAAO,EAAE,QAAQ;MAC3B,OAAOA,IAAE,MAAM,CAACA,IAAE,OAAO,GAAG,eAAe,CAAC,EAAE,SAAS;IACzD,CAAC;EACH;AACF;AAmCO,IAAM,iBAAiBC,0CAW5B;EACA,IAAI;EACJ,aAAa;EACb,cAAc;AAChB,CAAC;ACnHM,IAAM,sBAAsBH;EAAW,MAC5CC;IACEC,IAAE,OAAO;MACP,mBAAmBA,IAAE,QAAQ,EAAE,SAAS;MACxC,SAASA,IACN,OAAO,EAAE,gBAAgBA,IAAE,MAAMA,IAAE,OAAO,CAAC,EAAE,SAAS,EAAE,CAAC,EACzD,SAAS;MACZ,mBAAmBA,IAAE,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;MAC9D,cAAcA,IACX,OAAO;QACN,MAAMA,IAAE,QAAQ,aAAa;QAC7B,SAASA,IAAE,OAAO,EAAE,SAAS;QAC7B,MAAMA,IAAE,OAAO,EAAE,SAAS;QAC1B,QAAQA,IAAE,OAAO,EAAE,SAAS;QAC5B,UAAUA,IAAE,OAAO,EAAE,SAAS;MAChC,CAAC,EACA,SAAS;IACd,CAAC;EACH;AACF;AAEA,IAAM,uBAAuBF,WAAW,MAAMC,UAAUC,IAAE,OAAO,CAAC,CAAC,CAAC,CAAC;AAE9D,IAAM,wBAAwBF;EAAW,MAC9CC;IACEC,IAAE,OAAO;MACP,QAAQA,IAAE,mBAAmB,QAAQ;QACnCA,IAAE,OAAO;UACP,MAAMA,IAAE,QAAQ,QAAQ;UACxB,OAAOA,IAAE,OAAO,EAAE,SAAS;QAC7B,CAAC;QACDA,IAAE,OAAO;UACP,MAAMA,IAAE,QAAQ,UAAU;UAC1B,KAAKA,IAAE,OAAO,EAAE,QAAQ;QAC1B,CAAC;QACDA,IAAE,OAAO;UACP,MAAMA,IAAE,QAAQ,YAAY;UAC5B,KAAKA,IAAE,OAAO,EAAE,QAAQ;UACxB,SAASA,IAAE,OAAO,EAAE,QAAQ;QAC9B,CAAC;MACH,CAAC;MACD,SAASA,IACN;QACCA,IAAE,mBAAmB,QAAQ;UAC3BA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,KAAK,GAAG,KAAKA,IAAE,OAAO,EAAE,CAAC;UACpDA,IAAE,OAAO,EAAE,MAAMA,IAAE,QAAQ,KAAK,GAAG,MAAMA,IAAE,OAAO,EAAE,CAAC;QACvD,CAAC;MACH,EACC,SAAS;IACd,CAAC;EACH;AACF;AAEO,IAAM,uBAAuBC,0CA8GlC;EACA,IAAI;EACJ,aAAa;EACb,cAAc;AAChB,CAAC;ACvKM,IAAM,6BAA6BH;EAAW,MACnDC;IACEC,IAAE,OAAO;MACP,mBAAmBA,IAAE,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;MAC9D,cAAcA,IACX,OAAO;QACN,MAAMA,IAAE,QAAQ,aAAa;QAC7B,SAASA,IAAE,OAAO,EAAE,SAAS;QAC7B,MAAMA,IAAE,OAAO,EAAE,SAAS;QAC1B,QAAQA,IAAE,OAAO,EAAE,SAAS;QAC5B,UAAUA,IAAE,OAAO,EAAE,SAAS;MAChC,CAAC,EACA,SAAS;IACd,CAAC;EACH;AACF;AAEO,IAAM,8BAA8BF;EAAW,MACpDC,UAAUC,IAAE,OAAO,CAAC,CAAC,CAAC;AACxB;AAEA,IAAM,+BAA+BF;EAAW,MAC9CC;IACEC,IAAE,OAAO;MACP,QAAQA,IAAE,mBAAmB,QAAQ;QACnCA,IAAE,OAAO;UACP,MAAMA,IAAE,QAAQ,QAAQ;UACxB,OAAOA,IAAE,OAAO,EAAE,SAAS;QAC7B,CAAC;QACDA,IAAE,OAAO;UACP,MAAMA,IAAE,QAAQ,UAAU;UAC1B,KAAKA,IAAE,OAAO,EAAE,QAAQ;QAC1B,CAAC;QACDA,IAAE,OAAO;UACP,MAAMA,IAAE,QAAQ,YAAY;UAC5B,KAAKA,IAAE,OAAO,EAAE,QAAQ;UACxB,SAASA,IAAE,OAAO,EAAE,QAAQ;QAC9B,CAAC;MACH,CAAC;IACH,CAAC;EACH;AACF;AAEO,IAAM,mBAAmBC,0CAoF9B;EACA,IAAI;EACJ,aAAa;EACb,cAAc;AAChB,CAAC;AN5HD,eAAsB,sBAAsB;EAC1C;EACA;AACF,GAkBG;AAED,WAAQ,SAAA,OAAA,SAAA,MAAO,UAAS,QAAQ;AAEhC,QAAM,eAAkC,CAAC;AAEzC,MAAI,SAAS,MAAM;AACjB,WAAO,EAAE,OAAO,QAAW,YAAY,QAAW,aAAa;EACjE;AAEA,QAAM,cAA0C,CAAC;AAEjD,aAAW,QAAQ,OAAO;AACxB,YAAQ,KAAK,MAAM;MACjB,KAAK;AACH,oBAAY,KAAK;UACf,MAAM;UACN,MAAM,KAAK;UACX,aAAa,KAAK;UAClB,YAAY,KAAK;UACjB,GAAI,KAAK,UAAU,OAAO,EAAE,QAAQ,KAAK,OAAO,IAAI,CAAC;QACvD,CAAC;AACD;MACF,KAAK,YAAY;AACf,gBAAQ,KAAK,IAAI;UACf,KAAK,sBAAsB;AACzB,kBAAM,OAAO,MAAMO,cAAc;cAC/B,OAAO,KAAK;cACZ,QAAQ;YACV,CAAC;AAED,wBAAY,KAAK;cACf,MAAM;cACN,kBAAkB,KAAK;cACvB,iBAAiB,KAAK;cACtB,iBAAiB,KAAK,UAClB;gBACE,QAAQ,KAAK,QAAQ;gBACrB,iBAAiB,KAAK,QAAQ;cAChC,IACA;cACJ,SAAS,KAAK;YAChB,CAAC;AAED;UACF;UACA,KAAK,sBAAsB;AACzB,wBAAY,KAAK;cACf,MAAM;YACR,CAAC;AACD;UACF;UACA,KAAK,gBAAgB;AACnB,wBAAY,KAAK;cACf,MAAM;YACR,CAAC;AACD;UACF;UACA,KAAK,sBAAsB;AACzB,wBAAY,KAAK;cACf,MAAM;YACR,CAAC;AACD;UACF;UACA,KAAK,6BAA6B;AAChC,kBAAM,OAAO,MAAMA,cAAc;cAC/B,OAAO,KAAK;cACZ,QAAQ;YACV,CAAC;AACD,wBAAY,KAAK;cACf,MAAM;cACN,qBAAqB,KAAK;cAC1B,eAAe,KAAK;YACtB,CAAC;AACD;UACF;UACA,KAAK,qBAAqB;AACxB,kBAAM,OAAO,MAAMA,cAAc;cAC/B,OAAO,KAAK;cACZ,QAAQ;YACV,CAAC;AACD,wBAAY,KAAK;cACf,MAAM;cACN,SACE,KAAK,WAAW,OACZ,EAAE,iBAAiB,KAAK,QAAQ,eAAe,IAC/C;cACN,qBAAqB,KAAK;cAC1B,qBAAqB,KAAK;cAC1B,eAAe,KAAK;YACtB,CAAC;AACD;UACF;UACA,KAAK,2BAA2B;AAC9B,kBAAM,OAAO,MAAMA,cAAc;cAC/B,OAAO,KAAK;cACZ,QAAQ;YACV,CAAC;AAED,wBAAY,KAAK;cACf,MAAM;cACN,WACE,KAAK,aAAa,OACd,EAAE,MAAM,QAAQ,UAAU,OAAU,IACpC,OAAO,KAAK,cAAc,WACxB,KAAK,YACL,EAAE,MAAM,QAAQ,UAAU,KAAK,UAAU,QAAQ;YAC3D,CAAC;AACD;UACF;UACA,KAAK,2BAA2B;AAC9B,kBAAM,OAAO,MAAMA,cAAc;cAC/B,OAAO,KAAK;cACZ,QAAQ;YACV,CAAC;AAED,wBAAY,KAAK;cACf,MAAM;cACN,YAAY,KAAK;cACjB,gBAAgB,KAAK;cACrB,kBAAkB,KAAK,iBACnB;gBACE,SAAS,KAAK,eAAe;gBAC7B,WAAW,KAAK,eAAe;cACjC,IACA;cACJ,OAAO,KAAK;cACZ,YAAY,KAAK;cACjB,gBAAgB,KAAK;cACrB,SAAS,KAAK;cACd,oBAAoB,KAAK;cACzB,eAAe,KAAK;cACpB,MAAM,KAAK;YACb,CAAC;AACD;UACF;UACA,KAAK,cAAc;AACjB,kBAAM,OAAO,MAAMA,cAAc;cAC/B,OAAO,KAAK;cACZ,QAAQ;YACV,CAAC;AAED,kBAAM,oBAAoB,CAAC,YAAsC;cAC/D,YAAY,OAAO;YACrB;AAEA,kBAAM,kBAAkB,KAAK;AAC7B,kBAAM,uBAOJ,mBAAmB,OACf,SACA,OAAO,oBAAoB,WACzB,kBACA,gBAAgB,SAAS,OACvB,EAAE,OAAO,kBAAkB,gBAAgB,KAAK,EAAE,IAClD;AAEV,wBAAY,KAAK;cACf,MAAM;cACN,cAAc,KAAK;cACnB,eAAe,MAAM,QAAQ,KAAK,YAAY,IAC1C,KAAK,eACL,KAAK,eACH;gBACE,WAAW,KAAK,aAAa;gBAC7B,YAAY,KAAK,aAAa;cAChC,IACA;cACN,eAAe,KAAK;cACpB,cAAc,KAAK;cACnB,SAAS,KAAK;cACd,kBAAkB,wBAAA,OAAA,uBAAwB;cAC1C,oBAAoB,KAAK;cACzB,YAAY,KAAK;YACnB,CAAC;AAED;UACF;QACF;AACA;MACF;MACA;AACE,qBAAa,KAAK;UAChB,MAAM;UACN,SAAS,iBAAiB,IAAI;QAChC,CAAC;AACD;IACJ;EACF;AAEA,MAAI,cAAc,MAAM;AACtB,WAAO,EAAE,OAAO,aAAa,YAAY,QAAW,aAAa;EACnE;AAEA,QAAM,OAAO,WAAW;AAExB,UAAQ,MAAM;IACZ,KAAK;IACL,KAAK;IACL,KAAK;AACH,aAAO,EAAE,OAAO,aAAa,YAAY,MAAM,aAAa;IAC9D,KAAK;AACH,aAAO;QACL,OAAO;QACP,YACE,WAAW,aAAa,sBACxB,WAAW,aAAa,iBACxB,WAAW,aAAa,sBACxB,WAAW,aAAa,wBACxB,WAAW,aAAa,gBACxB,WAAW,aAAa,SACxB,WAAW,aAAa,gBACpB,EAAE,MAAM,WAAW,SAAS,IAC5B,EAAE,MAAM,YAAY,MAAM,WAAW,SAAS;QACpD;MACF;IACF,SAAS;AACP,YAAM,mBAA0B;AAChC,YAAM,IAAIF,8BAA8B;QACtC,eAAe,qBAAqB,gBAAgB;MACtD,CAAC;IACH;EACF;AACF;AT/LA,SAAS,4CACP,QACwB;AA1E1B,MAAA,IAAA;AA2EE,QAAM,UAAkC,CAAC;AACzC,aAAW,WAAW,QAAQ;AAC5B,QAAI,QAAQ,SAAS,YAAa;AAClC,eAAW,QAAQ,QAAQ,SAAS;AAClC,UAAI,KAAK,SAAS,YAAa;AAC/B,YAAM,qBAAoB,MAAA,KAAA,KAAK,oBAAL,OAAA,SAAA,GAAsB,WAAtB,OAAA,SAAA,GACtB;AACJ,UAAI,qBAAqB,MAAM;AAC7B,gBAAQ,iBAAiB,IAAI,KAAK;MACpC;IACF;EACF;AACA,SAAO;AACT;AAEO,IAAM,+BAAN,MAA8D;EAOnE,YAAY,SAAiC,QAAsB;AANnE,SAAS,uBAAuB;AAWhC,SAAS,gBAA0C;MACjD,WAAW,CAAC,iBAAiB;MAC7B,mBAAmB,CAAC,iBAAiB;IACvC;AAPE,SAAK,UAAU;AACf,SAAK,SAAS;EAChB;EAOA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAEA,MAAc,QAAQ;IACpB;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EACF,GAA+B;AA7HjC,QAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AA8HI,UAAM,WAA8B,CAAC;AACrC,UAAM,oBAAoB,mCAAmC,KAAK,OAAO;AAEzE,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK,EAAE,MAAM,eAAe,SAAS,OAAO,CAAC;IACxD;AAEA,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK,EAAE,MAAM,eAAe,SAAS,OAAO,CAAC;IACxD;AAEA,QAAI,mBAAmB,MAAM;AAC3B,eAAS,KAAK,EAAE,MAAM,eAAe,SAAS,kBAAkB,CAAC;IACnE;AAEA,QAAI,oBAAoB,MAAM;AAC5B,eAAS,KAAK,EAAE,MAAM,eAAe,SAAS,mBAAmB,CAAC;IACpE;AAEA,QAAI,iBAAiB,MAAM;AACzB,eAAS,KAAK,EAAE,MAAM,eAAe,SAAS,gBAAgB,CAAC;IACjE;AAEA,UAAM,gBAAgB,MAAMC,qBAAqB;MAC/C,UAAU;MACV;MACA,QAAQ;IACV,CAAC;AAED,UAAM,oBACJ,KAAA,iBAAA,OAAA,SAAA,cAAe,mBAAf,OAAA,KAAiC,kBAAkB;AAErD,SAAI,iBAAA,OAAA,SAAA,cAAe,kBAAgB,iBAAA,OAAA,SAAA,cAAe,qBAAoB;AACpE,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SAAS;MACX,CAAC;IACH;AAEA,UAAM,kBAAkB,sBAAsB;MAC5C;MACA,mBAAmB;QACjB,2BAA2B;QAC3B,sBAAsB;QACtB,2BAA2B;QAC3B,sBAAsB;QACtB,gBAAgB;QAChB,qBAAqB;QACrB,6BAA6B;QAC7B,cAAc;QACd,sBAAsB;MACxB;IACF,CAAC;AAED,UAAM,EAAE,OAAO,UAAU,cAAc,IACrC,MAAM,8BAA8B;MAClC;MACA;MACA,oBACE,KAAA,iBAAA,OAAA,SAAA,cAAe,sBAAf,OAAA,KACC,mBACG,cACA,kBAAkB;MACxB,gBAAgB,KAAK,OAAO;MAC5B,QAAO,KAAA,iBAAA,OAAA,SAAA,cAAe,UAAf,OAAA,KAAwB;MAC/B,mBAAmB,cAAc,oBAAoB;MACrD,cAAc,cAAc,cAAc;MAC1C,mBAAmB,cAAc,oBAAoB;IACvD,CAAC;AAEH,aAAS,KAAK,GAAG,aAAa;AAE9B,UAAM,oBAAmB,KAAA,iBAAA,OAAA,SAAA,cAAe,qBAAf,OAAA,KAAmC;AAE5D,QAAI,UAAyC,iBAAA,OAAA,SAAA,cAAe;AAE5D,aAAS,WAAW,KAAkC;AACpD,UAAI,WAAW,MAAM;AACnB,kBAAU,CAAC,GAAG;MAChB,WAAW,CAAC,QAAQ,SAAS,GAAG,GAAG;AACjC,kBAAU,CAAC,GAAG,SAAS,GAAG;MAC5B;IACF;AAEA,aAAS,cAAc,IAAY;AACjC,cACE,SAAA,OAAA,SAAA,MAAO,KAAK,CAAA,SAAQ,KAAK,SAAS,cAAc,KAAK,OAAO,EAAA,MAAO;IAEvE;AAGA,UAAM,cACJ,QAAO,iBAAA,OAAA,SAAA,cAAe,cAAa,WAC/B,iBAAA,OAAA,SAAA,cAAe,YACf,iBAAA,OAAA,SAAA,cAAe,cAAa,OAC1B,mBACA;AAER,QAAI,aAAa;AACf,iBAAW,8BAA8B;IAC3C;AAGA,UAAM,qBACJ,KAAA,SAAA,OAAA,SAAA,MAAO;MACL,CAAA,SACE,KAAK,SAAS,eACb,KAAK,OAAO,uBACX,KAAK,OAAO;IAAA,MAJlB,OAAA,SAAA,GAMC;AAEH,QAAI,mBAAmB;AACrB,iBAAW,gCAAgC;IAC7C;AAGA,QAAI,cAAc,yBAAyB,GAAG;AAC5C,iBAAW,+BAA+B;IAC5C;AAEA,UAAM,QAAQ,iBAAA,OAAA,SAAA,cAAe;AAG7B,QAAI,UAAU,SAAS,kBAAkB;AACvC,iBAAW,6BAA6B;IAC1C;AAEA,UAAM,WAAW;MACf,OAAO,KAAK;MACZ;MACA;MACA,OAAO;MACP,mBAAmB;MAEnB,KAAK,kBAAA,OAAA,SAAA,eAAgB,UAAS,WAAU,iBAAA,OAAA,SAAA,cAAe,mBAAkB;QACvE,MAAM;UACJ,IAAI,kBAAA,OAAA,SAAA,eAAgB,UAAS,UAAU;YACrC,QACE,eAAe,UAAU,OACrB;cACE,MAAM;cACN,QAAQ;cACR,OAAM,KAAA,eAAe,SAAf,OAAA,KAAuB;cAC7B,aAAa,eAAe;cAC5B,QAAQ,eAAe;YACzB,IACA,EAAE,MAAM,cAAc;UAC9B;UACA,IAAI,iBAAA,OAAA,SAAA,cAAe,kBAAiB;YAClC,WAAW,cAAc;UAC3B;QACF;MACF;;MAGA,cAAc,iBAAA,OAAA,SAAA,cAAe;MAC7B,gBAAgB,iBAAA,OAAA,SAAA,cAAe;MAC/B,UAAU,iBAAA,OAAA,SAAA,cAAe;MACzB,qBAAqB,iBAAA,OAAA,SAAA,cAAe;MACpC,sBAAsB,iBAAA,OAAA,SAAA,cAAe;MACrC;MACA,MAAM,iBAAA,OAAA,SAAA,cAAe;MACrB,cAAc,iBAAA,OAAA,SAAA,cAAe;MAC7B,cAAc,iBAAA,OAAA,SAAA,cAAe;MAC7B;MACA,kBAAkB,iBAAA,OAAA,SAAA,cAAe;MACjC,wBAAwB,iBAAA,OAAA,SAAA,cAAe;MACvC,mBAAmB,iBAAA,OAAA,SAAA,cAAe;MAClC,cAAc;MACd,YAAY,iBAAA,OAAA,SAAA,cAAe;;MAG3B,GAAI,sBACD,iBAAA,OAAA,SAAA,cAAe,oBAAmB,SACjC,iBAAA,OAAA,SAAA,cAAe,qBAAoB,SAAS;QAC5C,WAAW;UACT,IAAI,iBAAA,OAAA,SAAA,cAAe,oBAAmB,QAAQ;YAC5C,QAAQ,cAAc;UACxB;UACA,IAAI,iBAAA,OAAA,SAAA,cAAe,qBAAoB,QAAQ;YAC7C,SAAS,cAAc;UACzB;QACF;MACF;IACJ;AAIA,QAAI,kBAAkB;AAGpB,UACE,GACE,iBAAA,OAAA,SAAA,cAAe,qBAAoB,UACnC,kBAAkB,iCAEpB;AACA,YAAI,SAAS,eAAe,MAAM;AAChC,mBAAS,cAAc;AACvB,mBAAS,KAAK;YACZ,MAAM;YACN,SAAS;YACT,SAAS;UACX,CAAC;QACH;AAEA,YAAI,SAAS,SAAS,MAAM;AAC1B,mBAAS,QAAQ;AACjB,mBAAS,KAAK;YACZ,MAAM;YACN,SAAS;YACT,SAAS;UACX,CAAC;QACH;MACF;IACF,OAAO;AACL,WAAI,iBAAA,OAAA,SAAA,cAAe,oBAAmB,MAAM;AAC1C,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS;QACX,CAAC;MACH;AAEA,WAAI,iBAAA,OAAA,SAAA,cAAe,qBAAoB,MAAM;AAC3C,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS;QACX,CAAC;MACH;IACF;AAGA,SACE,iBAAA,OAAA,SAAA,cAAe,iBAAgB,UAC/B,CAAC,kBAAkB,wBACnB;AACA,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SACE;MACJ,CAAC;AAED,aAAQ,SAAiB;IAC3B;AAGA,SACE,iBAAA,OAAA,SAAA,cAAe,iBAAgB,cAC/B,CAAC,kBAAkB,4BACnB;AACA,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SACE;MACJ,CAAC;AAED,aAAQ,SAAiB;IAC3B;AAEA,UAAM;MACJ,OAAO;MACP,YAAY;MACZ;IACF,IAAI,MAAM,sBAAsB;MAC9B;MACA;IACF,CAAC;AAED,WAAO;MACL;MACA,MAAM;QACJ,GAAG;QACH,OAAO;QACP,aAAa;MACf;MACA,UAAU,CAAC,GAAG,UAAU,GAAG,YAAY;MACvC;MACA;IACF;EACF;EAEA,MAAM,WACJ,SACwC;AA/Z5C,QAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AAgaI,UAAM;MACJ,MAAM;MACN;MACA;MACA;IACF,IAAI,MAAM,KAAK,QAAQ,OAAO;AAC9B,UAAM,MAAM,KAAK,OAAO,IAAI;MAC1B,MAAM;MACN,SAAS,KAAK;IAChB,CAAC;AAED,UAAM,cAAc,KAAK,OAAO,SAAS,QAAQ,cAAc,EAAE;AAEjE,UAAM,+CACJ,4CAA4C,QAAQ,MAAM;AAE5D,UAAM;MACJ;MACA,OAAO;MACP,UAAU;IACZ,IAAI,MAAME,cAAc;MACtB;MACA,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D;MACA,uBAAuB;MACvB,2BAA2BC;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,QAAI,SAAS,OAAO;AAClB,YAAM,IAAI,aAAa;QACrB,SAAS,SAAS,MAAM;QACxB;QACA,mBAAmB;QACnB,YAAY;QACZ;QACA,cAAc;QACd,aAAa;MACf,CAAC;IACH;AAEA,UAAM,UAAyC,CAAC;AAChD,UAAM,WAA2C,CAAC;AAGlD,QAAI,kBAAkB;AAGtB,eAAW,QAAQ,SAAS,QAAS;AACnC,cAAQ,KAAK,MAAM;QACjB,KAAK,aAAa;AAEhB,cAAI,KAAK,QAAQ,WAAW,GAAG;AAC7B,iBAAK,QAAQ,KAAK,EAAE,MAAM,gBAAgB,MAAM,GAAG,CAAC;UACtD;AAEA,qBAAW,WAAW,KAAK,SAAS;AAClC,oBAAQ,KAAK;cACX,MAAM;cACN,MAAM,QAAQ;cACd,kBAAkB;gBAChB,CAAC,WAAW,GAAG;kBACb,QAAQ,KAAK;kBACb,4BAA2B,KAAA,KAAK,sBAAL,OAAA,KAA0B;gBACvD;cACF;YACF,CAAC;UACH;AACA;QACF;QAEA,KAAK,yBAAyB;AAC5B,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,gBAAgB,iBAAiB,kBAAkB;YAC7D,OAAO;YACP,kBAAkB;UACpB,CAAC;AAED,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,gBAAgB,iBAAiB,kBAAkB;YAC7D,QAAQ;cACN,QAAQ,KAAK;YACf;UACF,CAAC;AAED;QACF;QAEA,KAAK,oBAAoB;AACvB,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,gBAAgB,iBAAiB,aAAa;YACxD,OAAO,KAAK,UAAU;cACpB,QAAQ,KAAK;YACf,CAAqD;YACrD,kBAAkB;cAChB,CAAC,WAAW,GAAG;gBACb,QAAQ,KAAK;cACf;YACF;UACF,CAAC;AAED;QACF;QAEA,KAAK,cAAc;AACjB,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,gBAAgB,iBAAiB,OAAO;YAClD,OAAO,KAAK,UAAU;cACpB,QAAQ;gBACN,UAAU,KAAK,OAAO;cACxB;YACF,CAAgD;YAChD,kBAAkB;cAChB,CAAC,WAAW,GAAG;gBACb,QAAQ,KAAK;cACf;YACF;UACF,CAAC;AAED;QACF;QAEA,KAAK,WAAW;AACd,qBAAW,eAAe,KAAK,SAAS;AACtC,kBACE,MAAA,KAAA,QAAQ,oBAAR,OAAA,SAAA,GAAyB,WAAzB,OAAA,SAAA,GAAiC,aACjC,YAAY,UACZ;AACA,uBAAS,KAAK,YAAY,QAAQ;YACpC;AAEA,kBAAMC,oBAAqD;cACzD,QAAQ,KAAK;cACb,GAAI,YAAY,YAAY,SAAS,KAAK;gBACxC,aAAa,YAAY;cAC3B;YACF;AAEA,oBAAQ,KAAK;cACX,MAAM;cACN,MAAM,YAAY;cAClB,kBAAkB;gBAChB,CAAC,WAAW,GAAGA;cACjB;YACF,CAAC;AAED,uBAAW,cAAc,YAAY,aAAa;AAChD,kBAAI,WAAW,SAAS,gBAAgB;AACtC,wBAAQ,KAAK;kBACX,MAAM;kBACN,YAAY;kBACZ,KAAI,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BC,WAAW;kBAC7C,KAAK,WAAW;kBAChB,OAAO,WAAW;gBACpB,CAAC;cACH,WAAW,WAAW,SAAS,iBAAiB;AAC9C,wBAAQ,KAAK;kBACX,MAAM;kBACN,YAAY;kBACZ,KAAI,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BA,WAAW;kBAC7C,WAAW;kBACX,QAAO,MAAA,KAAA,WAAW,UAAX,OAAA,KAAoB,WAAW,aAA/B,OAAA,KAA2C;kBAClD,WAAU,KAAA,WAAW,aAAX,OAAA,KAAuB,WAAW;kBAC5C,GAAI,WAAW,UACX;oBACE,kBAAkB;sBAChB,CAAC,WAAW,GAAG;wBACb,QAAQ,WAAW;sBACrB;oBACF;kBACF,IACA,CAAC;gBACP,CAAC;cACH,WAAW,WAAW,SAAS,2BAA2B;AACxD,wBAAQ,KAAK;kBACX,MAAM;kBACN,YAAY;kBACZ,KAAI,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BA,WAAW;kBAC7C,WAAW;kBACX,QACE,MAAA,KAAA,WAAW,aAAX,OAAA,KAAuB,WAAW,YAAlC,OAAA,KAA6C;kBAC/C,WAAU,KAAA,WAAW,aAAX,OAAA,KAAuB,WAAW;kBAC5C,kBAAkB;oBAChB,CAAC,WAAW,GAAG;sBACb,QAAQ,WAAW;sBACnB,aAAa,WAAW;sBACxB,GAAI,WAAW,SAAS,OACpB,EAAE,OAAO,WAAW,MAAM,IAC1B,CAAC;oBACP;kBACF;gBACF,CAAC;cACH,WAAW,WAAW,SAAS,aAAa;AAC1C,wBAAQ,KAAK;kBACX,MAAM;kBACN,YAAY;kBACZ,KAAI,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BA,WAAW;kBAC7C,WAAW;kBACX,OAAO,WAAW;kBAClB,UAAU,WAAW;kBACrB,kBAAkB;oBAChB,CAAC,WAAW,GAAG;sBACb,QAAQ,WAAW;sBACnB,GAAI,WAAW,SAAS,OACpB,EAAE,OAAO,WAAW,MAAM,IAC1B,CAAC;oBACP;kBACF;gBACF,CAAC;cACH;YACF;UACF;AAEA;QACF;QAEA,KAAK,iBAAiB;AACpB,4BAAkB;AAElB,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,KAAK;YACf,OAAO,KAAK;YACZ,kBAAkB;cAChB,CAAC,WAAW,GAAG;gBACb,QAAQ,KAAK;cACf;YACF;UACF,CAAC;AACD;QACF;QAEA,KAAK,mBAAmB;AACtB,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,gBAAgB;cACxB,qBAAA,OAAA,oBAAqB;YACvB;YACA,OAAO,KAAK,UAAU,CAAC,CAAC;YACxB,kBAAkB;UACpB,CAAC;AAED,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,gBAAgB;cACxB,qBAAA,OAAA,oBAAqB;YACvB;YACA,QAAQ,mBAAmB,KAAK,MAAM;UACxC,CAAC;AAED;QACF;QAEA,KAAK,YAAY;AACf,gBAAM,aACJ,KAAK,uBAAuB,QACvB,KAAA,6CACC,KAAK,mBACP,MAFC,OAAA,KAEI,KAAK,KACV,KAAK;AAEX,gBAAM,WAAW,OAAO,KAAK,IAAI;AAEjC,kBAAQ,KAAK;YACX,MAAM;YACN;YACA;YACA,OAAO,KAAK;YACZ,kBAAkB;YAClB,SAAS;UACX,CAAC;AAED,kBAAQ,KAAK;YACX,MAAM;YACN;YACA;YACA,QAAQ;cACN,MAAM;cACN,aAAa,KAAK;cAClB,MAAM,KAAK;cACX,WAAW,KAAK;cAChB,GAAI,KAAK,UAAU,OAAO,EAAE,QAAQ,KAAK,OAAO,IAAI,CAAC;cACrD,GAAI,KAAK,SAAS,OACd,EAAE,OAAO,KAAK,MAA8B,IAC5C,CAAC;YACP;YACA,kBAAkB;cAChB,CAAC,WAAW,GAAG;gBACb,QAAQ,KAAK;cACf;YACF;UACF,CAAC;AACD;QACF;QAEA,KAAK,kBAAkB;AAErB;QACF;QAEA,KAAK,wBAAwB;AAC3B,gBAAM,qBAAoB,KAAA,KAAK,wBAAL,OAAA,KAA4B,KAAK;AAC3D,gBAAM,mBAAkB,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BA,WAAW;AACjE,gBAAM,WAAW,OAAO,KAAK,IAAI;AAEjC,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY;YACZ;YACA,OAAO,KAAK;YACZ,kBAAkB;YAClB,SAAS;UACX,CAAC;AAED,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY;YACZ,YAAY;UACd,CAA8C;AAC9C;QACF;QAEA,KAAK,iBAAiB;AACpB,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,gBAAgB,iBAAiB,cAAc;YACzD,OAAO;YACP,kBAAkB;UACpB,CAAC;AAED,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,gBAAgB,iBAAiB,cAAc;YACzD,QAAQ;cACN,MAAM;cACN,QAAQ,KAAK,UAAU;YACzB;UACF,CAAC;AACD;QACF;QAEA,KAAK,oBAAoB;AACvB,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,gBAAgB,iBAAiB,aAAa;YACxD,OAAO;YACP,kBAAkB;UACpB,CAAC;AAED,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,gBAAgB,iBAAiB,aAAa;YACxD,QAAQ;cACN,SAAS,KAAK;cACd,UACE,MAAA,KAAA,KAAK,YAAL,OAAA,SAAA,GAAc,IAAI,CAAA,YAAW;gBAC3B,YAAY,OAAO;gBACnB,QAAQ,OAAO;gBACf,UAAU,OAAO;gBACjB,OAAO,OAAO;gBACd,MAAM,OAAO;cACf,EAAA,MANA,OAAA,KAMO;YACX;UACF,CAAC;AACD;QACF;QAEA,KAAK,yBAAyB;AAC5B,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,gBAAgB,iBAAiB,kBAAkB;YAC7D,OAAO,KAAK,UAAU;cACpB,MAAM,KAAK;cACX,aAAa,KAAK;YACpB,CAA0D;YAC1D,kBAAkB;UACpB,CAAC;AAED,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,gBAAgB,iBAAiB,kBAAkB;YAC7D,QAAQ;cACN,SAAS,KAAK;YAChB;UACF,CAAC;AACD;QACF;QAEA,KAAK,oBAAoB;AACvB,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,gBAAgB,iBAAiB,aAAa;YACxD,OAAO,KAAK,UAAU;cACpB,QAAQ,KAAK;cACb,WAAW,KAAK;YAClB,CAAqD;YACrD,kBAAkB;cAChB,CAAC,WAAW,GAAG;gBACb,QAAQ,KAAK;cACf;YACF;UACF,CAAC;AAED;QACF;MACF;IACF;AAEA,UAAM,mBAA6C;MACjD,CAAC,WAAW,GAAG,EAAE,YAAY,SAAS,GAAG;IAC3C;AAEA,QAAI,SAAS,SAAS,GAAG;AACvB,uBAAiB,WAAW,EAAE,WAAW;IAC3C;AAEA,QAAI,OAAO,SAAS,iBAAiB,UAAU;AAC7C,uBAAiB,WAAW,EAAE,cAAc,SAAS;IACvD;AAEA,UAAM,QAAQ,SAAS;AAEvB,WAAO;MACL;MACA,cAAc;QACZ,SAAS,8BAA8B;UACrC,eAAc,KAAA,SAAS,uBAAT,OAAA,SAAA,GAA6B;UAC3C;QACF,CAAC;QACD,MAAK,MAAA,KAAA,SAAS,uBAAT,OAAA,SAAA,GAA6B,WAA7B,OAAA,KAAuC;MAC9C;MACA,OAAO,4BAA4B,KAAK;MACxC,SAAS,EAAE,KAAK;MAChB,UAAU;QACR,IAAI,SAAS;QACb,WAAW,IAAI,KAAK,SAAS,aAAc,GAAI;QAC/C,SAAS,SAAS;QAClB,SAAS;QACT,MAAM;MACR;MACA;MACA;IACF;EACF;EAEA,MAAM,SACJ,SACsC;AACtC,UAAM;MACJ,MAAM;MACN;MACA;MACA;MACA;IACF,IAAI,MAAM,KAAK,QAAQ,OAAO;AAE9B,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAMJ,cAAc;MAC/D,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D,MAAM;QACJ,GAAG;QACH,QAAQ;MACV;MACA,uBAAuB;MACvB,2BAA2BI;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,UAAM,OAAO;AACb,UAAM,cAAc,KAAK,OAAO,SAAS,QAAQ,cAAc,EAAE;AAEjE,UAAM,+CACJ,4CAA4C,QAAQ,MAAM;AAE5D,UAAM,+CAA+C,oBAAI,IAGvD;AAEF,QAAI,eAA4C;MAC9C,SAAS;MACT,KAAK;IACP;AACA,QAAI,QAA0C;AAC9C,UAAM,WAA2C,CAAC;AAClD,QAAI,aAA4B;AAEhC,UAAM,mBAcF,CAAC;AAGL,UAAM,qBAKF,CAAC;AAGL,QAAI,kBAAkB;AAEtB,UAAM,kBAOF,CAAC;AAEL,QAAI;AAEJ,WAAO;MACL,QAAQ,SAAS;QACf,IAAI,gBAGF;UACA,MAAM,YAAY;AAChB,uBAAW,QAAQ,EAAE,MAAM,gBAAgB,SAAS,CAAC;UACvD;UAEA,UAAU,OAAO,YAAY;AAl9BvC,gBAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AAm9BY,gBAAI,QAAQ,kBAAkB;AAC5B,yBAAW,QAAQ,EAAE,MAAM,OAAO,UAAU,MAAM,SAAS,CAAC;YAC9D;AAGA,gBAAI,CAAC,MAAM,SAAS;AAClB,6BAAe,EAAE,SAAS,SAAS,KAAK,OAAU;AAClD,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;YACF;AAEA,kBAAM,QAAQ,MAAM;AAEpB,gBAAI,+BAA+B,KAAK,GAAG;AACzC,kBAAI,MAAM,KAAK,SAAS,iBAAiB;AACvC,iCAAiB,MAAM,YAAY,IAAI;kBACrC,UAAU,MAAM,KAAK;kBACrB,YAAY,MAAM,KAAK;gBACzB;AAEA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;kBACf,UAAU,MAAM,KAAK;gBACvB,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,mBAAmB;AAChD,iCAAiB,MAAM,YAAY,IAAI;kBACrC,UAAU,gBAAgB;oBACxB,qBAAA,OAAA,oBAAqB;kBACvB;kBACA,YAAY,MAAM,KAAK;gBACzB;AAEA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;kBACf,UAAU,gBAAgB;oBACxB,qBAAA,OAAA,oBAAqB;kBACvB;kBACA,kBAAkB;gBACpB,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;gBACjB,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU,gBAAgB;oBACxB,qBAAA,OAAA,oBAAqB;kBACvB;kBACA,OAAO,KAAK,UAAU,CAAC,CAAC;kBACxB,kBAAkB;gBACpB,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,iBAAiB;AAC9C,iCAAiB,MAAM,YAAY,IAAI;kBACrC,UAAU,gBAAgB,iBAAiB,cAAc;kBACzD,YAAY,MAAM,KAAK;gBACzB;AAEA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;kBACf,UAAU,gBAAgB,iBAAiB,cAAc;kBACzD,kBAAkB;gBACpB,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,yBAAyB;AACtD,iCAAiB,MAAM,YAAY,IAAI;kBACrC,UACE,gBAAgB,iBAAiB,kBAAkB;kBACrD,YAAY,MAAM,KAAK;kBACvB,iBAAiB;oBACf,aAAa,MAAM,KAAK;kBAC1B;gBACF;AAEA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;kBACf,UACE,gBAAgB,iBAAiB,kBAAkB;kBACrD,kBAAkB;gBACpB,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;kBACf,OAAO,mBAAmB,MAAM,KAAK,YAAY;gBACnD,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,oBAAoB;AACjD,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU,gBAAgB,iBAAiB,aAAa;kBACxD,OAAO;kBACP,kBAAkB;gBACpB,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,yBAAyB;AACtD,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UACE,gBAAgB,iBAAiB,kBAAkB;kBACrD,OAAO;kBACP,kBAAkB;gBACpB,CAAC;cACH,WACE,MAAM,KAAK,SAAS,cACpB,MAAM,KAAK,SAAS,oBACpB,MAAM,KAAK,SAAS,wBACpB;cAIF,WAAW,MAAM,KAAK,SAAS,oBAAoB;AACjD,sBAAM,EAAE,SAAS,QAAQ,UAAU,IAAI,MAAM;AAE7C,iCAAiB,MAAM,YAAY,IAAI;kBACrC,UAAU,gBAAgB,iBAAiB,aAAa;kBACxD,YAAY;kBACZ,YAAY;;oBAEV,SAAS,UAAU,SAAS;oBAC5B,YAAY,UAAU,SAAS;kBACjC;gBACF;AAEA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI;kBACJ,UAAU,gBAAgB,iBAAiB,aAAa;gBAC1D,CAAC;AAED,oBAAI,UAAU,SAAS,eAAe;AACpC,wBAAM,cAAc,KAAK,UAAU;oBACjC;oBACA;kBACF,CAAqD;AAErD,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI;oBACJ,OAAO;kBACT,CAAC;AAED,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI;kBACN,CAAC;gBACH,OAAO;AACL,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI;oBACJ,OAAO,cAAc,gBAAgB,MAAM,CAAC,0BAA0B,gBAAgB,UAAU,IAAI,CAAC,aAAa,gBAAgB,UAAU,IAAI,CAAC;kBACnJ,CAAC;gBACH;cACF,WAAW,MAAM,KAAK,SAAS,cAAc;AAC3C,iCAAiB,MAAM,YAAY,IAAI;kBACrC,UAAU,gBAAgB,iBAAiB,OAAO;kBAClD,YAAY,MAAM,KAAK;gBACzB;cACF,WAAW,MAAM,KAAK,SAAS,WAAW;AACxC,mCAAmB,OAAO,GAAG,mBAAmB,MAAM;AACtD,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;kBACf,kBAAkB;oBAChB,CAAC,WAAW,GAAG;sBACb,QAAQ,MAAM,KAAK;oBACrB;kBACF;gBACF,CAAC;cACH,WACE,+BAA+B,KAAK,KACpC,MAAM,KAAK,SAAS,aACpB;AACA,gCAAgB,MAAM,KAAK,EAAE,IAAI;kBAC/B,kBAAkB,MAAM,KAAK;kBAC7B,cAAc,EAAE,GAAG,SAAS;gBAC9B;AAEA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,GAAG,MAAM,KAAK,EAAE;kBACpB,kBAAkB;oBAChB,CAAC,WAAW,GAAG;sBACb,QAAQ,MAAM,KAAK;sBACnB,4BACE,KAAA,MAAM,KAAK,sBAAX,OAAA,KAAgC;oBACpC;kBACF;gBACF,CAAC;cACH;YACF,WAAW,8BAA8B,KAAK,GAAG;AAC/C,kBAAI,MAAM,KAAK,SAAS,WAAW;AACjC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;kBACf,kBAAkB;oBAChB,CAAC,WAAW,GAAG;sBACb,QAAQ,MAAM,KAAK;sBACnB,GAAI,mBAAmB,SAAS,KAAK;wBACnC,aAAa;sBACf;oBACF;kBACF;gBACF,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,iBAAiB;AAC9C,iCAAiB,MAAM,YAAY,IAAI;AACvC,kCAAkB;AAElB,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;gBACjB,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU,MAAM,KAAK;kBACrB,OAAO,MAAM,KAAK;kBAClB,kBAAkB;oBAChB,CAAC,WAAW,GAAG;sBACb,QAAQ,MAAM,KAAK;oBACrB;kBACF;gBACF,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,mBAAmB;AAChD,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU,gBAAgB;oBACxB,qBAAA,OAAA,oBAAqB;kBACvB;kBACA,QAAQ,mBAAmB,MAAM,KAAK,MAAM;gBAC9C,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,iBAAiB;AAC9C,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;gBACjB,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU,gBAAgB,iBAAiB,cAAc;kBACzD,OAAO;kBACP,kBAAkB;gBACpB,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU,gBAAgB,iBAAiB,cAAc;kBACzD,QAAQ;oBACN,MAAM;oBACN,QAAQ,MAAM,KAAK,UAAU;kBAC/B;gBACF,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,oBAAoB;AACjD,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU,gBAAgB,iBAAiB,aAAa;kBACxD,QAAQ;oBACN,SAAS,MAAM,KAAK;oBACpB,UACE,MAAA,KAAA,MAAM,KAAK,YAAX,OAAA,SAAA,GAAoB,IAAI,CAAA,YAAW;sBACjC,YAAY,OAAO;sBACnB,QAAQ,OAAO;sBACf,UAAU,OAAO;sBACjB,OAAO,OAAO;sBACd,MAAM,OAAO;oBACf,EAAA,MANA,OAAA,KAMO;kBACX;gBACF,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,yBAAyB;AACtD,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UACE,gBAAgB,iBAAiB,kBAAkB;kBACrD,QAAQ;oBACN,SAAS,MAAM,KAAK;kBACtB;gBACF,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,yBAAyB;AACtD,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UACE,gBAAgB,iBAAiB,kBAAkB;kBACrD,QAAQ;oBACN,QAAQ,MAAM,KAAK;kBACrB;gBACF,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,YAAY;AACzC,iCAAiB,MAAM,YAAY,IAAI;AAEvC,sBAAM,qBACJ,KAAA,MAAM,KAAK,wBAAX,OAAA,KAAkC;AAIpC,sBAAM,oBACJ,qBAAqB,QAChB,MAAA,KAAA,6CAA6C;kBAC5C;gBACF,MAFC,OAAA,KAGD,6CACE,iBACF,MALC,OAAA,KAMD,MAAM,KAAK,KACX,MAAM,KAAK;AAEjB,sBAAM,WAAW,OAAO,MAAM,KAAK,IAAI;AAEvC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY;kBACZ;kBACA,OAAO,MAAM,KAAK;kBAClB,kBAAkB;kBAClB,SAAS;gBACX,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY;kBACZ;kBACA,QAAQ;oBACN,MAAM;oBACN,aAAa,MAAM,KAAK;oBACxB,MAAM,MAAM,KAAK;oBACjB,WAAW,MAAM,KAAK;oBACtB,GAAI,MAAM,KAAK,UAAU,OACrB,EAAE,QAAQ,MAAM,KAAK,OAAO,IAC5B,CAAC;oBACL,GAAI,MAAM,KAAK,SAAS,OACpB,EAAE,OAAO,MAAM,KAAK,MAA8B,IAClD,CAAC;kBACP;kBACA,kBAAkB;oBAChB,CAAC,WAAW,GAAG;sBACb,QAAQ,MAAM,KAAK;oBACrB;kBACF;gBACF,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,kBAAkB;AAE/C,iCAAiB,MAAM,YAAY,IAAI;cAGzC,WAAW,MAAM,KAAK,SAAS,oBAAoB;AACjD,sBAAM,WAAW,iBAAiB,MAAM,YAAY;AACpD,qBACE,YAAA,OAAA,SAAA,SAAU,eACV,CAAC,SAAS,WAAW,cACrB,MAAM,KAAK,UAAU,SAAS,eAC9B;AACA,sBAAI,CAAC,SAAS,WAAW,SAAS;AAChC,+BAAW,QAAQ;sBACjB,MAAM;sBACN,IAAI,SAAS;sBACb,OAAO,gBAAgB,MAAM,KAAK,UAAU,IAAI;oBAClD,CAAC;kBACH;AAEA,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI,SAAS;oBACb,OAAO;kBACT,CAAC;AAED,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI,SAAS;kBACf,CAAC;AAED,2BAAS,WAAW,aAAa;gBACnC;AAGA,oBAAI,YAAY,MAAM,KAAK,WAAW,aAAa;AACjD,6BAAW,QAAQ;oBACjB,MAAM;oBACN,YAAY,SAAS;oBACrB,UAAU,gBAAgB,iBAAiB,aAAa;oBACxD,OAAO,KAAK,UAAU;sBACpB,QAAQ,MAAM,KAAK;sBACnB,WAAW,MAAM,KAAK;oBACxB,CAAqD;oBACrD,kBAAkB;sBAChB,CAAC,WAAW,GAAG;wBACb,QAAQ,MAAM,KAAK;sBACrB;oBACF;kBACF,CAAC;gBACH;AAEA,iCAAiB,MAAM,YAAY,IAAI;cACzC,WAAW,MAAM,KAAK,SAAS,wBAAwB;AACrD,iCAAiB,MAAM,YAAY,IAAI;AAEvC,sBAAM,mBACJ,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BD,WAAW;AAC3C,sBAAM,qBACJ,KAAA,MAAM,KAAK,wBAAX,OAAA,KAAkC,MAAM,KAAK;AAC/C,6DAA6C;kBAC3C;kBACA;gBACF;AAEA,sBAAM,WAAW,OAAO,MAAM,KAAK,IAAI;AAEvC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY;kBACZ;kBACA,OAAO,MAAM,KAAK;kBAClB,kBAAkB;kBAClB,SAAS;gBACX,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY;kBACZ,YAAY;gBACd,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,oBAAoB;AACjD,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU,gBAAgB,iBAAiB,aAAa;kBACxD,OAAO,KAAK,UAAU;oBACpB,QAAQ;sBACN,MAAM;sBACN,SAAS,MAAM,KAAK,OAAO;sBAC3B,WAAW,MAAM,KAAK,OAAO;sBAC7B,MAAM,MAAM,KAAK,OAAO;sBACxB,kBAAkB,MAAM,KAAK,OAAO;sBACpC,KAAK,MAAM,KAAK,OAAO;oBACzB;kBACF,CAAqD;kBACrD,kBAAkB;oBAChB,CAAC,WAAW,GAAG,EAAE,QAAQ,MAAM,KAAK,GAAG;kBACzC;gBACF,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,cAAc;AAC3C,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU,gBAAgB,iBAAiB,OAAO;kBAClD,OAAO,KAAK,UAAU;oBACpB,QAAQ;sBACN,UAAU,MAAM,KAAK,OAAO;oBAC9B;kBACF,CAAgD;kBAChD,kBAAkB;oBAChB,CAAC,WAAW,GAAG,EAAE,QAAQ,MAAM,KAAK,GAAG;kBACzC;gBACF,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,aAAa;AAC1C,sBAAM,sBAAsB,gBAAgB,MAAM,KAAK,EAAE;AAIzD,sBAAM,qBAAqB,OAAO;kBAChC,oBAAoB;gBACtB,EACG;kBACC,CAAC,CAAC,GAAG,MAAM,MACT,WAAW,YAAY,WAAW;gBACtC,EACC,IAAI,CAAC,CAAC,YAAY,MAAM,YAAY;AAEvC,2BAAW,gBAAgB,oBAAoB;AAC7C,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI,GAAG,MAAM,KAAK,EAAE,IAAI,YAAY;oBACpC,kBAAkB;sBAChB,CAAC,WAAW,GAAG;wBACb,QAAQ,MAAM,KAAK;wBACnB,4BACE,KAAA,MAAM,KAAK,sBAAX,OAAA,KAAgC;sBACpC;oBACF;kBACF,CAAC;gBACH;AAEA,uBAAO,gBAAgB,MAAM,KAAK,EAAE;cACtC;YACF,WAAW,0CAA0C,KAAK,GAAG;AAC3D,oBAAM,WAAW,iBAAiB,MAAM,YAAY;AAEpD,kBAAI,YAAY,MAAM;AACpB,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,SAAS;kBACb,OAAO,MAAM;gBACf,CAAC;cACH;YACF,WAAW,gDAAgD,KAAK,GAAG;AACjE,oBAAM,WAAW,iBAAiB,MAAM,YAAY;AAEpD,kBAAI,YAAA,OAAA,SAAA,SAAU,YAAY;AACxB,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,SAAS;kBACb,OAAO,gBAAgB,MAAM,KAAK;gBACpC,CAAC;AAED,yBAAS,WAAW,UAAU;cAChC;YACF,WAAW,+CAA+C,KAAK,GAAG;AAChE,oBAAM,WAAW,iBAAiB,MAAM,YAAY;AAEpD,mBAAI,YAAA,OAAA,SAAA,SAAU,eAAc,CAAC,SAAS,WAAW,YAAY;AAC3D,oBAAI,CAAC,SAAS,WAAW,SAAS;AAChC,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI,SAAS;oBACb,OAAO,gBAAgB,MAAM,IAAI;kBACnC,CAAC;AAED,2BAAS,WAAW,UAAU;gBAChC;AAEA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,SAAS;kBACb,OAAO;gBACT,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,SAAS;gBACf,CAAC;AAED,yBAAS,WAAW,aAAa;cACnC;YACF,WAAW,+CAA+C,KAAK,GAAG;AAChE,yBAAW,QAAQ;gBACjB,MAAM;gBACN,YAAY,MAAM;gBAClB,UAAU,gBAAgB,iBAAiB,kBAAkB;gBAC7D,QAAQ;kBACN,QAAQ,MAAM;gBAChB;gBACA,aAAa;cACf,CAAC;YACH,WAAW,4CAA4C,KAAK,GAAG;AAC7D,oBAAM,WAAW,iBAAiB,MAAM,YAAY;AAEpD,kBAAI,YAAY,MAAM;AACpB,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,SAAS;kBACb,OAAO,gBAAgB,MAAM,KAAK;gBACpC,CAAC;cACH;YACF,WAAW,2CAA2C,KAAK,GAAG;AAC5D,oBAAM,WAAW,iBAAiB,MAAM,YAAY;AAEpD,kBAAI,YAAY,MAAM;AACpB,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,SAAS;kBACb,OAAO;gBACT,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,SAAS;gBACf,CAAC;AAGD,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,SAAS;kBACrB,UACE,gBAAgB,iBAAiB,kBAAkB;kBACrD,OAAO,KAAK,UAAU;oBACpB,MAAM,MAAM;oBACZ,aAAa,SAAS,gBAAiB;kBACzC,CAA0D;kBAC1D,kBAAkB;gBACpB,CAAC;cACH;YACF,WAAW,uBAAuB,KAAK,GAAG;AACxC,2BAAa,MAAM,SAAS;AAC5B,yBAAW,QAAQ;gBACjB,MAAM;gBACN,IAAI,MAAM,SAAS;gBACnB,WAAW,IAAI,KAAK,MAAM,SAAS,aAAa,GAAI;gBACpD,SAAS,MAAM,SAAS;cAC1B,CAAC;YACH,WAAW,iBAAiB,KAAK,GAAG;AAClC,yBAAW,QAAQ;gBACjB,MAAM;gBACN,IAAI,MAAM;gBACV,OAAO,MAAM;cACf,CAAC;AAED,oBAAI,MAAA,KAAA,QAAQ,oBAAR,OAAA,SAAA,GAAyB,WAAzB,OAAA,SAAA,GAAiC,aAAY,MAAM,UAAU;AAC/D,yBAAS,KAAK,MAAM,QAAQ;cAC9B;YACF,WAAW,MAAM,SAAS,yCAAyC;AAEjE,kBAAI,MAAM,gBAAgB,GAAG;AAC3B,sBAAM,sBAAsB,gBAAgB,MAAM,OAAO;AAEzD,oCAAoB,aAAa,MAAM,aAAa,IAClD;AAGF,2BAAW,gBAAgB,OAAO;kBAChC,oBAAoB;gBACtB,GAAG;AACD,sBACE,oBAAoB,aAAa,YAAY,MAC7C,gBACA;AACA,+BAAW,QAAQ;sBACjB,MAAM;sBACN,IAAI,GAAG,MAAM,OAAO,IAAI,YAAY;sBACpC,kBAAkB;wBAChB,CAAC,WAAW,GAAG,EAAE,QAAQ,MAAM,QAAQ;sBACzC;oBACF,CAAC;AACD,wCAAoB,aAAa,YAAY,IAC3C;kBACJ;gBACF;AAEA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,GAAG,MAAM,OAAO,IAAI,MAAM,aAAa;kBAC3C,kBAAkB;oBAChB,CAAC,WAAW,GAAG;sBACb,QAAQ,MAAM;sBACd,4BACE,MAAA,KAAA,gBAAgB,MAAM,OAAO,MAA7B,OAAA,SAAA,GAAgC,qBAAhC,OAAA,KACA;oBACJ;kBACF;gBACF,CAAC;cACH;YACF,WAAW,MAAM,SAAS,yCAAyC;AACjE,yBAAW,QAAQ;gBACjB,MAAM;gBACN,IAAI,GAAG,MAAM,OAAO,IAAI,MAAM,aAAa;gBAC3C,OAAO,MAAM;gBACb,kBAAkB;kBAChB,CAAC,WAAW,GAAG;oBACb,QAAQ,MAAM;kBAChB;gBACF;cACF,CAAC;YACH,WAAW,MAAM,SAAS,wCAAwC;AAGhE,kBAAI,OAAO;AACT,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,GAAG,MAAM,OAAO,IAAI,MAAM,aAAa;kBAC3C,kBAAkB;oBAChB,CAAC,WAAW,GAAG,EAAE,QAAQ,MAAM,QAAQ;kBACzC;gBACF,CAAC;AAGD,gCAAgB,MAAM,OAAO,EAAG,aAC9B,MAAM,aACR,IAAI;cACN,OAAO;AAGL,gCAAgB,MAAM,OAAO,EAAG,aAC9B,MAAM,aACR,IAAI;cACN;YACF,WAAW,wBAAwB,KAAK,GAAG;AACzC,6BAAe;gBACb,SAAS,8BAA8B;kBACrC,eAAc,KAAA,MAAM,SAAS,uBAAf,OAAA,SAAA,GAAmC;kBACjD;gBACF,CAAC;gBACD,MAAK,MAAA,KAAA,MAAM,SAAS,uBAAf,OAAA,SAAA,GAAmC,WAAnC,OAAA,KAA6C;cACpD;AACA,sBAAQ,MAAM,SAAS;AACvB,kBAAI,OAAO,MAAM,SAAS,iBAAiB,UAAU;AACnD,8BAAc,MAAM,SAAS;cAC/B;YACF,WAAW,+BAA+B,KAAK,GAAG;AAChD,iCAAmB,KAAK,MAAM,UAAU;AACxC,kBAAI,MAAM,WAAW,SAAS,gBAAgB;AAC5C,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY;kBACZ,KAAI,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BA,WAAW;kBAC7C,KAAK,MAAM,WAAW;kBACtB,OAAO,MAAM,WAAW;gBAC1B,CAAC;cACH,WAAW,MAAM,WAAW,SAAS,iBAAiB;AACpD,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY;kBACZ,KAAI,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BA,WAAW;kBAC7C,WAAW;kBACX,QACE,MAAA,KAAA,MAAM,WAAW,UAAjB,OAAA,KACA,MAAM,WAAW,aADjB,OAAA,KAEA;kBACF,WACE,KAAA,MAAM,WAAW,aAAjB,OAAA,KAA6B,MAAM,WAAW;kBAChD,GAAI,MAAM,WAAW,UACjB;oBACE,kBAAkB;sBAChB,CAAC,WAAW,GAAG;wBACb,QAAQ,MAAM,WAAW;sBAC3B;oBACF;kBACF,IACA,CAAC;gBACP,CAAC;cACH,WAAW,MAAM,WAAW,SAAS,2BAA2B;AAC9D,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY;kBACZ,KAAI,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BA,WAAW;kBAC7C,WAAW;kBACX,QACE,MAAA,KAAA,MAAM,WAAW,aAAjB,OAAA,KACA,MAAM,WAAW,YADjB,OAAA,KAEA;kBACF,WACE,KAAA,MAAM,WAAW,aAAjB,OAAA,KAA6B,MAAM,WAAW;kBAChD,kBAAkB;oBAChB,CAAC,WAAW,GAAG;sBACb,QAAQ,MAAM,WAAW;sBACzB,aAAa,MAAM,WAAW;sBAC9B,GAAI,MAAM,WAAW,SAAS,OAC1B,EAAE,OAAO,MAAM,WAAW,MAAM,IAChC,CAAC;oBACP;kBACF;gBACF,CAAC;cACH,WAAW,MAAM,WAAW,SAAS,aAAa;AAChD,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY;kBACZ,KAAI,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BA,WAAW;kBAC7C,WAAW;kBACX,OAAO,MAAM,WAAW;kBACxB,UAAU,MAAM,WAAW;kBAC3B,kBAAkB;oBAChB,CAAC,WAAW,GAAG;sBACb,QAAQ,MAAM,WAAW;sBACzB,GAAI,MAAM,WAAW,SAAS,OAC1B,EAAE,OAAO,MAAM,WAAW,MAAM,IAChC,CAAC;oBACP;kBACF;gBACF,CAAC;cACH;YACF,WAAW,aAAa,KAAK,GAAG;AAC9B,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,CAAC;YACpD;UACF;UAEA,MAAM,YAAY;AAChB,kBAAM,mBAA6C;cACjD,CAAC,WAAW,GAAG;gBACb;cACF;YACF;AAEA,gBAAI,SAAS,SAAS,GAAG;AACvB,+BAAiB,WAAW,EAAE,WAAW;YAC3C;AAEA,gBAAI,gBAAgB,QAAW;AAC7B,+BAAiB,WAAW,EAAE,cAAc;YAC9C;AAEA,uBAAW,QAAQ;cACjB,MAAM;cACN;cACA,OAAO,4BAA4B,KAAK;cACxC;YACF,CAAC;UACH;QACF,CAAC;MACH;MACA,SAAS,EAAE,KAAK;MAChB,UAAU,EAAE,SAAS,gBAAgB;IACvC;EACF;AACF;AAEA,SAAS,iBACP,OACwE;AACxE,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,8BACP,OACuE;AACvE,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,wBACP,OAGA;AACA,SACE,MAAM,SAAS,wBAAwB,MAAM,SAAS;AAE1D;AAEA,SAAS,uBACP,OAC8D;AAC9D,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,0CACP,OAGA;AACA,SAAO,MAAM,SAAS;AACxB;AACA,SAAS,+CACP,OAGA;AACA,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,4CACP,OAGA;AACA,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,2CACP,OAGA;AACA,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,gDACP,OAC2D;AAC3D,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,+CACP,OAC0D;AAC1D,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,+BACP,OACwE;AACxE,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,+BACP,OAGA;AACA,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,aACP,OACmD;AACnD,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,mBACP,QAC2C;AA/1D7C,MAAA;AAg2DE,UAAQ,OAAO,MAAM;IACnB,KAAK;AACH,aAAO;QACL,QAAQ,EAAE,MAAM,UAAU,QAAO,KAAA,OAAO,UAAP,OAAA,KAAgB,OAAU;;QAE3D,GAAI,OAAO,WAAW,QAAQ,EAAE,SAAS,OAAO,QAAQ;MAC1D;IACF,KAAK;AACH,aAAO,EAAE,QAAQ,EAAE,MAAM,YAAY,KAAK,OAAO,IAAI,EAAE;IACzD,KAAK;AACH,aAAO;QACL,QAAQ;UACN,MAAM;UACN,KAAK,OAAO;UACZ,SAAS,OAAO;QAClB;MACF;EACJ;AACF;AAIA,SAAS,gBAAgB,OAAe;AACtC,SAAO,KAAK,UAAU,KAAK,EAAE,MAAM,GAAG,EAAE;AAC1C;;;AiBj3DO,IAAM,mBAKT;EACF;EACA;EACA;EACA;AACF;ACfO,IAAM,UACX,OACI,UACA;AF0IC,SAAS,YACd,UAAuC,CAAC,GACnB;AAjJvB,MAAA;AAkJE,QAAM,aAAa,MAAM;AACvB,UAAM,cAAc;MAClB,WAAW,WAAW;QACpB,QAAQ,QAAQ;QAChB,yBAAyB;QACzB,aAAa;MACf,CAAC;MACD,GAAG,QAAQ;IACb;AACA,WAAO,oBAAoB,aAAa,gBAAgB,OAAO,EAAE;EACnE;AAEA,QAAM,kBAAkB,MACtB,YAAY;IACV,cAAc,QAAQ;IACtB,aAAa;IACb,yBAAyB;IACzB,aAAa;EACf,CAAC;AAEH,QAAM,cAAa,KAAA,QAAQ,eAAR,OAAA,KAAsB;AAEzC,QAAM,MAAM,CAAC,EAAE,MAAM,QAAQ,MAAyC;AAxKxE,QAAAE;AAyKI,UAAM,iBACJA,MAAA,QAAQ,YAAR,OAAAA,MAAmB,WAAW,gBAAgB,CAAC;AAEjD,QAAI;AACJ,QAAI,QAAQ,wBAAwB;AAElC,gBAAU,IAAI,IAAI,GAAG,aAAa,gBAAgB,OAAO,GAAG,IAAI,EAAE;IACpE,OAAO;AAEL,gBAAU,IAAI,IAAI,GAAG,aAAa,MAAM,IAAI,EAAE;IAChD;AAEA,YAAQ,aAAa,IAAI,eAAe,UAAU;AAClD,WAAO,QAAQ,SAAS;EAC1B;AAEA,QAAM,kBAAkB,CAAC,mBACvB,IAAI,wBAAwB,gBAAgB;IAC1C,UAAU;IACV;IACA,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,wBAAwB,CAAC,YAC7B,IAAI,8BAA8B,SAAS;IACzC,UAAU;IACV;IACA,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,uBAAuB,CAAC,YAC5B,IAAI,qBAAqB,SAAS;IAChC,UAAU;IACV,SAAS;IACT;IACA,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,uBAAuB,CAAC,YAC5B,IAAI,6BAA6B,SAAS;IACxC,UAAU;IACV;IACA,SAAS;IACT,OAAO,QAAQ;IACf,gBAAgB,CAAC,YAAY;EAC/B,CAAC;AAEH,QAAM,mBAAmB,CAAC,YACxB,IAAI,iBAAiB,SAAS;IAC5B,UAAU;IACV;IACA,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,2BAA2B,CAAC,YAChC,IAAI,yBAAyB,SAAS;IACpC,UAAU;IACV;IACA,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,oBAAoB,CAAC,YACzB,IAAI,kBAAkB,SAAS;IAC7B,UAAU;IACV;IACA,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,WAAW,SAAU,cAAsB;AAC/C,QAAI,YAAY;AACd,YAAM,IAAI;QACR;MACF;IACF;AAEA,WAAO,qBAAqB,YAAY;EAC1C;AAEA,WAAS,uBAAuB;AAChC,WAAS,gBAAgB;AACzB,WAAS,OAAO;AAChB,WAAS,aAAa;AACtB,WAAS,YAAY;AACrB,WAAS,iBAAiB;AAC1B,WAAS,gBAAgB;AACzB,WAAS,qBAAqB;AAC9B,WAAS,QAAQ;AACjB,WAAS,aAAa;AACtB,WAAS,YAAY;AACrB,WAAS,gBAAgB;AACzB,WAAS,SAAS;AAClB,WAAS,QAAQ;AACjB,SAAO;AACT;AAKO,IAAM,QAAQ,YAAY;","names":["z","z","z","z","z","z","z","z","z","z","z","z","z","z","z","z","z","z","z","z","z","z","_a","lazySchema","zodSchema","UnsupportedFunctionalityError","toolCall","getResponseMetadata","mapOpenAIFinishReason","parseProviderOptions","postJsonToApi","combineHeaders","createJsonResponseHandler","createEventSourceResponseHandler","response","responseHeaders","_b","_c","_d","_e","convertBase64ToUint8Array","postFormDataToApi","lazySchema","zodSchema","z","createProviderToolFactoryWithOutputSchema","_a","_b","_c","convertToBase64","UnsupportedFunctionalityError","parseProviderOptions","validateTypes","postJsonToApi","combineHeaders","createJsonResponseHandler","providerMetadata","generateId","createEventSourceResponseHandler","_a"]}