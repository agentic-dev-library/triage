export { OpenAICompatibleErrorData as TogetherAIErrorData } from '@ai-sdk/openai-compatible';
import { ProviderV3, LanguageModelV3, EmbeddingModelV3, ImageModelV3, RerankingModelV3 } from '@ai-sdk/provider';
import * as _ai_sdk_provider_utils from '@ai-sdk/provider-utils';
import { FetchFunction, InferSchema } from '@ai-sdk/provider-utils';

type TogetherAIRerankingModelId = 'Salesforce/Llama-Rank-v1' | 'mixedbread-ai/Mxbai-Rerank-Large-V2' | (string & {});
type TogetherAIRerankingOptions = {
    /**
     * List of keys in the JSON Object document to rank by.
     * Defaults to use all supplied keys for ranking.
     *
     * @example ["title", "text"]
     */
    rankFields?: string[];
};

type TogetherAIChatModelId = 'meta-llama/Llama-3.3-70B-Instruct-Turbo' | 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo' | 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo' | 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo' | 'meta-llama/Meta-Llama-3-8B-Instruct-Turbo' | 'meta-llama/Meta-Llama-3-70B-Instruct-Turbo' | 'meta-llama/Llama-3.2-3B-Instruct-Turbo' | 'meta-llama/Meta-Llama-3-8B-Instruct-Lite' | 'meta-llama/Meta-Llama-3-70B-Instruct-Lite' | 'meta-llama/Llama-3-8b-chat-hf' | 'meta-llama/Llama-3-70b-chat-hf' | 'nvidia/Llama-3.1-Nemotron-70B-Instruct-HF' | 'Qwen/Qwen2.5-Coder-32B-Instruct' | 'Qwen/QwQ-32B-Preview' | 'microsoft/WizardLM-2-8x22B' | 'google/gemma-2-27b-it' | 'google/gemma-2-9b-it' | 'databricks/dbrx-instruct' | 'deepseek-ai/deepseek-llm-67b-chat' | 'deepseek-ai/DeepSeek-V3' | 'google/gemma-2b-it' | 'Gryphe/MythoMax-L2-13b' | 'meta-llama/Llama-2-13b-chat-hf' | 'mistralai/Mistral-7B-Instruct-v0.1' | 'mistralai/Mistral-7B-Instruct-v0.2' | 'mistralai/Mistral-7B-Instruct-v0.3' | 'mistralai/Mixtral-8x7B-Instruct-v0.1' | 'mistralai/Mixtral-8x22B-Instruct-v0.1' | 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO' | 'Qwen/Qwen2.5-7B-Instruct-Turbo' | 'Qwen/Qwen2.5-72B-Instruct-Turbo' | 'Qwen/Qwen2-72B-Instruct' | 'upstage/SOLAR-10.7B-Instruct-v1.0' | (string & {});

type TogetherAICompletionModelId = 'meta-llama/Llama-2-70b-hf' | 'mistralai/Mistral-7B-v0.1' | 'mistralai/Mixtral-8x7B-v0.1' | 'Meta-Llama/Llama-Guard-7b' | 'codellama/CodeLlama-34b-Instruct-hf' | 'Qwen/Qwen2.5-Coder-32B-Instruct' | (string & {});

type TogetherAIEmbeddingModelId = 'togethercomputer/m2-bert-80M-2k-retrieval' | 'togethercomputer/m2-bert-80M-32k-retrieval' | 'togethercomputer/m2-bert-80M-8k-retrieval' | 'WhereIsAI/UAE-Large-V1' | 'BAAI/bge-large-en-v1.5' | 'BAAI/bge-base-en-v1.5' | 'sentence-transformers/msmarco-bert-base-dot-v5' | 'bert-base-uncased' | (string & {});

type TogetherAIImageModelId = 'stabilityai/stable-diffusion-xl-base-1.0' | 'black-forest-labs/FLUX.1-dev' | 'black-forest-labs/FLUX.1-dev-lora' | 'black-forest-labs/FLUX.1-schnell' | 'black-forest-labs/FLUX.1-canny' | 'black-forest-labs/FLUX.1-depth' | 'black-forest-labs/FLUX.1-redux' | 'black-forest-labs/FLUX.1.1-pro' | 'black-forest-labs/FLUX.1-pro' | 'black-forest-labs/FLUX.1-schnell-Free' | 'black-forest-labs/FLUX.1-kontext-pro' | 'black-forest-labs/FLUX.1-kontext-max' | 'black-forest-labs/FLUX.1-kontext-dev' | (string & {});

interface TogetherAIProviderSettings {
    /**
  TogetherAI API key.
  */
    apiKey?: string;
    /**
  Base URL for the API calls.
  */
    baseURL?: string;
    /**
  Custom headers to include in the requests.
  */
    headers?: Record<string, string>;
    /**
  Custom fetch implementation. You can use it as a middleware to intercept requests,
  or to provide a custom fetch implementation for e.g. testing.
  */
    fetch?: FetchFunction;
}
interface TogetherAIProvider extends ProviderV3 {
    /**
  Creates a model for text generation.
  */
    (modelId: TogetherAIChatModelId): LanguageModelV3;
    /**
  Creates a chat model for text generation.
  */
    chatModel(modelId: TogetherAIChatModelId): LanguageModelV3;
    /**
  Creates a chat model for text generation.
  */
    languageModel(modelId: TogetherAIChatModelId): LanguageModelV3;
    /**
  Creates a completion model for text generation.
  */
    completionModel(modelId: TogetherAICompletionModelId): LanguageModelV3;
    /**
  Creates a text embedding model for text generation.
  */
    embeddingModel(modelId: TogetherAIEmbeddingModelId): EmbeddingModelV3;
    /**
     * @deprecated Use `embeddingModel` instead.
     */
    textEmbeddingModel(modelId: TogetherAIEmbeddingModelId): EmbeddingModelV3;
    /**
  Creates a model for image generation.
  */
    image(modelId: TogetherAIImageModelId): ImageModelV3;
    /**
  Creates a model for image generation.
  */
    imageModel(modelId: TogetherAIImageModelId): ImageModelV3;
    /**
     * Creates a model for reranking.
     */
    reranking(modelId: TogetherAIRerankingModelId): RerankingModelV3;
    /**
     * Creates a model for reranking.
     */
    rerankingModel(modelId: TogetherAIRerankingModelId): RerankingModelV3;
}
declare function createTogetherAI(options?: TogetherAIProviderSettings): TogetherAIProvider;
declare const togetherai: TogetherAIProvider;

/**
 * Provider options schema for Together AI image generation.
 */
declare const togetheraiImageProviderOptionsSchema: _ai_sdk_provider_utils.LazySchema<{
    [x: string]: unknown;
    steps?: number | null | undefined;
    guidance?: number | null | undefined;
    negative_prompt?: string | null | undefined;
    disable_safety_checker?: boolean | null | undefined;
}>;
type TogetherAIImageProviderOptions = InferSchema<typeof togetheraiImageProviderOptionsSchema>;

declare const VERSION: string;

export { type TogetherAIImageProviderOptions, type TogetherAIProvider, type TogetherAIProviderSettings, type TogetherAIRerankingOptions, VERSION, createTogetherAI, togetherai };
